{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "03_1_Estrategias_de_treino.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "5Xu4l1od4y1N",
        "0WyR3sukIS9D",
        "rsOgJBcofpZN"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "63a6b5d2130f49de995d8b87298f393e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1267a539a61f48b499984017b344826b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e9c52220ba4348fcb03ad3d4c37224be",
              "IPY_MODEL_0f547a258bf4479d8566740d224b482a"
            ]
          }
        },
        "1267a539a61f48b499984017b344826b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9c52220ba4348fcb03ad3d4c37224be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_157f152f56bb4275ad7417b60248c26e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b3c87a00bf146f19a4840d708fc0b9d"
          }
        },
        "0f547a258bf4479d8566740d224b482a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a652e14b414541af88d691ef255feead",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 52369918.15it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_647ddf9477db401fa19771363e3d95c0"
          }
        },
        "157f152f56bb4275ad7417b60248c26e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5b3c87a00bf146f19a4840d708fc0b9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a652e14b414541af88d691ef255feead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "647ddf9477db401fa19771363e3d95c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c4a1ea66ed340d8b0419cfd1b68b07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5c40fb6eabfc42fa94455f62312251bd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_501a5e66387e4c8fa7c51c35a2a591b4",
              "IPY_MODEL_70ef5ebd7daf4ccd8a419e8aba4e3f52"
            ]
          }
        },
        "5c40fb6eabfc42fa94455f62312251bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "501a5e66387e4c8fa7c51c35a2a591b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1e9b184b374d40958d822f6556ab4278",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d460f93e9ab14a8db6da01b38fbaffb5"
          }
        },
        "70ef5ebd7daf4ccd8a419e8aba4e3f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_13b9ca5b94f44bb19bc934eb6bece083",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 101312684.17it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c67ab45ebd4940d289eebf389c8441d0"
          }
        },
        "1e9b184b374d40958d822f6556ab4278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d460f93e9ab14a8db6da01b38fbaffb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13b9ca5b94f44bb19bc934eb6bece083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c67ab45ebd4940d289eebf389c8441d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXlS74cg4Ebl"
      },
      "source": [
        "# EstratÃ©gias de treino\n",
        "\n",
        "AtÃ© agora no curso, vimos somente uma estratÃ©gia de treino para redes neurais: o treinamento do zero.\n",
        "Entretanto, hÃ¡ outras formas de se explorar redes neurais.\n",
        "Nessa aula, vamos rever a estratÃ©gia treinamento do zero alÃ©m de apresentar duas novas formas:\n",
        "\n",
        "1.   rede neural como um extrator de caracterÃ­sticas, e\n",
        "2.   *fine-tuning*.\n",
        "\n",
        "Para cada uma dessas estratÃ©gias, vamos apresentar sua definiÃ§Ã£o, vantagens e desvantagens.\n",
        "Antes, vamos instalar o Pytorch, importar alguns pacotes e definir funÃ§Ãµes para carregar os dados.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDFChpaZ4MiW",
        "outputId": "92661a73-adbe-4a28-d184-4f46d933781a"
      },
      "source": [
        "import time, os, sys, numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch import optim\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "import time, os, sys, numpy as np\n",
        "\n",
        "# Test if GPU is avaliable, if not, use cpu instead\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "n = torch.cuda.device_count()\n",
        "devices_ids= list(range(n))\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF4QkjwG4RQI"
      },
      "source": [
        "def load_data_cifar10(batch_size, resize=None, root=os.path.join(\n",
        "        '~', '.pytorch', 'datasets', 'fashion-mnist')):\n",
        "    \"\"\"Download the Cifar10-MNIST dataset and then load into memory.\"\"\"\n",
        "    root = os.path.expanduser(root)\n",
        "    transformer = []\n",
        "    if resize:\n",
        "        transformer += [torchvision.transforms.Resize(resize)]\n",
        "    transformer += [torchvision.transforms.ToTensor()]\n",
        "    transformer = torchvision.transforms.Compose(transformer)\n",
        "\n",
        "    mnist_train = torchvision.datasets.CIFAR10(root=root, train=True,download=True,transform=transformer)\n",
        "    mnist_test = torchvision.datasets.CIFAR10(root=root, train=False,download=True,transform=transformer)\n",
        "    num_workers = 0 if sys.platform.startswith('win32') else 4\n",
        "\n",
        "\n",
        "\n",
        "    train_iter = torch.utils.data.DataLoader(mnist_train,\n",
        "                                  batch_size, shuffle=True,\n",
        "                                  num_workers=num_workers)\n",
        "    test_iter = torch.utils.data.DataLoader(mnist_test,\n",
        "                                 batch_size, shuffle=False,\n",
        "                                 num_workers=num_workers)\n",
        "    return train_iter, test_iter\n",
        "\n",
        "# funÃ§Ãµes bÃ¡sicas\n",
        "def _get_batch(batch):\n",
        "    \"\"\"Return features and labels on ctx.\"\"\"\n",
        "    features, labels = batch\n",
        "    if labels.type() != features.type():\n",
        "        labels = labels.type(features.type())\n",
        "    return (torch.nn.DataParallel(features, device_ids=devices_ids),\n",
        "            torch.nn.DataParallel(labels, device_ids=devices_ids), features.shape[0])\n",
        "\n",
        "# FunÃ§Ã£o usada para calcular acurÃ¡cia\n",
        "def evaluate_accuracy(data_iter, net, loss):\n",
        "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
        "\n",
        "    acc_sum, n, l = torch.Tensor([0]), 0, 0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "      for X, y in data_iter:\n",
        "          #y = y.astype('float32')\n",
        "          X, y = X.to(device), y.to(device)\n",
        "          y_hat = net(X)\n",
        "          l += loss(y_hat, y).sum()\n",
        "          acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
        "          n += y.size()[0]\n",
        "\n",
        "    return acc_sum.item() / n, l.item() / len(data_iter)\n",
        "  \n",
        "# FunÃ§Ã£o usada no treinamento e validaÃ§Ã£o da rede\n",
        "def train_validate(net, train_iter, test_iter, batch_size, trainer, loss,\n",
        "                   num_epochs):\n",
        "    print('training on', device)\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
        "        for X, y in train_iter:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_hat = net(X)\n",
        "            trainer.zero_grad()\n",
        "            l = loss(y_hat, y).sum()\n",
        "            l.backward()\n",
        "            trainer.step()\n",
        "            train_l_sum += l.item()\n",
        "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
        "            n += y.size()[0]\n",
        "        test_acc, test_loss = evaluate_accuracy(test_iter, net, loss)\n",
        "        print('epoch %d, train loss %.4f, train acc %.3f, test loss %.4f, '\n",
        "              'test acc %.3f, time %.1f sec'\n",
        "              % (epoch + 1, train_l_sum / len(train_iter), train_acc_sum / n, test_loss, \n",
        "                 test_acc, time.time() - start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xu4l1od4y1N"
      },
      "source": [
        "## Treinamento do zero\n",
        "\n",
        "Como dito anteriormente, essa foi a Ãºnica estratÃ©gia vista atÃ© o momento no curso.\n",
        "Nessa estratÃ©gia, uma rede neural Ã© proposta, **inicializada com pesos aleatÃ³rios** e treinada atÃ© convergir.\n",
        "A **vantagem** dessa estratÃ©gia Ã© liberdade para definir como quiser a arquitetura da rede e seus hiper-parÃ¢metros\n",
        "Por outro lado, a **desvantagem** Ã© que essa estratÃ©gia requer muitos dados para convergir a rede inicializada aleatoriamente.\n",
        "Logo, se tivermos poucos dados, essa nÃ£o Ã© a estratÃ©gia mais recomendada.\n",
        "Abaixo, uma representaÃ§Ã£o visual dessa estratÃ©gia.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img width=600 src=\"https://drive.google.com/uc?export=view&id=1_bBQjyoDqB3kQMncmVkuJwSxDs3rqUmM\">\n",
        "</p>\n",
        "\n",
        "Apesar de jÃ¡ termos visto essa estratÃ©gia na prÃ¡tica, vamos vÃª-la aqui novamente para efeitos de comparaÃ§Ã£o com as outras tÃ©cnicas. Para tal, vamos, primeiro, definimos a arquitetura da [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZAEDlZ-DgGd"
      },
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, input_channels, classes=10, **kwargs):\n",
        "        super(AlexNet, self).__init__(**kwargs)\n",
        "        self.convs = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_channels, out_channels=96, kernel_size=11, stride=4, padding=0),   # entrada: (b, 3, 227, 227) e saida: (b, 96, 55, 55)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0),                                   # entrada: (b, 96, 55, 55) e saida: (b, 96, 27, 27)\n",
        "\n",
        "            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2),  # entrada: (b, 96, 27, 27) e saida: (b, 256, 27, 27)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0),                                   # entrada: (b, 256, 27, 27) e saida: (b, 256, 13, 13)\n",
        "            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1), # entrada: (b, 256, 13, 13) e saida: (b, 384, 13, 13)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1), # entrada: (b, 384, 13, 13) e saida: (b, 384, 13, 13)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1), # entrada: (b, 384, 13, 13) e saida: (b, 256, 13, 13)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0)                                    # entrada: (b, 256, 13, 13) e saida: (b, 256, 6, 6)\n",
        "        )\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Flatten(),                                                                     # entrada: (b, 256, 13, 13) e saida: (b, 256*6*6) = (b, 9216)\n",
        "            nn.Linear(9216, 4096),                                                             # entrada: (b, 9216) e saida: (b, 4096)\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),                                                             # entrada: (b, 4096) e saida: (b, 4096)\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, classes)                                                          # entrada: (b, 4096) e saida: (b, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = self.features(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "63a6b5d2130f49de995d8b87298f393e",
            "1267a539a61f48b499984017b344826b",
            "e9c52220ba4348fcb03ad3d4c37224be",
            "0f547a258bf4479d8566740d224b482a",
            "157f152f56bb4275ad7417b60248c26e",
            "5b3c87a00bf146f19a4840d708fc0b9d",
            "a652e14b414541af88d691ef255feead",
            "647ddf9477db401fa19771363e3d95c0"
          ]
        },
        "id": "9Wr5rH-KMNZo",
        "outputId": "5b781524-ed97-460c-e42d-6d7a1ad06560"
      },
      "source": [
        "# parÃ¢metros: nÃºmero de epochs, learning rate (ou taxa de aprendizado), \n",
        "# tamanho do batch, e lambda do weight decay\n",
        "num_epochs, lr, batch_size, wd_lambda = 20, 0.01, 100, 0.0001\n",
        "\n",
        "\n",
        "# rede baseada na AlexNet-5 \n",
        "net = AlexNet(3, 10)\n",
        "\n",
        "# Sending model to device\n",
        "net.to(device)\n",
        "print(summary(net,(3, 227, 227))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\n",
        "                                # and stored weights. \n",
        "\n",
        "# funÃ§Ã£o de custo (ou loss)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# carregamento do dado: mnist\n",
        "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n",
        "\n",
        "# trainer do gluon\n",
        "trainer = optim.SGD(net.parameters(), lr=lr, weight_decay=wd_lambda, momentum=0.9)\n",
        "\n",
        "# treinamento e validaÃ§Ã£o via Pytorch\n",
        "train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n",
        "                num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 55, 55]          34,944\n",
            "              ReLU-2           [-1, 96, 55, 55]               0\n",
            "         MaxPool2d-3           [-1, 96, 27, 27]               0\n",
            "            Conv2d-4          [-1, 256, 27, 27]         614,656\n",
            "              ReLU-5          [-1, 256, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 256, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         885,120\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 384, 13, 13]       1,327,488\n",
            "             ReLU-10          [-1, 384, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "          Flatten-14                 [-1, 9216]               0\n",
            "           Linear-15                 [-1, 4096]      37,752,832\n",
            "             ReLU-16                 [-1, 4096]               0\n",
            "          Dropout-17                 [-1, 4096]               0\n",
            "           Linear-18                 [-1, 4096]      16,781,312\n",
            "             ReLU-19                 [-1, 4096]               0\n",
            "          Dropout-20                 [-1, 4096]               0\n",
            "           Linear-21                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 58,322,314\n",
            "Trainable params: 58,322,314\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 11.11\n",
            "Params size (MB): 222.48\n",
            "Estimated Total Size (MB): 234.18\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/.pytorch/datasets/fashion-mnist/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63a6b5d2130f49de995d8b87298f393e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/datasets/fashion-mnist/cifar-10-python.tar.gz to /root/.pytorch/datasets/fashion-mnist\n",
            "Files already downloaded and verified\n",
            "training on cuda\n",
            "epoch 1, train loss 2.2015, train acc 0.161, test loss 1.9719, test acc 0.281, time 92.1 sec\n",
            "epoch 2, train loss 1.7785, train acc 0.339, test loss 1.5453, test acc 0.423, time 93.5 sec\n",
            "epoch 3, train loss 1.4151, train acc 0.483, test loss 1.2054, test acc 0.574, time 94.3 sec\n",
            "epoch 4, train loss 1.1467, train acc 0.591, test loss 0.9854, test acc 0.656, time 94.4 sec\n",
            "epoch 5, train loss 0.9382, train acc 0.671, test loss 0.8815, test acc 0.693, time 94.5 sec\n",
            "epoch 6, train loss 0.7706, train acc 0.734, test loss 0.7898, test acc 0.728, time 95.9 sec\n",
            "epoch 7, train loss 0.6444, train acc 0.777, test loss 0.6734, test acc 0.770, time 95.3 sec\n",
            "epoch 8, train loss 0.5413, train acc 0.812, test loss 0.6623, test acc 0.779, time 95.8 sec\n",
            "epoch 9, train loss 0.4430, train acc 0.846, test loss 0.6259, test acc 0.789, time 98.7 sec\n",
            "epoch 10, train loss 0.3558, train acc 0.876, test loss 0.6036, test acc 0.799, time 99.4 sec\n",
            "epoch 11, train loss 0.2787, train acc 0.903, test loss 0.6869, test acc 0.795, time 99.3 sec\n",
            "epoch 12, train loss 0.2203, train acc 0.923, test loss 0.6432, test acc 0.808, time 99.4 sec\n",
            "epoch 13, train loss 0.1925, train acc 0.934, test loss 0.7119, test acc 0.801, time 97.3 sec\n",
            "epoch 14, train loss 0.1473, train acc 0.950, test loss 0.7386, test acc 0.807, time 97.1 sec\n",
            "epoch 15, train loss 0.1273, train acc 0.957, test loss 0.8623, test acc 0.805, time 97.3 sec\n",
            "epoch 16, train loss 0.1147, train acc 0.961, test loss 0.7945, test acc 0.803, time 98.0 sec\n",
            "epoch 17, train loss 0.0930, train acc 0.969, test loss 0.8906, test acc 0.813, time 97.9 sec\n",
            "epoch 18, train loss 0.0865, train acc 0.971, test loss 0.8490, test acc 0.810, time 99.5 sec\n",
            "epoch 19, train loss 0.0689, train acc 0.977, test loss 0.9094, test acc 0.806, time 101.2 sec\n",
            "epoch 20, train loss 0.0683, train acc 0.977, test loss 0.8422, test acc 0.816, time 100.3 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgJwhj2SSGFB"
      },
      "source": [
        "Ã‰ muito comum se usar redes jÃ¡ existentes para aprender caracterÃ­sticas em novos dados.\n",
        "Por isso, muitos frameworks jÃ¡ deixam as arquiteturas mais famosas prÃ©-implementadas para que possam ser usadas.\n",
        "\n",
        "No Pytorch, podemos importar uma rede [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) usando o pacote [torchvision.models](https://pytorch.org/docs/stable/torchvision/models.html#torchvision-models) do Pytorch.\n",
        "HÃ¡ vÃ¡rias arquiteturas prÃ©-definidas nessa biblioteca, incluindo vÃ¡rias [DenseNets](https://arxiv.org/pdf/1608.06993.pdf) e [ResNets](https://arxiv.org/abs/1603.05027), [VGGs](https://arxiv.org/abs/1409.1556), [SqueezeNets](https://arxiv.org/abs/1602.07360), etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9c4a1ea66ed340d8b0419cfd1b68b07c",
            "5c40fb6eabfc42fa94455f62312251bd",
            "501a5e66387e4c8fa7c51c35a2a591b4",
            "70ef5ebd7daf4ccd8a419e8aba4e3f52",
            "1e9b184b374d40958d822f6556ab4278",
            "d460f93e9ab14a8db6da01b38fbaffb5",
            "13b9ca5b94f44bb19bc934eb6bece083",
            "c67ab45ebd4940d289eebf389c8441d0"
          ]
        },
        "id": "f3u7xCEQM0qF",
        "outputId": "576b9bbe-98b0-4f5b-ce44-5ff4eae067fa"
      },
      "source": [
        "# parÃ¢metros: nÃºmero de epochs, learning rate (ou taxa de aprendizado), \n",
        "# tamanho do batch, e lambda do weight decay\n",
        "num_epochs, lr, batch_size, wd_lambda = 20, 0.01, 100, 0.0001\n",
        "\n",
        "# rede baseada na AlexNet-5 \n",
        "net = torchvision.models.alexnet(num_classes=10)\n",
        "\n",
        "# Sending model to device\n",
        "net.to(device)\n",
        "print(summary(net,(3,227,227))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\n",
        "                                # and stored weights. \n",
        "\n",
        "# funÃ§Ã£o de custo (ou loss)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# carregamento do dado: mnist\n",
        "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n",
        "\n",
        "# trainer do gluon\n",
        "trainer = optim.SGD(net.parameters(), lr=lr, weight_decay=wd_lambda, momentum=0.9)\n",
        "\n",
        "# treinamento e validaÃ§Ã£o via Pytorch\n",
        "train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n",
        "                num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
            "              ReLU-2           [-1, 64, 56, 56]               0\n",
            "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
            "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
            "              ReLU-5          [-1, 192, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-10          [-1, 256, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
            "          Dropout-15                 [-1, 9216]               0\n",
            "           Linear-16                 [-1, 4096]      37,752,832\n",
            "             ReLU-17                 [-1, 4096]               0\n",
            "          Dropout-18                 [-1, 4096]               0\n",
            "           Linear-19                 [-1, 4096]      16,781,312\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "           Linear-21                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 57,044,810\n",
            "Trainable params: 57,044,810\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 8.48\n",
            "Params size (MB): 217.61\n",
            "Estimated Total Size (MB): 226.68\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/.pytorch/datasets/fashion-mnist/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c4a1ea66ed340d8b0419cfd1b68b07c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/datasets/fashion-mnist/cifar-10-python.tar.gz to /root/.pytorch/datasets/fashion-mnist\n",
            "Files already downloaded and verified\n",
            "training on cuda\n",
            "epoch 1, train loss 2.2569, train acc 0.132, test loss 2.0560, test acc 0.233, time 87.3 sec\n",
            "epoch 2, train loss 1.8570, train acc 0.312, test loss 1.5836, test acc 0.414, time 87.2 sec\n",
            "epoch 3, train loss 1.4649, train acc 0.463, test loss 1.2912, test acc 0.530, time 88.2 sec\n",
            "epoch 4, train loss 1.2168, train acc 0.564, test loss 1.1152, test acc 0.600, time 88.2 sec\n",
            "epoch 5, train loss 0.9965, train acc 0.651, test loss 0.9834, test acc 0.658, time 88.5 sec\n",
            "epoch 6, train loss 0.8407, train acc 0.706, test loss 0.8171, test acc 0.722, time 88.8 sec\n",
            "epoch 7, train loss 0.7193, train acc 0.749, test loss 0.7321, test acc 0.749, time 88.4 sec\n",
            "epoch 8, train loss 0.6326, train acc 0.779, test loss 0.6461, test acc 0.778, time 88.1 sec\n",
            "epoch 9, train loss 0.5552, train acc 0.805, test loss 0.6047, test acc 0.793, time 88.2 sec\n",
            "epoch 10, train loss 0.4882, train acc 0.830, test loss 0.6147, test acc 0.788, time 88.2 sec\n",
            "epoch 11, train loss 0.4301, train acc 0.850, test loss 0.5401, test acc 0.815, time 88.5 sec\n",
            "epoch 12, train loss 0.3753, train acc 0.869, test loss 0.5618, test acc 0.809, time 88.5 sec\n",
            "epoch 13, train loss 0.3325, train acc 0.881, test loss 0.5655, test acc 0.813, time 88.2 sec\n",
            "epoch 14, train loss 0.2878, train acc 0.898, test loss 0.5629, test acc 0.827, time 88.6 sec\n",
            "epoch 15, train loss 0.2535, train acc 0.911, test loss 0.5592, test acc 0.825, time 88.7 sec\n",
            "epoch 16, train loss 0.2283, train acc 0.920, test loss 0.5841, test acc 0.827, time 88.7 sec\n",
            "epoch 17, train loss 0.2010, train acc 0.929, test loss 0.6103, test acc 0.816, time 88.4 sec\n",
            "epoch 18, train loss 0.1835, train acc 0.936, test loss 0.6266, test acc 0.816, time 88.6 sec\n",
            "epoch 19, train loss 0.1588, train acc 0.945, test loss 0.6158, test acc 0.826, time 88.6 sec\n",
            "epoch 20, train loss 0.1472, train acc 0.949, test loss 0.7042, test acc 0.814, time 88.0 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WyR3sukIS9D"
      },
      "source": [
        "## Extrator de caracterÃ­sticas\n",
        "\n",
        "A terceira e Ãºltima estratÃ©gia, mostrada na figura abaixo, Ã© usar uma rede neural prÃ©-treinada em algum dataset grande para extrair caracterÃ­sticas de um outro dataset. Essa estratÃ©gia Ã© preferÃ­vel quando o dataset que se quer extrair as *features* tem muito poucas amostras, inviabilizando o treinamento ou *fine-tuning* da rede.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img width=600 src=\"https://drive.google.com/uc?export=view&id=1pWGfQIAeOODIvm-IQ7De4kl60XpRYbb5\">\n",
        "</p>\n",
        "\n",
        "Existem duas formas de se explorar essa estratÃ©gia. A primeira consiste em substituir e treinar somente a Ãºltima camada da rede neural. Nessa primeira forma, todas as outras camadas da rede ficam com *learning rate* 0, ou seja, nÃ£o aprendem nada, e sÃ£o somente usadas como codificadores/extratores de caracterÃ­sticas. A segunda forma, *features* das imagens do dataset que se quer classificar sÃ£o extraÃ­das da penÃºltima camada da rede prÃ©-treinada (geralmente, a camada antes da camada de classificaÃ§Ã£o). Essas *features* sÃ£o entÃ£o usadas para se treinar um agoritmo externo (como um SVM ou *random forest*), que entÃ£o classifica o dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VLBe7z2HmNK",
        "outputId": "ba0e5ad7-9991-4e19-dce3-71d816aa7e55"
      },
      "source": [
        "# rede baseada na AlexNet\n",
        "net = torchvision.models.alexnet(pretrained=True)\n",
        "\n",
        "# Sending model to device\n",
        "net.to(device)\n",
        "\n",
        "for param in net.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "print(summary(net, (3, 227, 227)))\n",
        "\n",
        "num_ftrs = net.classifier[6].in_features\n",
        "net.classifier[6] = nn.Linear(num_ftrs,10) # Alterando a Ãºltima layer para retornar 10 classes ao invÃ©s de 1000\n",
        "\n",
        "# Sending model to device\n",
        "net.to(device)\n",
        "\n",
        "# Verifique no output a Ãºltima camada do classifier, podemos ver que sua saÃ­da Ã© 10\n",
        "print(net)\n",
        "\n",
        "# Podemos ver que este output mostra que apenas  40970 parÃ¢metros serÃ£o treinados. Ou seja, somente a Ãºltima camada\n",
        "print(summary(net, (3,227,227))) \n",
        "\n",
        "# CÃ³digo retirado de https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "print(\"Params to learn: \")\n",
        "\n",
        "params_to_update = []\n",
        "for name,param in net.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        print(\"\\t\",name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
            "              ReLU-2           [-1, 64, 56, 56]               0\n",
            "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
            "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
            "              ReLU-5          [-1, 192, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-10          [-1, 256, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
            "          Dropout-15                 [-1, 9216]               0\n",
            "           Linear-16                 [-1, 4096]      37,752,832\n",
            "             ReLU-17                 [-1, 4096]               0\n",
            "          Dropout-18                 [-1, 4096]               0\n",
            "           Linear-19                 [-1, 4096]      16,781,312\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "           Linear-21                 [-1, 1000]       4,097,000\n",
            "================================================================\n",
            "Total params: 61,100,840\n",
            "Trainable params: 0\n",
            "Non-trainable params: 61,100,840\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 8.49\n",
            "Params size (MB): 233.08\n",
            "Estimated Total Size (MB): 242.16\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
            "              ReLU-2           [-1, 64, 56, 56]               0\n",
            "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
            "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
            "              ReLU-5          [-1, 192, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-10          [-1, 256, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
            "          Dropout-15                 [-1, 9216]               0\n",
            "           Linear-16                 [-1, 4096]      37,752,832\n",
            "             ReLU-17                 [-1, 4096]               0\n",
            "          Dropout-18                 [-1, 4096]               0\n",
            "           Linear-19                 [-1, 4096]      16,781,312\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "           Linear-21                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 57,044,810\n",
            "Trainable params: 40,970\n",
            "Non-trainable params: 57,003,840\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 8.48\n",
            "Params size (MB): 217.61\n",
            "Estimated Total Size (MB): 226.68\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "Params to learn: \n",
            "\t classifier.6.weight\n",
            "\t classifier.6.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fk0epQ2PDb0",
        "outputId": "7538a430-fc04-4b26-e1da-4de225349e42"
      },
      "source": [
        "# Treinando a Ãºltima camada da rede acima\n",
        "# parÃ¢metros: nÃºmero de epochs, learning rate (ou taxa de aprendizado), \n",
        "# tamanho do batch, e lambda do weight decay\n",
        "num_epochs, lr, batch_size, wd_lambda = 20, 0.001, 100, 0.0001\n",
        "\n",
        "# funÃ§Ã£o de custo (ou loss)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# carregamento do dado: mnist\n",
        "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n",
        "\n",
        "# trainer do gluon\n",
        "trainer = optim.SGD(params_to_update, lr=lr, weight_decay=wd_lambda, momentum=0.9)\n",
        "\n",
        "# treinamento e validaÃ§Ã£o via Pytorch\n",
        "train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n",
        "                num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "training on cuda\n",
            "epoch 1, train loss 1.3262, train acc 0.534, test loss 1.0916, test acc 0.610, time 86.6 sec\n",
            "epoch 2, train loss 1.1642, train acc 0.588, test loss 0.9961, test acc 0.654, time 86.8 sec\n",
            "epoch 3, train loss 1.1277, train acc 0.602, test loss 0.9634, test acc 0.662, time 86.9 sec\n",
            "epoch 4, train loss 1.1151, train acc 0.606, test loss 0.9462, test acc 0.672, time 86.8 sec\n",
            "epoch 5, train loss 1.0945, train acc 0.614, test loss 0.9265, test acc 0.676, time 86.7 sec\n",
            "epoch 6, train loss 1.0882, train acc 0.618, test loss 0.9345, test acc 0.671, time 86.8 sec\n",
            "epoch 7, train loss 1.0796, train acc 0.618, test loss 0.9326, test acc 0.678, time 86.5 sec\n",
            "epoch 8, train loss 1.0778, train acc 0.619, test loss 0.8997, test acc 0.684, time 86.5 sec\n",
            "epoch 9, train loss 1.0652, train acc 0.626, test loss 0.9065, test acc 0.679, time 86.6 sec\n",
            "epoch 10, train loss 1.0652, train acc 0.624, test loss 0.8911, test acc 0.687, time 86.8 sec\n",
            "epoch 11, train loss 1.0613, train acc 0.623, test loss 0.9190, test acc 0.674, time 87.0 sec\n",
            "epoch 12, train loss 1.0560, train acc 0.625, test loss 0.9070, test acc 0.678, time 86.6 sec\n",
            "epoch 13, train loss 1.0552, train acc 0.627, test loss 0.8888, test acc 0.686, time 86.7 sec\n",
            "epoch 14, train loss 1.0525, train acc 0.627, test loss 0.9140, test acc 0.673, time 86.8 sec\n",
            "epoch 15, train loss 1.0493, train acc 0.628, test loss 0.8974, test acc 0.684, time 86.7 sec\n",
            "epoch 16, train loss 1.0452, train acc 0.632, test loss 0.9008, test acc 0.683, time 86.6 sec\n",
            "epoch 17, train loss 1.0462, train acc 0.631, test loss 0.8753, test acc 0.693, time 86.6 sec\n",
            "epoch 18, train loss 1.0478, train acc 0.630, test loss 0.8919, test acc 0.681, time 86.8 sec\n",
            "epoch 19, train loss 1.0452, train acc 0.630, test loss 0.9101, test acc 0.679, time 86.5 sec\n",
            "epoch 20, train loss 1.0377, train acc 0.634, test loss 0.8619, test acc 0.698, time 86.9 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozt5EPQmSsx1",
        "outputId": "82b0c52f-afb0-4324-f260-d832917ac1b5"
      },
      "source": [
        "# parÃ¢metros: nÃºmero de epochs, learning rate (ou taxa de aprendizado), \n",
        "# tamanho do batch, e lambda do weight decay\n",
        "num_epochs, lr, batch_size, wd_lambda = 20, 0.01, 100, 0.0001\n",
        "\n",
        "# rede baseada na AlexNet-5 \n",
        "net = torchvision.models.alexnet(pretrained=True)\n",
        "\n",
        "# Sending model to device\n",
        "net.to(device)\n",
        "\n",
        "# carregamento do dado: fashion mnist\n",
        "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)  \n",
        "\n",
        "# remove last fully-connected layer\n",
        "new_classifier = nn.Sequential(*list(net.classifier.children())[:-1])\n",
        "net.classifier = new_classifier\n",
        "\n",
        "print(summary(net,(3,227,227))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\n",
        "                                # and stored weights. \n",
        "\n",
        "first = True    \n",
        "with torch.no_grad():\n",
        "    for X, y in train_iter:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        features = net(X)\n",
        "        if first is True:\n",
        "          train_features = features.cpu().numpy()\n",
        "          train_labels = y.cpu().numpy()\n",
        "          first = False\n",
        "        else:\n",
        "          train_features = np.concatenate((train_features, features.cpu().numpy()))\n",
        "          train_labels = np.concatenate((train_labels, y.cpu().numpy()))\n",
        "\n",
        "\n",
        "first = True    \n",
        "with torch.no_grad():\n",
        "    for X, y in test_iter:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        features = net(X)\n",
        "        if first is True:\n",
        "          test_features = features.cpu().numpy()\n",
        "          test_labels = y.cpu().numpy()\n",
        "          first = False\n",
        "        else:\n",
        "          test_features = np.concatenate((test_features, features.cpu().numpy()))\n",
        "          test_labels = np.concatenate((test_labels, y.cpu().numpy()))\n",
        "\n",
        "          \n",
        "print(train_features.shape, test_features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
            "              ReLU-2           [-1, 64, 56, 56]               0\n",
            "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
            "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
            "              ReLU-5          [-1, 192, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-10          [-1, 256, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
            "          Dropout-15                 [-1, 9216]               0\n",
            "           Linear-16                 [-1, 4096]      37,752,832\n",
            "             ReLU-17                 [-1, 4096]               0\n",
            "          Dropout-18                 [-1, 4096]               0\n",
            "           Linear-19                 [-1, 4096]      16,781,312\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "================================================================\n",
            "Total params: 57,003,840\n",
            "Trainable params: 57,003,840\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 8.48\n",
            "Params size (MB): 217.45\n",
            "Estimated Total Size (MB): 226.52\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "(50000, 4096) (10000, 4096)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR7LqiOTY6Tc",
        "outputId": "76c66d61-8dab-46cd-cfd3-58152fc3324a"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = LinearSVC()\n",
        "clf.fit(train_features, train_labels)\n",
        "\n",
        "pred = clf.predict(test_features)\n",
        "print(accuracy_score(test_labels, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.5193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsOgJBcofpZN"
      },
      "source": [
        "## *Fine-tuning*\n",
        "\n",
        "A segunda estratÃ©gia Ã© chamada de *fine-tuning*, e Ã© comumente classificada como um estratÃ©gia de *transfer learning*, onde o aprendizado Ã© transferido entre datasets.\n",
        "Especificamente, esta estratÃ©gia, representada na figura abaixo, tenta usar um modelo prÃ©-treinado aprendido anteriormente em algum dataset (geralmente muito grande, como o [ImageNet](http://www.image-net.org/)) para classificar outro conjunto de dados diferentes (geralmente com poucas amostras).\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img width=600 src=\"https://drive.google.com/uc?export=view&id=1CoOfpMcQAEl9YAL0lgW11LLYpDcnL4dQ\">\n",
        "</p>\n",
        "\n",
        "Como esses dados podem possuir caracterÃ­sticas diferentes, treinamos a rede usando um *learning rate* pequeno, apenas para fazer pequenos ajustes nos pesos. Entretanto, como esses datasets geralmente tem nÃºmero e classes diferentes, a Ãºltima camada nÃ£o Ã© usada nessa transferÃªncia de peso e, geralmente, Ã© inicializada aleatoriamente (e por isso, tem um *learning rate* mais alto que as demais camadas).\n",
        "\n",
        "Por fim, Ã© um [fato conhecido](https://arxiv.org/pdf/1602.01517.pdf) que as redes neurais conseguem aprender caracterÃ­sticas de baixo nÃ­vel nas camadas iniciais. Geralmente, essas caracterÃ­sticas sÃ£o comuns Ã  vÃ¡rios datasets. Por isso, uma opÃ§Ã£o durante o processo de *fine-tuning* Ã© \"congelar\" as camadas iniciais (ou seja, nÃ£o treinÃ¡-las) e treinar somente as demais camadas com taxa de aprendizado bem pequeno (exceto pela camada de classificaÃ§Ã£o).\n",
        "\n",
        "No bloco de cÃ³digo abaixo, importamos a rede prÃ©-treinada [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), que foi treinada no dataset do [ImageNet](http://www.image-net.org/), que tem 1000 classes. Como iremos fazer *fine-tuning* nessa arquitetura para o dataset do [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html), que tem somente 10 classes, removeremos a Ãºltima camada e criaremos uma nova camada inicializada aleatoriamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hDGgIDhdG2z",
        "outputId": "61777eec-bff0-4563-e931-f0e9a101b357"
      },
      "source": [
        "# rede baseada na AlexNet \n",
        "net = torchvision.models.alexnet(pretrained=True)\n",
        "\n",
        "# Sending model to device\n",
        "net.to(device)\n",
        "\n",
        "print(summary(net,(3,227,227))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\n",
        "                                # and stored weights. \n",
        "\n",
        "num_ftrs = net.classifier[6].in_features\n",
        "net.classifier[6] = nn.Linear(num_ftrs,10) # Alterando a Ãºltima layer para retornar 10 classes ao invÃ©s de 1000\n",
        "\n",
        "# Sending model to device\n",
        "net.to(device)\n",
        "\n",
        "# Verifique no output a Ãºltima camada do classifier, podemos ver que sua saÃ­da Ã© 10\n",
        "print(net)\n",
        "\n",
        "# Podemos ver que este output mostra que apenas  40970 parÃ¢metros serÃ£o treinados. Ou seja, somente a Ãºltima camada\n",
        "print(summary(net,(3,227,227))) \n",
        "\n",
        "# Treinando a Ãºltima camada da rede acima\n",
        "# parÃ¢metros: nÃºmero de epochs, learning rate (ou taxa de aprendizado), \n",
        "# tamanho do batch, e lambda do weight decay\n",
        "num_epochs, lr, batch_size, wd_lambda = 20, 0.001, 100, 0.0001\n",
        "\n",
        "\n",
        "# funÃ§Ã£o de custo (ou loss)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# carregamento do dado: cifar 10\n",
        "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n",
        "\n",
        "# trainer\n",
        "trainer = optim.SGD([\n",
        "                {'params': net.features.parameters(), 'lr': lr * 0.1},\n",
        "                {'params': net.classifier[0:6].parameters(), 'lr': lr * 0.1},\n",
        "                {'params': net.classifier[6].parameters(), 'lr': lr}], weight_decay=wd_lambda, momentum=0.9)\n",
        "\n",
        "# treinamento e validaÃ§Ã£o via Pytorch\n",
        "train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n",
        "                num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
            "              ReLU-2           [-1, 64, 56, 56]               0\n",
            "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
            "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
            "              ReLU-5          [-1, 192, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-10          [-1, 256, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
            "          Dropout-15                 [-1, 9216]               0\n",
            "           Linear-16                 [-1, 4096]      37,752,832\n",
            "             ReLU-17                 [-1, 4096]               0\n",
            "          Dropout-18                 [-1, 4096]               0\n",
            "           Linear-19                 [-1, 4096]      16,781,312\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "           Linear-21                 [-1, 1000]       4,097,000\n",
            "================================================================\n",
            "Total params: 61,100,840\n",
            "Trainable params: 61,100,840\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 8.49\n",
            "Params size (MB): 233.08\n",
            "Estimated Total Size (MB): 242.16\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
            "              ReLU-2           [-1, 64, 56, 56]               0\n",
            "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
            "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
            "              ReLU-5          [-1, 192, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-10          [-1, 256, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
            "          Dropout-15                 [-1, 9216]               0\n",
            "           Linear-16                 [-1, 4096]      37,752,832\n",
            "             ReLU-17                 [-1, 4096]               0\n",
            "          Dropout-18                 [-1, 4096]               0\n",
            "           Linear-19                 [-1, 4096]      16,781,312\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "           Linear-21                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 57,044,810\n",
            "Trainable params: 57,044,810\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 8.48\n",
            "Params size (MB): 217.61\n",
            "Estimated Total Size (MB): 226.68\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "training on cuda\n",
            "epoch 1, train loss 0.9806, train acc 0.654, test loss 0.6364, test acc 0.776, time 84.2 sec\n",
            "epoch 2, train loss 0.6690, train acc 0.768, test loss 0.5465, test acc 0.809, time 84.4 sec\n",
            "epoch 3, train loss 0.5880, train acc 0.794, test loss 0.5182, test acc 0.818, time 84.2 sec\n",
            "epoch 4, train loss 0.5356, train acc 0.815, test loss 0.4531, test acc 0.844, time 84.3 sec\n",
            "epoch 5, train loss 0.5001, train acc 0.827, test loss 0.4471, test acc 0.847, time 84.5 sec\n",
            "epoch 6, train loss 0.4728, train acc 0.834, test loss 0.4193, test acc 0.855, time 84.3 sec\n",
            "epoch 7, train loss 0.4471, train acc 0.845, test loss 0.3970, test acc 0.860, time 84.6 sec\n",
            "epoch 8, train loss 0.4314, train acc 0.849, test loss 0.4118, test acc 0.856, time 84.6 sec\n",
            "epoch 9, train loss 0.4126, train acc 0.854, test loss 0.3848, test acc 0.864, time 84.8 sec\n",
            "epoch 10, train loss 0.3979, train acc 0.861, test loss 0.3758, test acc 0.870, time 84.8 sec\n",
            "epoch 11, train loss 0.3882, train acc 0.864, test loss 0.3794, test acc 0.866, time 84.6 sec\n",
            "epoch 12, train loss 0.3738, train acc 0.868, test loss 0.3636, test acc 0.870, time 84.4 sec\n",
            "epoch 13, train loss 0.3635, train acc 0.873, test loss 0.3448, test acc 0.877, time 84.7 sec\n",
            "epoch 14, train loss 0.3552, train acc 0.876, test loss 0.3551, test acc 0.874, time 84.1 sec\n",
            "epoch 15, train loss 0.3435, train acc 0.879, test loss 0.3383, test acc 0.881, time 84.4 sec\n",
            "epoch 16, train loss 0.3370, train acc 0.882, test loss 0.3313, test acc 0.885, time 84.0 sec\n",
            "epoch 17, train loss 0.3267, train acc 0.887, test loss 0.3287, test acc 0.883, time 83.9 sec\n",
            "epoch 18, train loss 0.3179, train acc 0.890, test loss 0.3288, test acc 0.883, time 83.9 sec\n",
            "epoch 19, train loss 0.3146, train acc 0.891, test loss 0.3229, test acc 0.887, time 83.9 sec\n",
            "epoch 20, train loss 0.3056, train acc 0.893, test loss 0.3206, test acc 0.886, time 83.9 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_uFa_Msi-EP"
      },
      "source": [
        "## PrÃ¡tica\n",
        "\n",
        "1. Ã‰ possÃ­vel melhorar o resultado obtido anteriormente?\n",
        "Estude o [model_zoo](https://pytorch.org/docs/stable/torchvision/models.html)  e tente usar as estratÃ©gias anteriores com diferentes redes neurais para melhorar o resultado.\n",
        "Algumas redes possÃ­veis:\n",
        "\n",
        "- [MobileNets](https://arxiv.org/abs/1801.04381)\n",
        "- [VGGs](https://arxiv.org/abs/1409.1556)\n",
        "- [ResNets](https://arxiv.org/abs/1603.05027)\n",
        "- [DenseNets](https://arxiv.org/pdf/1608.06993.pdf)\n",
        "\n",
        "2. Procure agora congelar algumas camadas para realizar o *fine-tuning*. Essa estratÃ©gia Ã© melhor quando se tem poucas imagens para fazer o *fine-tuning*.\n",
        "\n",
        "3. Procura usar outros algoritmos de aprendizado de mÃ¡quina (como [*random forest*](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) e [SVM-RBF](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)) para classificar *deep features* extraÃ­das de uma rede neural prÃ©-treinada.\n",
        "  1. Procure tambÃ©m extrair e classificar *features* de outras camadas convolucionais.\n",
        "\n",
        "4. Procure usar as diferentes estratÃ©gias para melhorar os resultados dos datasets que jÃ¡ usamos, como [MNIST](https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.MNIST) e [Fashion MNIST](https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.FashionMNIST)."
      ]
    }
  ]
}