{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_3_AlexNet_Reduced_Gabarito.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIolQ6y6Tjmr"
      },
      "source": [
        "\n",
        "# Prática: AlexNet com recursos limitados\n",
        "\n",
        "Se antes implementamos a [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) sem considerar a questão de quantidade de parâmetros, nesta prática focaremos nesse quesito.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUe7ps69Tmib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65dd9661-3ad2-4727-f302-cd91f6a836fd"
      },
      "source": [
        "import time, os, sys, numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch import optim\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "import time, os, sys, numpy as np\n",
        "\n",
        "# Test if GPU is avaliable, if not, use cpu instead\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "n = torch.cuda.device_count()\n",
        "devices_ids= list(range(n))\n",
        "print(device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE0X3AQzTsvK"
      },
      "source": [
        "def load_data_cifar10(batch_size, resize=None, root=os.path.join(\n",
        "        '~', '.pytorch', 'datasets', 'fashion-mnist')):\n",
        "    \"\"\"Download the Cifar10-MNIST dataset and then load into memory.\"\"\"\n",
        "    root = os.path.expanduser(root)\n",
        "    transformer = []\n",
        "    if resize:\n",
        "        transformer += [torchvision.transforms.Resize(resize)]\n",
        "    transformer += [torchvision.transforms.ToTensor()]\n",
        "    transformer = torchvision.transforms.Compose(transformer)\n",
        "\n",
        "    mnist_train = torchvision.datasets.CIFAR10(root=root, train=True,download=True,transform=transformer)\n",
        "    mnist_test = torchvision.datasets.CIFAR10(root=root, train=False,download=True,transform=transformer)\n",
        "    num_workers = 0 if sys.platform.startswith('win32') else 4\n",
        "\n",
        "    train_iter = torch.utils.data.DataLoader(mnist_train,\n",
        "                                  batch_size, shuffle=True,\n",
        "                                  num_workers=num_workers)\n",
        "    test_iter = torch.utils.data.DataLoader(mnist_test,\n",
        "                                 batch_size, shuffle=False,\n",
        "                                 num_workers=num_workers)\n",
        "    return train_iter, test_iter\n",
        "\n",
        "def load_data_fashion_mnist(batch_size, resize=None, root=os.path.join(\n",
        "        '~', '.pytorch', 'datasets', 'fashion-mnist')):\n",
        "    \"\"\"Download the Fashion-MNIST dataset and then load into memory.\"\"\"\n",
        "    root = os.path.expanduser(root)\n",
        "    transformer = []\n",
        "    if resize:\n",
        "        transformer += [torchvision.transforms.Resize(resize)]\n",
        "    transformer += [torchvision.transforms.ToTensor()]\n",
        "    transformer = torchvision.transforms.Compose(transformer)\n",
        "\n",
        "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True,download=True,transform=transformer)\n",
        "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False,download=True,transform=transformer)\n",
        "    num_workers = 0 if sys.platform.startswith('win32') else 4\n",
        "\n",
        "    train_iter = torch.utils.data.DataLoader(mnist_train,\n",
        "                                  batch_size, shuffle=True,\n",
        "                                  num_workers=num_workers)\n",
        "    test_iter = torch.utils.data.DataLoader(mnist_test,\n",
        "                                 batch_size, shuffle=False,\n",
        "                                 num_workers=num_workers)\n",
        "    return train_iter, test_iter\n",
        "\n",
        "# funções básicas\n",
        "def _get_batch(batch):\n",
        "    \"\"\"Return features and labels on ctx.\"\"\"\n",
        "    features, labels = batch\n",
        "    if labels.type() != features.type():\n",
        "        labels = labels.type(features.type())\n",
        "    return (torch.nn.DataParallel(features, device_ids=devices_ids),\n",
        "            torch.nn.DataParallel(labels, device_ids=devices_ids), features.shape[0])\n",
        "\n",
        "# Função usada para calcular acurácia\n",
        "def evaluate_accuracy(data_iter, net, loss):\n",
        "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
        "\n",
        "    acc_sum, n, l = torch.Tensor([0]), 0, 0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "      for X, y in data_iter:\n",
        "          #y = y.astype('float32')\n",
        "          X, y = X.to(device), y.to(device)\n",
        "          y_hat = net(X)\n",
        "          l += loss(y_hat, y).sum()\n",
        "          acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
        "          n += y.size()[0]\n",
        "\n",
        "    return acc_sum.item() / n, l.item() / len(data_iter)\n",
        "  \n",
        "# Função usada no treinamento e validação da rede\n",
        "def train_validate(net, train_iter, test_iter, batch_size, trainer, loss,\n",
        "                   num_epochs):\n",
        "    print('training on', device)\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
        "        for X, y in train_iter:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_hat = net(X)\n",
        "            trainer.zero_grad()\n",
        "            l = loss(y_hat, y).sum()\n",
        "            l.backward()\n",
        "            trainer.step()\n",
        "            train_l_sum += l.item()\n",
        "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
        "            n += y.size()[0]\n",
        "        test_acc, test_loss = evaluate_accuracy(test_iter, net, loss)\n",
        "        print('epoch %d, train loss %.4f, train acc %.3f, test loss %.4f, '\n",
        "              'test acc %.3f, time %.1f sec'\n",
        "              % (epoch + 1, train_l_sum / len(train_iter), train_acc_sum / n, test_loss, \n",
        "                 test_acc, time.time() - start))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYVw56ASTyHk"
      },
      "source": [
        "## AlexNet\n",
        "\n",
        "Como vimos, a rede [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) foi uma das arquiteturas mais famosas dessa nova onda de rede neurais.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img width=700 src=\"https://miro.medium.com/max/700/1*vXBvV_Unz3JAxytc5iSeoQ.png\">\n",
        "</p>\n",
        "\n",
        "Entretanto, ela possui muitos parâmetros.\n",
        "Especificamente, essa arquitetura, para classificar 10 classes, tem um total de **58.312.736** de parâmetros como mostrado na tabela abaixo.\n",
        "\n",
        "**Camada** | **Calc Parâmetros** | **Total Parâmetros**\n",
        "--- | ---: | ---:\n",
        "Convolução 1 | 11\\*11\\*3\\*96 | 34.848\n",
        "Convolução 2 | 5\\*5\\*96\\*256 | 614.400\n",
        "Convolução 3 | 3\\*3\\*256\\*384 | 884.736\n",
        "Convolução 4 | 3\\*3\\*384\\*384 | 1.327.104\n",
        "Convolução 5 | 3\\*3\\*384\\*256 | 884.736\n",
        "FC 6 | 9216*4096 | 37.748.736\n",
        "FC 7 | 4096*4096 | 16.777.216\n",
        "FC 8 | 4096*10 | 40.960\n",
        "**Total** | | **58.312.736**\n",
        "\n",
        "**Seu objetivo nessa prática é propor uma nova rede neural, baseada na [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), que possuia MENOS parâmetros e alcance uma acurácia similar ou melhor que a rede original vista na aula passada.**\n",
        "\n",
        "Procure usar [*batch normalization*](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html), camadas dilatadas e separáveis.\n",
        "Neste caso, desconsidere os parâmetros da camada [*batch normalization*](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3Aj2N9wkHE8"
      },
      "source": [
        "### Rede original para efeito de comparação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB2Oo6rvdgqp"
      },
      "source": [
        "class AlexNet(nn.Module):\r\n",
        "    def __init__(self, input_channels, classes=10, **kwargs):\r\n",
        "        super(AlexNet, self).__init__(**kwargs)\r\n",
        "        self.features = nn.Sequential(\r\n",
        "            nn.Conv2d(in_channels=input_channels, out_channels=96, kernel_size=11, stride=4, padding=0),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0),\r\n",
        "\r\n",
        "            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0),\r\n",
        "\r\n",
        "            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1),\r\n",
        "            nn.ReLU(),\r\n",
        "\r\n",
        "            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1),\r\n",
        "            nn.ReLU(),\r\n",
        "\r\n",
        "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\r\n",
        "        )\r\n",
        "\r\n",
        "        self.classifier = nn.Sequential(\r\n",
        "            nn.Flatten(),\r\n",
        "\r\n",
        "            nn.Linear(9216, 4096),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Dropout(0.5),\r\n",
        "\r\n",
        "            nn.Linear(4096, 4096),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Dropout(0.5),\r\n",
        "\r\n",
        "            nn.Linear(4096, classes)\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.features(x)\r\n",
        "        x = self.classifier(x)\r\n",
        "        return x"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByKaqWyBehxQ",
        "outputId": "3bfb8570-3fb7-4566-8943-cbadfc7c73ed"
      },
      "source": [
        "num_epochs, lr, batch_size, wd_lambda = 20, 0.001, 100, 0.0001\r\n",
        "\r\n",
        "net = AlexNet(3, 10)\r\n",
        "\r\n",
        "# Sending model to device\r\n",
        "net.to(device)\r\n",
        "print(summary(net,(3,227,227))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\r\n",
        "                                # and stored weights. \r\n",
        "\r\n",
        "# função de custo (ou loss)\r\n",
        "loss = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "# carregamento do dado: mnist\r\n",
        "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\r\n",
        "\r\n",
        "# trainer do gluon\r\n",
        "trainer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd_lambda)\r\n",
        "\r\n",
        "# treinamento e validação via Pytorch\r\n",
        "train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \r\n",
        "                num_epochs)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 55, 55]          34,944\n",
            "              ReLU-2           [-1, 96, 55, 55]               0\n",
            "         MaxPool2d-3           [-1, 96, 27, 27]               0\n",
            "            Conv2d-4          [-1, 256, 27, 27]         614,656\n",
            "              ReLU-5          [-1, 256, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 256, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         885,120\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 384, 13, 13]       1,327,488\n",
            "             ReLU-10          [-1, 384, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "          Flatten-14                 [-1, 9216]               0\n",
            "           Linear-15                 [-1, 4096]      37,752,832\n",
            "             ReLU-16                 [-1, 4096]               0\n",
            "          Dropout-17                 [-1, 4096]               0\n",
            "           Linear-18                 [-1, 4096]      16,781,312\n",
            "             ReLU-19                 [-1, 4096]               0\n",
            "          Dropout-20                 [-1, 4096]               0\n",
            "           Linear-21                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 58,322,314\n",
            "Trainable params: 58,322,314\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 11.11\n",
            "Params size (MB): 222.48\n",
            "Estimated Total Size (MB): 234.18\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "training on cuda\n",
            "epoch 1, train loss 1.9995, train acc 0.247, test loss 1.6608, test acc 0.385, time 92.1 sec\n",
            "epoch 2, train loss 1.5566, train acc 0.427, test loss 1.4259, test acc 0.473, time 92.1 sec\n",
            "epoch 3, train loss 1.3788, train acc 0.502, test loss 1.2590, test acc 0.547, time 92.2 sec\n",
            "epoch 4, train loss 1.2490, train acc 0.552, test loss 1.1405, test acc 0.595, time 92.3 sec\n",
            "epoch 5, train loss 1.1384, train acc 0.593, test loss 1.0679, test acc 0.622, time 91.8 sec\n",
            "epoch 6, train loss 1.0558, train acc 0.628, test loss 1.0135, test acc 0.646, time 92.0 sec\n",
            "epoch 7, train loss 0.9778, train acc 0.654, test loss 0.9917, test acc 0.655, time 91.8 sec\n",
            "epoch 8, train loss 0.9199, train acc 0.674, test loss 0.9409, test acc 0.667, time 91.8 sec\n",
            "epoch 9, train loss 0.8683, train acc 0.697, test loss 0.9345, test acc 0.678, time 91.5 sec\n",
            "epoch 10, train loss 0.8216, train acc 0.714, test loss 0.8946, test acc 0.689, time 91.5 sec\n",
            "epoch 11, train loss 0.7857, train acc 0.726, test loss 0.9312, test acc 0.680, time 92.1 sec\n",
            "epoch 12, train loss 0.7416, train acc 0.742, test loss 0.8685, test acc 0.699, time 91.8 sec\n",
            "epoch 13, train loss 0.7087, train acc 0.752, test loss 0.8866, test acc 0.697, time 92.3 sec\n",
            "epoch 14, train loss 0.6769, train acc 0.761, test loss 0.8813, test acc 0.699, time 91.6 sec\n",
            "epoch 15, train loss 0.6542, train acc 0.770, test loss 0.8705, test acc 0.703, time 92.1 sec\n",
            "epoch 16, train loss 0.6257, train acc 0.780, test loss 0.8911, test acc 0.706, time 91.6 sec\n",
            "epoch 17, train loss 0.6060, train acc 0.789, test loss 0.8816, test acc 0.710, time 91.9 sec\n",
            "epoch 18, train loss 0.5723, train acc 0.799, test loss 0.8914, test acc 0.714, time 92.0 sec\n",
            "epoch 19, train loss 0.5569, train acc 0.805, test loss 0.8953, test acc 0.706, time 92.8 sec\n",
            "epoch 20, train loss 0.5382, train acc 0.811, test loss 0.9188, test acc 0.701, time 93.4 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJEztWkKs1In"
      },
      "source": [
        "### Arquitetura 1\r\n",
        "\r\n",
        "Essa primeira versão da [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) usa [*batch normalization*](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html) para melhorar o resultado. Esse arquitetura é somente para efeitos de comparação já que, por enquanto, ainda temos a mesma quantidade de parâmetros da versão original."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfUkyoMOsTcU"
      },
      "source": [
        "class AlexNet(nn.Module):\r\n",
        "    def __init__(self, input_channels, classes=10, **kwargs):\r\n",
        "        super(AlexNet, self).__init__(**kwargs)\r\n",
        "        self.features = nn.Sequential(\r\n",
        "            nn.Conv2d(in_channels=input_channels, out_channels=96, kernel_size=11, stride=4, padding=0),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.BatchNorm2d(num_features=96),\r\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0),\r\n",
        "\r\n",
        "            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.BatchNorm2d(num_features=256),\r\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0),\r\n",
        "\r\n",
        "            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.BatchNorm2d(num_features=384),\r\n",
        "\r\n",
        "            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.BatchNorm2d(num_features=384),\r\n",
        "\r\n",
        "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.BatchNorm2d(num_features=256),\r\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\r\n",
        "        )\r\n",
        "\r\n",
        "        self.classifier = nn.Sequential(\r\n",
        "            nn.Flatten(),\r\n",
        "\r\n",
        "            nn.Linear(9216, 4096),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.BatchNorm1d(num_features=4096),\r\n",
        "            nn.Dropout(0.5),\r\n",
        "\r\n",
        "            nn.Linear(4096, 4096),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.BatchNorm1d(num_features=4096),\r\n",
        "            nn.Dropout(0.5),\r\n",
        "\r\n",
        "            nn.Linear(4096, classes)\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.features(x)\r\n",
        "        x = self.classifier(x)\r\n",
        "        return x"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpIEqaO2sVuh",
        "outputId": "15004be8-53da-4324-c059-3dd0c349622e"
      },
      "source": [
        "num_epochs, lr, batch_size, wd_lambda = 20, 0.001, 100, 0.0001\r\n",
        "\r\n",
        "net = AlexNet(3, 10)\r\n",
        "\r\n",
        "# Sending model to device\r\n",
        "net.to(device)\r\n",
        "print(summary(net,(3,227,227))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\r\n",
        "                                # and stored weights. \r\n",
        "\r\n",
        "# função de custo (ou loss)\r\n",
        "loss = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "# carregamento do dado: mnist\r\n",
        "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\r\n",
        "\r\n",
        "# trainer do gluon\r\n",
        "trainer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd_lambda)\r\n",
        "\r\n",
        "# treinamento e validação via Pytorch\r\n",
        "train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \r\n",
        "                num_epochs)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 55, 55]          34,944\n",
            "              ReLU-2           [-1, 96, 55, 55]               0\n",
            "       BatchNorm2d-3           [-1, 96, 55, 55]             192\n",
            "         MaxPool2d-4           [-1, 96, 27, 27]               0\n",
            "            Conv2d-5          [-1, 256, 27, 27]         614,656\n",
            "              ReLU-6          [-1, 256, 27, 27]               0\n",
            "       BatchNorm2d-7          [-1, 256, 27, 27]             512\n",
            "         MaxPool2d-8          [-1, 256, 13, 13]               0\n",
            "            Conv2d-9          [-1, 384, 13, 13]         885,120\n",
            "             ReLU-10          [-1, 384, 13, 13]               0\n",
            "      BatchNorm2d-11          [-1, 384, 13, 13]             768\n",
            "           Conv2d-12          [-1, 384, 13, 13]       1,327,488\n",
            "             ReLU-13          [-1, 384, 13, 13]               0\n",
            "      BatchNorm2d-14          [-1, 384, 13, 13]             768\n",
            "           Conv2d-15          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-16          [-1, 256, 13, 13]               0\n",
            "      BatchNorm2d-17          [-1, 256, 13, 13]             512\n",
            "        MaxPool2d-18            [-1, 256, 6, 6]               0\n",
            "          Flatten-19                 [-1, 9216]               0\n",
            "           Linear-20                 [-1, 4096]      37,752,832\n",
            "             ReLU-21                 [-1, 4096]               0\n",
            "      BatchNorm1d-22                 [-1, 4096]           8,192\n",
            "          Dropout-23                 [-1, 4096]               0\n",
            "           Linear-24                 [-1, 4096]      16,781,312\n",
            "             ReLU-25                 [-1, 4096]               0\n",
            "      BatchNorm1d-26                 [-1, 4096]           8,192\n",
            "          Dropout-27                 [-1, 4096]               0\n",
            "           Linear-28                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 58,341,450\n",
            "Trainable params: 58,341,450\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 16.13\n",
            "Params size (MB): 222.55\n",
            "Estimated Total Size (MB): 239.28\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "training on cuda\n",
            "epoch 1, train loss 1.8312, train acc 0.421, test loss 1.6312, test acc 0.464, time 97.5 sec\n",
            "epoch 2, train loss 1.5349, train acc 0.535, test loss 1.8795, test acc 0.433, time 97.6 sec\n",
            "epoch 3, train loss 1.4115, train acc 0.590, test loss 3.7439, test acc 0.569, time 97.7 sec\n",
            "epoch 4, train loss 1.3658, train acc 0.616, test loss 1.7238, test acc 0.585, time 97.4 sec\n",
            "epoch 5, train loss 1.1965, train acc 0.657, test loss 1.8943, test acc 0.617, time 97.3 sec\n",
            "epoch 6, train loss 1.1110, train acc 0.685, test loss 1.2236, test acc 0.666, time 97.7 sec\n",
            "epoch 7, train loss 1.0765, train acc 0.701, test loss 1.1200, test acc 0.685, time 97.3 sec\n",
            "epoch 8, train loss 1.0201, train acc 0.714, test loss 0.9428, test acc 0.741, time 97.1 sec\n",
            "epoch 9, train loss 1.1125, train acc 0.691, test loss 0.9165, test acc 0.732, time 97.5 sec\n",
            "epoch 10, train loss 0.9917, train acc 0.725, test loss 1.2072, test acc 0.706, time 97.2 sec\n",
            "epoch 11, train loss 1.0551, train acc 0.710, test loss 1.7279, test acc 0.705, time 97.6 sec\n",
            "epoch 12, train loss 0.8047, train acc 0.757, test loss 0.8602, test acc 0.763, time 97.2 sec\n",
            "epoch 13, train loss 0.7271, train acc 0.765, test loss 1.6154, test acc 0.738, time 97.3 sec\n",
            "epoch 14, train loss 0.6017, train acc 0.796, test loss 4.2194, test acc 0.749, time 97.5 sec\n",
            "epoch 15, train loss 0.5436, train acc 0.815, test loss 3.4914, test acc 0.760, time 97.5 sec\n",
            "epoch 16, train loss 0.5018, train acc 0.829, test loss 1.4015, test acc 0.797, time 97.4 sec\n",
            "epoch 17, train loss 0.4978, train acc 0.829, test loss 0.7991, test acc 0.757, time 97.2 sec\n",
            "epoch 18, train loss 0.4443, train acc 0.847, test loss 0.6971, test acc 0.805, time 97.6 sec\n",
            "epoch 19, train loss 0.4240, train acc 0.856, test loss 0.7316, test acc 0.765, time 97.3 sec\n",
            "epoch 20, train loss 0.4087, train acc 0.858, test loss 0.6288, test acc 0.798, time 97.9 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G7vYkuivJlB"
      },
      "source": [
        "### Arquitetura 2\r\n",
        "\r\n",
        "Essa segunda versão da [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) usa [*batch normalization*](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html) e camadas de [convolução dilatada](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.htmll).\r\n",
        "Neste caso, como usamos filtros dilatados em duas camadas (com dilatação aumentante, ou seja, dilatação 2 seguida da dilatação 4), foram removidos duas camadas convolucionais, já que o *receptive field* se mantem similar dessa forma.\r\n",
        "\r\n",
        "Nessa arquitetura, já temos menos parâmetros. Precisamente, temos \r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBB6rRTzvJSK"
      },
      "source": [
        "class AlexNet(nn.Module):\r\n",
        "    def __init__(self, input_channels, classes=10, **kwargs):\r\n",
        "        super(AlexNet, self).__init__(**kwargs)\r\n",
        "        self.features = nn.Sequential(\r\n",
        "            nn.Conv2d(in_channels=input_channels, out_channels=96, kernel_size=11, stride=4, padding=0),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.BatchNorm2d(num_features=96),\r\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0),\r\n",
        "\r\n",
        "            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2, dilation=2),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.BatchNorm2d(num_features=256),\r\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0),\r\n",
        "\r\n",
        "            # nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1),\r\n",
        "            # nn.ReLU(),\r\n",
        "            # nn.BatchNorm2d(num_features=384),\r\n",
        "\r\n",
        "            # nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1),\r\n",
        "            # nn.ReLU(),\r\n",
        "            # nn.BatchNorm2d(num_features=384),\r\n",
        "\r\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, dilation=4),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.BatchNorm2d(num_features=256),\r\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\r\n",
        "        )\r\n",
        "\r\n",
        "        self.classifier = nn.Sequential(\r\n",
        "            nn.Flatten(),\r\n",
        "\r\n",
        "            nn.Linear(1024, 4096),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.BatchNorm1d(num_features=4096),\r\n",
        "            nn.Dropout(0.5),\r\n",
        "\r\n",
        "            nn.Linear(4096, 4096),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.BatchNorm1d(num_features=4096),\r\n",
        "            nn.Dropout(0.5),\r\n",
        "\r\n",
        "            nn.Linear(4096, classes)\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.features(x)\r\n",
        "        x = self.classifier(x)\r\n",
        "        return x"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D20w3Yudvf0Q",
        "outputId": "89472659-91cc-44bb-8d73-8bdab5257508"
      },
      "source": [
        "num_epochs, lr, batch_size, wd_lambda = 20, 0.001, 100, 0.0001\r\n",
        "\r\n",
        "net = AlexNet(3, 10)\r\n",
        "\r\n",
        "# Sending model to device\r\n",
        "net.to(device)\r\n",
        "print(summary(net,(3,227,227))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\r\n",
        "                                # and stored weights. \r\n",
        "\r\n",
        "# função de custo (ou loss)\r\n",
        "loss = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "# carregamento do dado: mnist\r\n",
        "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\r\n",
        "\r\n",
        "# trainer do gluon\r\n",
        "trainer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd_lambda)\r\n",
        "\r\n",
        "# treinamento e validação via Pytorch\r\n",
        "train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \r\n",
        "                num_epochs)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 55, 55]          34,944\n",
            "              ReLU-2           [-1, 96, 55, 55]               0\n",
            "       BatchNorm2d-3           [-1, 96, 55, 55]             192\n",
            "         MaxPool2d-4           [-1, 96, 27, 27]               0\n",
            "            Conv2d-5          [-1, 256, 23, 23]         614,656\n",
            "              ReLU-6          [-1, 256, 23, 23]               0\n",
            "       BatchNorm2d-7          [-1, 256, 23, 23]             512\n",
            "         MaxPool2d-8          [-1, 256, 11, 11]               0\n",
            "            Conv2d-9            [-1, 256, 5, 5]         590,080\n",
            "             ReLU-10            [-1, 256, 5, 5]               0\n",
            "      BatchNorm2d-11            [-1, 256, 5, 5]             512\n",
            "        MaxPool2d-12            [-1, 256, 2, 2]               0\n",
            "          Flatten-13                 [-1, 1024]               0\n",
            "           Linear-14                 [-1, 4096]       4,198,400\n",
            "             ReLU-15                 [-1, 4096]               0\n",
            "      BatchNorm1d-16                 [-1, 4096]           8,192\n",
            "          Dropout-17                 [-1, 4096]               0\n",
            "           Linear-18                 [-1, 4096]      16,781,312\n",
            "             ReLU-19                 [-1, 4096]               0\n",
            "      BatchNorm1d-20                 [-1, 4096]           8,192\n",
            "          Dropout-21                 [-1, 4096]               0\n",
            "           Linear-22                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 22,277,962\n",
            "Trainable params: 22,277,962\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 10.93\n",
            "Params size (MB): 84.98\n",
            "Estimated Total Size (MB): 96.50\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "training on cuda\n",
            "epoch 1, train loss 1.6600, train acc 0.467, test loss 1.4030, test acc 0.546, time 98.8 sec\n",
            "epoch 2, train loss 1.2137, train acc 0.615, test loss 1.1222, test acc 0.612, time 99.2 sec\n",
            "epoch 3, train loss 0.9860, train acc 0.688, test loss 1.0605, test acc 0.678, time 99.2 sec\n",
            "epoch 4, train loss 0.8627, train acc 0.726, test loss 0.9006, test acc 0.709, time 98.0 sec\n",
            "epoch 5, train loss 0.6815, train acc 0.769, test loss 0.8443, test acc 0.726, time 97.3 sec\n",
            "epoch 6, train loss 0.5663, train acc 0.807, test loss 3.2595, test acc 0.727, time 97.1 sec\n",
            "epoch 7, train loss 0.4898, train acc 0.831, test loss 0.8398, test acc 0.746, time 96.6 sec\n",
            "epoch 8, train loss 0.4206, train acc 0.855, test loss 0.8171, test acc 0.754, time 96.4 sec\n",
            "epoch 9, train loss 0.3607, train acc 0.877, test loss 0.8848, test acc 0.732, time 95.9 sec\n",
            "epoch 10, train loss 0.3189, train acc 0.891, test loss 0.9928, test acc 0.724, time 96.4 sec\n",
            "epoch 11, train loss 0.2605, train acc 0.910, test loss 0.9701, test acc 0.733, time 96.3 sec\n",
            "epoch 12, train loss 0.2199, train acc 0.925, test loss 0.9351, test acc 0.748, time 96.1 sec\n",
            "epoch 13, train loss 0.2077, train acc 0.928, test loss 0.9760, test acc 0.754, time 96.1 sec\n",
            "epoch 14, train loss 0.1819, train acc 0.938, test loss 1.0235, test acc 0.741, time 96.2 sec\n",
            "epoch 15, train loss 0.1730, train acc 0.941, test loss 0.9771, test acc 0.746, time 96.2 sec\n",
            "epoch 16, train loss 0.1514, train acc 0.948, test loss 1.0424, test acc 0.741, time 96.0 sec\n",
            "epoch 17, train loss 0.1468, train acc 0.949, test loss 1.1505, test acc 0.711, time 96.0 sec\n",
            "epoch 18, train loss 0.1383, train acc 0.951, test loss 1.0512, test acc 0.746, time 96.0 sec\n",
            "epoch 19, train loss 0.1214, train acc 0.958, test loss 1.0535, test acc 0.757, time 96.1 sec\n",
            "epoch 20, train loss 0.1276, train acc 0.957, test loss 1.0608, test acc 0.754, time 96.1 sec\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}