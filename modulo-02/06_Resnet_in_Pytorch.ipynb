{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_Resnet in Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG-mVsVuE0if"
      },
      "source": [
        "# Preâmbulo\n",
        "\n",
        "Imports, funções, downloads e instalação do Pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEHmMCjR4PJw"
      },
      "source": [
        "# Basic imports.\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils import data\n",
        "from torch.backends import cudnn\n",
        "\n",
        "from torchvision import models\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "from skimage import io\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "cudnn.benchmark = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwhRUUlc4j23"
      },
      "source": [
        "# Setting predefined arguments.\n",
        "args = {\n",
        "    'epoch_num': 50,      # Number of epochs.\n",
        "    'n_classes': 10,      # Number of classes.\n",
        "    'lr': 1e-4,           # Learning rate.\n",
        "    'weight_decay': 5e-4, # L2 penalty.\n",
        "    'momentum': 0.9,      # Momentum.\n",
        "    'num_workers': 4,     # Number of workers on data loader.\n",
        "    'batch_size': 200,    # Mini-batch size.\n",
        "    'w_size': 224,        # Width size for image resizing.\n",
        "    'h_size': 224,        # Height size for image resizing.\n",
        "}\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    args['device'] = torch.device('cuda')\n",
        "else:\n",
        "    args['device'] = torch.device('cpu')\n",
        "\n",
        "print(args['device'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ura-BNFMcoTb"
      },
      "source": [
        "# Root directory for the dataset (to be downloaded).\n",
        "root = './'\n",
        "\n",
        "# Data Augmentation transforms.\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((100, 100)),\n",
        "    transforms.RandomCrop((75, 75)),\n",
        "    transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Setting datasets and dataloaders.\n",
        "train_set = datasets.CIFAR10(root,\n",
        "                             train=True,\n",
        "                             download=True,\n",
        "                             transform=data_transform)\n",
        "test_set = datasets.CIFAR10(root,\n",
        "                            train=False,\n",
        "                            download=False,\n",
        "                            transform=data_transform)\n",
        "    \n",
        "for iters in range(5):\n",
        "    \n",
        "    fig, ax = plt.subplots(1, 5, figsize=(20, 4))\n",
        "\n",
        "    for i, test_data in enumerate(test_set):\n",
        "\n",
        "        if i >= 5:\n",
        "            break\n",
        "    \n",
        "        test_img, _ = test_data\n",
        "\n",
        "        ax[i].imshow(test_img.numpy().transpose(1, 2, 0))\n",
        "        ax[i].set_yticks([])\n",
        "        ax[i].set_xticks([])\n",
        "        ax[i].set_title('Image ' + str(i))\n",
        "        \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi3Zh8fQ4X_3"
      },
      "source": [
        "# Root directory for the dataset (to be downloaded).\n",
        "root = './'\n",
        "\n",
        "# Setting transforms (resizing, conversion to tensor and normalizing).\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((args['h_size'], args['w_size'])),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Setting datasets and dataloaders.\n",
        "train_set = datasets.CIFAR10(root,\n",
        "                             train=True,\n",
        "                             download=True,\n",
        "                             transform=data_transform)\n",
        "test_set = datasets.CIFAR10(root,\n",
        "                            train=False,\n",
        "                            download=False,\n",
        "                            transform=data_transform)\n",
        "\n",
        "train_loader = DataLoader(train_set,\n",
        "                          args['batch_size'],\n",
        "                          num_workers=args['num_workers'],\n",
        "                          shuffle=True)\n",
        "test_loader = DataLoader(test_set,\n",
        "                         args['batch_size'],\n",
        "                         num_workers=args['num_workers'],\n",
        "                         shuffle=False)\n",
        "\n",
        "# Printing training and testing dataset sizes.\n",
        "print('Size of training set: ' + str(len(train_set)) + ' samples')\n",
        "print('Size of test set: ' + str(len(test_set)) + ' samples')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWKYCVh5oFtL"
      },
      "source": [
        "# Redes Residuais (ResNets)\n",
        "\n",
        "Entre 2012 e 2015 a comunidade de Visão Computacional percebeu que redes mais profundas conseguiam capturar características semânticas mais úteis dos dados para tarefas de reconhecimento de imagens (i.e. classificação, segmentação, detecção...). Porém, redes mais profundas que as maiores arquiteturas da época -- como a [VGG](https://arxiv.org/abs/1409.1556) e a [Inception](https://arxiv.org/abs/1409.4842) -- sofriam de um problema chamado **Vanishing Gradient**.\n",
        "\n",
        "![VGG](https://www.researchgate.net/profile/Clifford_Yang/publication/325137356/figure/fig2/AS:670371271413777@1536840374533/llustration-of-the-network-architecture-of-VGG-19-model-conv-means-convolution-FC-means_W640.jpg)\n",
        "\n",
        "![Inception](https://miro.medium.com/max/700/1*uW81y16b-ptBDV8SIT1beQ.png)\n",
        "\n",
        "\n",
        "O **Vanishing Gradient** se torna mais problemático em redes mais profundas porque o gradiente dos erros precisa backpropagar desde a última camada até o começo da rede. Dessa forma, as últimas camadas conseguem ser treinadas de forma eficiente, mas o gradiente dos erros vai desaparecendo à medida em que backpropaga pela rede, praticamente impossibilitando o treinamento das primeiras camadas. Assim, foi constatado que uma rede com, por exemplo, 34 camadas acabava por conseguir resultados piores que uma rede com apenas 18 camadas.\n",
        "\n",
        "![Rede Não Residual](https://www.dropbox.com/s/pq190al5b3qv194/normal_18_vs_34_layers.png?dl=1)\n",
        "\n",
        "No final de 2015 foi proposta uma solução para o **Vanishing Gradient** na forma de **Blocos Residuais** que, juntos, formam **Redes Residuais** [**(ResNets)**](https://arxiv.org/abs/1512.03385). Esses blocos residuais recebem uma entrada $x$ e a alimentam para um bloco convolucional ($\\mathcal{F}(x)$) composto por:\n",
        "\n",
        "1.   Convolução 3x3;\n",
        "2.   Batch Normalization;\n",
        "3.   ReLU;\n",
        "4.   Convolução 3x3;\n",
        "5.   Batch Normalization.\n",
        "\n",
        "A saída $\\mathcal{F}(x)$ desse bloco, antes de ser passada por uma segunda ReLU, é passada em conjunto com a entrada $x$ para uma função identidade, que, no caso das **ResNets**, é uma simples soma. Dessa forma, a saída final de um **Bloco Residual** é dada por: $\\mathcal{F}(x) + x$. O esquema de um **Bloco Residual** pode ser visto na figura abaixo.\n",
        "\n",
        "![Bloco Residual](https://www.dropbox.com/s/ezydump33p95ohc/residual_block.png?dl=1)\n",
        "\n",
        "Como pode ser visto na imagem a seguir, com o uso de blocos residuais, uma arquitetura com 34 camadas consegue resultados melhores que uma arquitetura com apenas 18 camadas. Esses resultados evidenciam que o uso da soma como **identity function** de fato permite que o backward treine mais efetivamente as primeiras camadas das **ResNets**. **ResNets** permitiram que CNNs chegassem até a casa das 100 camadas. A maior **ResNet** usada na prática possui 152 camadas, o que a deixa impraticável de imprimir numa figura como é mostrado abaixo na ResNet34.\n",
        "\n",
        "![Rede Residual](https://www.dropbox.com/s/q4wcjwf8qj4xjrn/resnet_18_vs_34_layers.png?dl=1)\n",
        "\n",
        "Como pode ser visto nas imagens abaixo, ResNets (e outras arquiteturas modernas como a [VGG](https://arxiv.org/abs/1409.1556) e as [DenseNets](https://arxiv.org/abs/1608.06993) são compostas basicamente de convoluções com kernels de tamanho 3x3. Além disso, é notável na arquitetura residual (à direita) a presença dos \"atalhos\" para o gradiente  na forma das funções identidade que ajudam no treinamento das primeiras camadas durante o backpropagation.\n",
        "\n",
        "![VGG vs. Plain34 vs. ResNet34](https://www.dropbox.com/s/d2w3h7dlumgclx2/vgg_plain34_resnet34.png?dl=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHotK0b3hqpG"
      },
      "source": [
        "# Atividade Prática\n",
        "\n",
        "1.   Implementar a classe *ResidualBlock()*. Devem ser implementados os"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25PD5HF-8XxD"
      },
      "source": [
        "# Implementation of residual block to be reused.\n",
        "class ResidualBlock(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_planes, out_planes):\n",
        "        \n",
        "        super(ResidualBlock, self).__init__()\n",
        "        \n",
        "        # TO DO: define first and second convolutional blocks.\n",
        "        \n",
        "        # If in_planes != out_planes, perform a 1x1 conv to match #channels.\n",
        "        self.conv1x1 = None\n",
        "        if in_planes != out_planes:\n",
        "            self.conv1x1 = # TO DO: define 1x1 convolution.\n",
        "            \n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        identity = x\n",
        "\n",
        "        # TO DO: forward on first conv block.\n",
        "        \n",
        "        # TO DO: forward on second conv block. (don't forget the 1x1 conv to match the number of channels)\n",
        "        \n",
        "        # TO DO: return output.\n",
        "\n",
        "# ResNet18 implementation.\n",
        "class ResNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_classes=10):\n",
        "\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        # TO DO: define first convolutional block:\n",
        "        #        1. conv with 7x7 kernel, 64 output channels, stride of 2,\n",
        "        #           padding of 3 and with no bias;\n",
        "        #        2. 2d batch normalization;\n",
        "        #        3. ReLU;\n",
        "        #        4. 2d max pool with 3x3 kernel, stride of 2 and padding of 1.\n",
        "\n",
        "\n",
        "        # TO DO: define first residual block + pooling:\n",
        "        #        1. instantiate residual block from class ResidualBlock with\n",
        "        #           number of output channels equal to 64;\n",
        "        #        2. 2d max pool with 3x3 kernel, stride of 2 and padding of 1.\n",
        "        \n",
        "        \n",
        "        # TO DO: define second residual block + pooling:\n",
        "        #        1. instantiate residual block from class ResidualBlock with\n",
        "        #           number of output channels equal to 128;\n",
        "        #        2. 2d max pool with 3x3 kernel, stride of 2 and padding of 1.\n",
        "        \n",
        "        # TO DO: define classifier:\n",
        "        #        1. define an nn.AdaptiveAvgPool2d(output_size(1, 1))\n",
        "        #        2. define FC classification layer with 10 outputs.\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "        \n",
        "        self.classifier = nn.Linear(128, num_classes)\n",
        "        \n",
        "        self.initialize_weights()\n",
        "    \n",
        "    # Function for randomly initializing weights.\n",
        "    def initialize_weights(self):\n",
        "        \n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight,\n",
        "                                        mode='fan_out',\n",
        "                                        nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "                \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # TO DO: forward on first conv block.\n",
        "        \n",
        "        # TO DO: forward on first residual block.\n",
        "        \n",
        "        # TO DO: forward on second residual block.\n",
        "        \n",
        "        # TO DO: forward on adaptive_pool.\n",
        "        \n",
        "        # TO DO: linearizing tensor to serve as input to FC layer.\n",
        "        \n",
        "        # TO DO: obtain 10 predictions (one for each class) on FC layer.\n",
        "        \n",
        "        # TO DO: return output.\n",
        "\n",
        "# Instantiating architecture.\n",
        "net = ResNet(args['n_classes']).to(args['device'])\n",
        "\n",
        "# Printing architecture.\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpNtOtd6bHDg"
      },
      "source": [
        "# Using predefined and pretrained model of ResNet18 on torchvision.\n",
        "# net = models.resnet18(pretrained=True, progress=False).to(args['device'])\n",
        "# net.fc = nn.Linear(in_features=512, out_features=10, bias=True).to(args['device'])\n",
        "\n",
        "# Shrunk version of ResNet18 to be used in class.\n",
        "# net = models.resnet18(pretrained=True, progress=False).to(args['device'])\n",
        "# net.layer3 = nn.Sequential().to(args['device']) # Uncomment to shrink ResNet.\n",
        "# net.layer4 = nn.Sequential().to(args['device']) # Uncomment to shrink ResNet.\n",
        "# net.fc = nn.Linear(in_features=128, out_features=10, bias=True).to(args['device'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS2l_pqAI0F2"
      },
      "source": [
        "# Definindo o otimizador\n",
        "\n",
        "O Pytorch possui vários otimizadores prontos no subpacote [optim](https://pytorch.org/docs/stable/optim.html), desde o SGD básico a otimizadores mais complexos e com taxas de aprendizado por parâmetro como o Adagrad, RMSProp e Adam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_-RN1wH-4bB"
      },
      "source": [
        "optimizer = optim.Adam(net.parameters(),\n",
        "                       lr=args['lr'],\n",
        "                       betas=(args['momentum'], 0.999),\n",
        "                       weight_decay=args['weight_decay'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVhOWUkWKU4f"
      },
      "source": [
        "# Definindo a loss\n",
        "\n",
        "O subpacote [nn](https://pytorch.org/docs/stable/nn.html) possui várias funções de perda para diferentes tarefas (i.e. Cross Entropy, Negative Log Likelihood, loss L1, MSE, Kullback Leibler Divergence, etc) implementadas por padrão.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX_bmN3__LIK"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss().to(args['device'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXhZakGZK_kU"
      },
      "source": [
        "# Criando funções para Treino e Teste\n",
        "\n",
        "Iterando sobre os datasets/dataloaders de treino e teste do CIFAR10. Abaixo são implementadas a função *train()* que itera sobre os batches do dataset de treino e atualiza o modelo e a função *test()* que apenas realiza o forward dos dados de teste no modelo e calcula a acurácia no dataset de teste para o modelo no estado atual."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCU5Gx9D_6xW"
      },
      "source": [
        "def train(train_loader, net, criterion, optimizer, epoch):\n",
        "\n",
        "    tic = time.time()\n",
        "    \n",
        "    # Setting network for training mode.\n",
        "    net.train()\n",
        "\n",
        "    # Lists for losses and metrics.\n",
        "    train_loss = []\n",
        "    \n",
        "    # Iterating over batches.\n",
        "    for i, batch_data in enumerate(train_loader):\n",
        "\n",
        "        # Obtaining images, labels and paths for batch.\n",
        "        inps, labs = batch_data\n",
        "        \n",
        "        # Casting to cuda variables.\n",
        "        inps = inps.to(args['device'])\n",
        "        labs = labs.to(args['device'])\n",
        "        \n",
        "        # Clears the gradients of optimizer.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forwarding.\n",
        "        outs = net(inps)\n",
        "\n",
        "        # Computing loss.\n",
        "        loss = criterion(outs, labs)\n",
        "\n",
        "        # Computing backpropagation.\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Updating lists.\n",
        "        train_loss.append(loss.data.item())\n",
        "    \n",
        "    toc = time.time()\n",
        "    \n",
        "    train_loss = np.asarray(train_loss)\n",
        "    \n",
        "    # Printing training epoch loss and metrics.\n",
        "    print('--------------------------------------------------------------------')\n",
        "    print('[epoch %d], [train loss %.4f +/- %.4f], [training time %.2f]' % (\n",
        "        epoch, train_loss.mean(), train_loss.std(), (toc - tic)))\n",
        "    print('--------------------------------------------------------------------')\n",
        "    \n",
        "def test(test_loader, net, criterion, epoch):\n",
        "\n",
        "    tic = time.time()\n",
        "    \n",
        "    # Setting network for evaluation mode (not computing gradients).\n",
        "    net.eval()\n",
        "\n",
        "    # Lists for losses and metrics.\n",
        "    test_loss = []\n",
        "    prd_list = []\n",
        "    lab_list = []\n",
        "    \n",
        "    # Iterating over batches.\n",
        "    for i, batch_data in enumerate(train_loader):\n",
        "\n",
        "        # Obtaining images, labels and paths for batch.\n",
        "        inps, labs = batch_data\n",
        "\n",
        "        # Casting to cuda variables.\n",
        "        inps = inps.to(args['device'])\n",
        "        labs = labs.to(args['device'])\n",
        "\n",
        "        # Forwarding.\n",
        "        outs = net(inps)\n",
        "\n",
        "        # Computing loss.\n",
        "        loss = criterion(outs, labs)\n",
        "        \n",
        "        # Obtaining predictions.\n",
        "        prds = outs.data.max(dim=1)[1].cpu().numpy()\n",
        "        \n",
        "        # Updating lists.\n",
        "        test_loss.append(loss.data.item())\n",
        "        prd_list.append(prds)\n",
        "        lab_list.append(labs.detach().cpu().numpy())\n",
        "    \n",
        "    toc = time.time()\n",
        "    \n",
        "    # Computing accuracy.\n",
        "    acc = metrics.accuracy_score(np.asarray(lab_list).ravel(),\n",
        "                                 np.asarray(prd_list).ravel())\n",
        "    \n",
        "    test_loss = np.asarray(test_loss)\n",
        "    \n",
        "    # Printing training epoch loss and metrics.\n",
        "    print('--------------------------------------------------------------------')\n",
        "    print('[epoch %d], [test loss %.4f +/- %.4f], [acc %.4f], [testing time %.2f]' % (\n",
        "        epoch, test_loss.mean(), test_loss.std(), acc, (toc - tic)))\n",
        "    print('--------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ijo07bsTMFMs"
      },
      "source": [
        "# Iterando sobre epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU2aYIob_zTu"
      },
      "source": [
        "# Iterating over epochs.\n",
        "for epoch in range(1, args['epoch_num'] + 1):\n",
        "\n",
        "    # Training function.\n",
        "    train(train_loader, net, criterion, optimizer, epoch)\n",
        "\n",
        "    # Computing test loss and metrics.\n",
        "    test(test_loader, net, criterion, epoch)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}