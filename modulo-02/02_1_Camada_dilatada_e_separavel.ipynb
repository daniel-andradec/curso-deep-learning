{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_1_Camada_dilatada_e_separavel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4f98a119b56347f0b6507cc4f17cbdb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ac09743b02b4482aa669eb4532bf080c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_de15ccf2a208435e932cae0513f58a83",
              "IPY_MODEL_b591011763ac45d8b58170bb07b3d14e"
            ]
          }
        },
        "ac09743b02b4482aa669eb4532bf080c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de15ccf2a208435e932cae0513f58a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_efa650b5c8a34c7e85be9ee9c1e7801d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fe6aa21a949f471f95d0fe5401acd59f"
          }
        },
        "b591011763ac45d8b58170bb07b3d14e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5c96474ef9ad46afbee8fd541d21717a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 26427392/? [00:20&lt;00:00, 10813466.41it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1344d6457f3747b5bd8e301c508d5a76"
          }
        },
        "efa650b5c8a34c7e85be9ee9c1e7801d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fe6aa21a949f471f95d0fe5401acd59f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c96474ef9ad46afbee8fd541d21717a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1344d6457f3747b5bd8e301c508d5a76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "066e53e03c0f4853bbf31ef371ee5481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_979a94c4af4646b3bd75dab48f2118ca",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8b0dd833dd9c4fcbbf00260f40e06aad",
              "IPY_MODEL_3b29bd16158e48fcb1a436183be5ca5b"
            ]
          }
        },
        "979a94c4af4646b3bd75dab48f2118ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b0dd833dd9c4fcbbf00260f40e06aad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a3bf12b1a1e34b7ebd5830543859a72e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ed1bdbedb21c441d992737260baa545f"
          }
        },
        "3b29bd16158e48fcb1a436183be5ca5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6e740503d57f4d06bce2e43f7f675657",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 32768/? [00:02&lt;00:00, 15785.24it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d5e3ffcec87a4e9393cea645080f3e63"
          }
        },
        "a3bf12b1a1e34b7ebd5830543859a72e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ed1bdbedb21c441d992737260baa545f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6e740503d57f4d06bce2e43f7f675657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d5e3ffcec87a4e9393cea645080f3e63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5075c71ab400490a82d9ef38852d7101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dee46293e2c3441abff6bada87ffc27d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_64250143bb5d4047a0614d8119eacb31",
              "IPY_MODEL_363ebf9d372d4425822a55d013181994"
            ]
          }
        },
        "dee46293e2c3441abff6bada87ffc27d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64250143bb5d4047a0614d8119eacb31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8c40f2c086224305a3af5240b51284cd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1ac177ef115c4c20954ed66aa4ec4257"
          }
        },
        "363ebf9d372d4425822a55d013181994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2db72b74256648979624c524d4fddbb3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4423680/? [00:01&lt;00:00, 2610358.16it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_05eb1081bcdb4515831db8f7649e4666"
          }
        },
        "8c40f2c086224305a3af5240b51284cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1ac177ef115c4c20954ed66aa4ec4257": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2db72b74256648979624c524d4fddbb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "05eb1081bcdb4515831db8f7649e4666": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cae0ef027714421485b4dbfbd4b96f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3c4caf0d429c4413a4541835f7e21a8b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_43c9061c05bb4e5fa497560908541609",
              "IPY_MODEL_d8cd4e3a54be44928b90393305f9d87e"
            ]
          }
        },
        "3c4caf0d429c4413a4541835f7e21a8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43c9061c05bb4e5fa497560908541609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_429b0ed14a6b4bfbb5a412058d573f9c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_64d26bd877e648458b96955cf415c6ec"
          }
        },
        "d8cd4e3a54be44928b90393305f9d87e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4ca3e939294f4d2db516a012c4d4699e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8192/? [00:00&lt;00:00, 16091.61it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_52d77e90be9f42518b9123116465592f"
          }
        },
        "429b0ed14a6b4bfbb5a412058d573f9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "64d26bd877e648458b96955cf415c6ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ca3e939294f4d2db516a012c4d4699e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "52d77e90be9f42518b9123116465592f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT4cwsIl3pFL"
      },
      "source": [
        "# Outras Camadas Convolucionais\n",
        "\n",
        "AlÃ©m das camadas convolucionais padrÃµes, algumas outras surgiram tentando melhorar alguns quesitos da convoluÃ§Ã£o tradicional.\n",
        "\n",
        "Entre elas estÃ£o:\n",
        "\n",
        "- [convoluÃ§Ã£o dilatada](https://arxiv.org/abs/1511.07122) (*dilated convolution*), que permite que o filtro convolucional tenha *buracos* aumentando o *receptive field* mas mantendo a resoluÃ§Ã£o da imagem, e \n",
        "- [convoluÃ§Ã£o separÃ¡vel por canal](https://arxiv.org/abs/1704.04861) (*depthwise separable convolution*), que, de acordo com a literatura, alcanÃ§a resultados similares ao da convoluÃ§Ã£o padrÃ£o porÃ©m usando menos parÃ¢metros (por isso, sÃ£o mais rÃ¡pidas)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y2OZ2LW44JO"
      },
      "source": [
        "import time, os, sys, numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch import optim\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "import time, os, sys, numpy as np\n",
        "\n",
        "# Test if GPU is avaliable, if not, use cpu instead\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "n = torch.cuda.device_count()\n",
        "devices_ids= list(range(n))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "125j0Pz145zN"
      },
      "source": [
        "def load_data_cifar10(batch_size, resize=None, root=os.path.join(\n",
        "        '~', '.pytorch', 'datasets', 'fashion-mnist')):\n",
        "    \"\"\"Download the Cifar10-MNIST dataset and then load into memory.\"\"\"\n",
        "    root = os.path.expanduser(root)\n",
        "    transformer = []\n",
        "    if resize:\n",
        "        transformer += [torchvision.transforms.Resize(resize)]\n",
        "    transformer += [torchvision.transforms.ToTensor()]\n",
        "    transformer = torchvision.transforms.Compose(transformer)\n",
        "\n",
        "    mnist_train = torchvision.datasets.CIFAR10(root=root, train=True,download=True,transform=transformer)\n",
        "    mnist_test = torchvision.datasets.CIFAR10(root=root, train=False,download=True,transform=transformer)\n",
        "    num_workers = 0 if sys.platform.startswith('win32') else 4\n",
        "\n",
        "\n",
        "\n",
        "    train_iter = torch.utils.data.DataLoader(mnist_train,\n",
        "                                  batch_size, shuffle=True,\n",
        "                                  num_workers=num_workers)\n",
        "    test_iter = torch.utils.data.DataLoader(mnist_test,\n",
        "                                 batch_size, shuffle=False,\n",
        "                                 num_workers=num_workers)\n",
        "    return train_iter, test_iter\n",
        "\n",
        "def load_data_fashion_mnist(batch_size, resize=None, root=os.path.join(\n",
        "        '~', '.pytorch', 'datasets', 'fashion-mnist')):\n",
        "    \"\"\"Download the Fashion-MNIST dataset and then load into memory.\"\"\"\n",
        "    root = os.path.expanduser(root)\n",
        "    transformer = []\n",
        "    if resize:\n",
        "        transformer += [torchvision.transforms.Resize(resize)]\n",
        "    transformer += [torchvision.transforms.ToTensor()]\n",
        "    transformer = torchvision.transforms.Compose(transformer)\n",
        "\n",
        "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True,download=True,transform=transformer)\n",
        "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False,download=True,transform=transformer)\n",
        "    num_workers = 0 if sys.platform.startswith('win32') else 4\n",
        "\n",
        "\n",
        "\n",
        "    train_iter = torch.utils.data.DataLoader(mnist_train,\n",
        "                                  batch_size, shuffle=True,\n",
        "                                  num_workers=num_workers)\n",
        "    test_iter = torch.utils.data.DataLoader(mnist_test,\n",
        "                                 batch_size, shuffle=False,\n",
        "                                 num_workers=num_workers)\n",
        "    return train_iter, test_iter\n",
        "\n",
        "# funÃ§Ãµes bÃ¡sicas\n",
        "def _get_batch(batch):\n",
        "    \"\"\"Return features and labels on ctx.\"\"\"\n",
        "    features, labels = batch\n",
        "    if labels.type() != features.type():\n",
        "        labels = labels.type(features.type())\n",
        "    return (torch.nn.DataParallel(features, device_ids=devices_ids),\n",
        "            torch.nn.DataParallel(labels, device_ids=devices_ids), features.shape[0])\n",
        "\n",
        "# FunÃ§Ã£o usada para calcular acurÃ¡cia\n",
        "def evaluate_accuracy(data_iter, net, loss):\n",
        "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
        "\n",
        "    acc_sum, n, l = torch.Tensor([0]), 0, 0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "      for X, y in data_iter:\n",
        "          #y = y.astype('float32')\n",
        "          X, y = X.to(device), y.to(device)\n",
        "          y_hat = net(X)\n",
        "          l += loss(y_hat, y).sum()\n",
        "          acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
        "          n += y.size()[0]\n",
        "\n",
        "    return acc_sum.item() / n, l.item() / len(data_iter)\n",
        "  \n",
        "# FunÃ§Ã£o usada no treinamento e validaÃ§Ã£o da rede\n",
        "def train_validate(net, train_iter, test_iter, batch_size, trainer, loss,\n",
        "                   num_epochs):\n",
        "    print('training on', device)\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
        "        for X, y in train_iter:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_hat = net(X)\n",
        "            trainer.zero_grad()\n",
        "            l = loss(y_hat, y).sum()\n",
        "            l.backward()\n",
        "            trainer.step()\n",
        "            train_l_sum += l.item()\n",
        "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
        "            n += y.size()[0]\n",
        "        test_acc, test_loss = evaluate_accuracy(test_iter, net, loss)\n",
        "        print('epoch %d, train loss %.4f, train acc %.3f, test loss %.4f, '\n",
        "              'test acc %.3f, time %.1f sec'\n",
        "              % (epoch + 1, train_l_sum / len(train_iter), train_acc_sum / n, test_loss, \n",
        "                 test_acc, time.time() - start))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkvT5yvj57ff"
      },
      "source": [
        "## Convolucional Dilatada (*Dilated Convolution*)\n",
        "\n",
        "Nas camadas convolucionais dilatadas, os pesos do filtro sÃ£o empregados de maneira diferente quando comparados Ã s convoluÃ§Ãµes padrÃ£o.\n",
        "Especificamente, os filtros dessa camada nÃ£o precisam ser contÃ­guos e podem ter lacunas (ou \"buracos\") entre seus parÃ¢metros.\n",
        "Essas lacunas, inseridas de acordo com a taxa de dilataÃ§Ã£o $r \\in \\mathbb{N}$, que permite um aumento do tamanho do filtro convolucional, preservando o nÃºmero de parÃ¢metros treinÃ¡veis, uma vez que os buracos inseridos nÃ£o sÃ£o considerados no processo de convoluÃ§Ã£o.\n",
        "Portanto, esta taxa de dilataÃ§Ã£o $ r $ pode ser vista como um parÃ¢metro responsÃ¡vel por definir o alinhamento final dos pesos.\n",
        "\n",
        "Formalmente, uma convoluÃ§Ã£o dilatada 2-D recebe uma entrada em duas dimensÃµes $ Y $, uma taxa de dilataÃ§Ã£o $ R $ e um vetor de peso 2-D $ W $ (neste caso, com tamanho $ n \\times n $) e processos eles dessa forma: \n",
        "\n",
        "$$ Y[k, l] = \\sum_{i=1}^{n} \\sum_{j=1}^{n} X(k + r \\times i, l + r \\times j) K(i,j) $$\n",
        ", onde $Y$ Ã© a saÃ­da ou *feature map*.\n",
        "Observe as diferenÃ§as entre a dilataÃ§Ã£o e a convoluÃ§Ã£o padrÃ£o apresentadas na aula anterior.\n",
        "\n",
        "O efeito da taxa de dilataÃ§Ã£o diferente $ r $ Ã© apresentado na figura abaixo.\n",
        "Como pode ser visto, taxas menores resultam em um filtro mais clusterizado (na verdade, a taxa 1 gera um filtro idÃªntico Ã  convoluÃ§Ã£o padrÃ£o) enquanto as taxas maiores fazem uma expansÃ£o do filtro, produzindo um kernel maior com vÃ¡rios buracos.\n",
        "Como todo esse processo de dilataÃ§Ã£o do filtro Ã© independente dos dados de entrada, alterar a taxa de dilataÃ§Ã£o nÃ£o afeta a resoluÃ§Ã£o do resultado, ou seja, em uma convoluÃ§Ã£o dilatada, independente da taxa, a entrada e a saÃ­da tÃªm a mesma resoluÃ§Ã£o (considerando, claro, o efeito do *padding* e do *stride*).\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1HixSXbx3HKWUrcCqJ8d-IF-RTykoT2Pz\">\n",
        "</p>\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://cdn-images-1.medium.com/max/800/0*oX5IPr7TlVM2NpEU.gif\">\n",
        "  <img src=\"https://cdn-images-1.medium.com/max/800/0*3cTXIemm0k3Sbask.gif\">\n",
        "</p>\n",
        "\n",
        "Ao ampliar o filtro (com essas lacunas), a rede expande seu campo receptivo (jÃ¡ que os pesos serÃ£o organizados em uma forma mais esparsa), mas preserva a resoluÃ§Ã£o e nenhuma reduÃ§Ã£o de resoluÃ§Ã£o nos dados Ã© executada.\n",
        "Portanto, esse processo tem vÃ¡rias vantagens, como:\n",
        "(i) suporta a expansÃ£o do campo receptivo sem aumentar o nÃºmero de parÃ¢metros treinÃ¡veis por camada, o que reduz a carga computacional, e\n",
        "(ii) preserva a resoluÃ§Ã£o do mapa de caracterÃ­sticas, o que pode ajudar a rede a extrair informaÃ§Ãµes ainda mais Ãºteis dos dados, principalmente de pequenos objetos.\n",
        "\n",
        "### Campo Receptivo (*Receptive Field*)\n",
        "\n",
        "O campo receptivo Ã© definido como a regiÃ£o no espaÃ§o de entrada que tem influÃªncia sobre a saÃ­da atual da rede convolucional.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://miro.medium.com/max/1000/1*mModSYik9cD9XJNemdTraw.png\">\n",
        "</p>\n",
        "\n",
        "### ImplementaÃ§Ã£o\n",
        "\n",
        "No Pytorch, a [camada convoluÃ§Ã£o padrÃ£o](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d) tem suporte para dilataÃ§Ã£o dos filtros de acordo com o parÃ¢metro *dilation*.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRZAhVA947KE"
      },
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self, input_channels, classes=10, **kwargs):\n",
        "        super(LeNet, self).__init__(**kwargs)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=6, kernel_size=5, stride=1, padding=0)\n",
        "        self.avgpool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, dilation=3)\n",
        "        # self.avgpool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        # self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1, padding=0)\n",
        "        self.flatten  = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(64, 84)\n",
        "        self.fc2 = nn.Linear(84, classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        output_conv1 = F.tanh(self.conv1(x))\n",
        "        output_avgpool1 = self.avgpool1(output_conv1)\n",
        "        output_conv2 = F.tanh(self.conv2(output_avgpool1))\n",
        "        # output_avgpool2 = self.avgpool2(output_conv2)\n",
        "        # output_conv3 = F.tanh(self.conv3(output_avgpool2))\n",
        "        flatten_output = self.flatten(output_conv2)\n",
        "        output_fc1 = F.tanh(self.fc1(flatten_output))\n",
        "        output = self.fc2(output_fc1)\n",
        "\n",
        "        return output "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJoGUPx7_0V4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4bf219a-5779-4220-b51f-3cbd593065dc"
      },
      "source": [
        "# parÃ¢metros: nÃºmero de epochs, learning rate (ou taxa de aprendizado), \n",
        "# tamanho do batch, e lambda do weight decay\n",
        "num_epochs, lr, batch_size, wd_lambda = 10, 0.1, 128, 0.000001\n",
        "\n",
        "\n",
        "# rede baseada na AlexNet-5 \n",
        "net = LeNet(1, 10)\n",
        "\n",
        "# Sending model to device\n",
        "net.to(device)\n",
        "print(summary(net,(1,32,32))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\n",
        "                                # and stored weights. \n",
        "\n",
        "# funÃ§Ã£o de custo (ou loss)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# carregamento do dado: mnist\n",
        "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=32)\n",
        "\n",
        "# trainer do gluon\n",
        "trainer = optim.SGD(net.parameters(), lr=lr, weight_decay=wd_lambda, momentum=0.9)\n",
        "\n",
        "# treinamento e validaÃ§Ã£o via Pytorch\n",
        "train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n",
        "                num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 6, 28, 28]             156\n",
            "         AvgPool2d-2            [-1, 6, 14, 14]               0\n",
            "            Conv2d-3             [-1, 16, 2, 2]           2,416\n",
            "           Flatten-4                   [-1, 64]               0\n",
            "            Linear-5                   [-1, 84]           5,460\n",
            "            Linear-6                   [-1, 10]             850\n",
            "================================================================\n",
            "Total params: 8,882\n",
            "Trainable params: 8,882\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.05\n",
            "Params size (MB): 0.03\n",
            "Estimated Total Size (MB): 0.08\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "training on cuda\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1, train loss 0.5977, train acc 0.780, test loss 0.4687, test acc 0.826, time 8.7 sec\n",
            "epoch 2, train loss 0.4035, train acc 0.854, test loss 0.4263, test acc 0.843, time 8.7 sec\n",
            "epoch 3, train loss 0.3740, train acc 0.864, test loss 0.4107, test acc 0.851, time 9.2 sec\n",
            "epoch 4, train loss 0.3496, train acc 0.872, test loss 0.3977, test acc 0.853, time 8.9 sec\n",
            "epoch 5, train loss 0.3364, train acc 0.875, test loss 0.3938, test acc 0.859, time 8.4 sec\n",
            "epoch 6, train loss 0.3338, train acc 0.877, test loss 0.3652, test acc 0.868, time 8.8 sec\n",
            "epoch 7, train loss 0.3225, train acc 0.879, test loss 0.3815, test acc 0.856, time 8.9 sec\n",
            "epoch 8, train loss 0.3176, train acc 0.881, test loss 0.3932, test acc 0.851, time 8.8 sec\n",
            "epoch 9, train loss 0.3090, train acc 0.884, test loss 0.3575, test acc 0.874, time 9.4 sec\n",
            "epoch 10, train loss 0.3050, train acc 0.885, test loss 0.3568, test acc 0.871, time 9.0 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTY9u26LFWAn"
      },
      "source": [
        "Para efeito de **comparaÃ§Ã£o**, recriamos a rede sem as duas camadas convolucionais (removidas na arquitetura anterior) e sem camadas dilatadas. Dessa forma, podemos observar o ganho das convoluÃ§Ãµes dilatadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KduV4haLAGNH"
      },
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self, input_channels, classes=10, **kwargs):\n",
        "        super(LeNet, self).__init__(**kwargs)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=input_channels,out_channels=6, kernel_size=5, stride=1, padding=0)\n",
        "        self.avgpool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
        "        self.avgpool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1, padding=0)\n",
        "        self.flatten  = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(120, 84)\n",
        "        self.fc2 = nn.Linear(84, classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        output_conv1 = F.tanh(self.conv1(x))\n",
        "        output_avgpool1 = self.avgpool1(output_conv1)\n",
        "        output_conv2 = F.tanh(self.conv2(output_avgpool1))\n",
        "        output_avgpool2 = self.avgpool2(output_conv2)\n",
        "        output_conv3 = F.tanh(self.conv3(output_avgpool2))\n",
        "        flatten_output = self.flatten(output_conv3)\n",
        "        output_fc1 = F.tanh(self.fc1(flatten_output))\n",
        "        output = self.fc2(output_fc1)\n",
        "\n",
        "        return output "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ePkwQp-Fh55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff7c7dcb-74fc-4037-a1ac-b8c69df88336"
      },
      "source": [
        "# parÃ¢metros: nÃºmero de epochs, learning rate (ou taxa de aprendizado), \n",
        "# tamanho do batch, e lambda do weight decay\n",
        "num_epochs, lr, batch_size, wd_lambda = 10, 0.1, 128, 0.000001\n",
        "\n",
        "\n",
        "# rede baseada na AlexNet-5 \n",
        "net = LeNet(1, 10)\n",
        "\n",
        "# Sending model to device\n",
        "net.to(device)\n",
        "print(summary(net,(1,32,32))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\n",
        "                                # and stored weights. \n",
        "\n",
        "# funÃ§Ã£o de custo (ou loss)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# carregamento do dado: mnist\n",
        "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=32)\n",
        "\n",
        "# trainer do gluon\n",
        "trainer = optim.SGD(net.parameters(), lr=lr, weight_decay=wd_lambda, momentum=0.9)\n",
        "\n",
        "# treinamento e validaÃ§Ã£o via Pytorch\n",
        "train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n",
        "                num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 6, 28, 28]             156\n",
            "         AvgPool2d-2            [-1, 6, 14, 14]               0\n",
            "            Conv2d-3           [-1, 16, 10, 10]           2,416\n",
            "         AvgPool2d-4             [-1, 16, 5, 5]               0\n",
            "            Conv2d-5            [-1, 120, 1, 1]          48,120\n",
            "           Flatten-6                  [-1, 120]               0\n",
            "            Linear-7                   [-1, 84]          10,164\n",
            "            Linear-8                   [-1, 10]             850\n",
            "================================================================\n",
            "Total params: 61,706\n",
            "Trainable params: 61,706\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.06\n",
            "Params size (MB): 0.24\n",
            "Estimated Total Size (MB): 0.30\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "training on cuda\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1, train loss 0.6267, train acc 0.763, test loss 0.4404, test acc 0.843, time 8.7 sec\n",
            "epoch 2, train loss 0.3904, train acc 0.855, test loss 0.3763, test acc 0.862, time 8.9 sec\n",
            "epoch 3, train loss 0.3527, train acc 0.869, test loss 0.3716, test acc 0.859, time 8.8 sec\n",
            "epoch 4, train loss 0.3239, train acc 0.881, test loss 0.3807, test acc 0.857, time 8.9 sec\n",
            "epoch 5, train loss 0.3029, train acc 0.887, test loss 0.3615, test acc 0.869, time 9.1 sec\n",
            "epoch 6, train loss 0.2868, train acc 0.894, test loss 0.3199, test acc 0.886, time 8.7 sec\n",
            "epoch 7, train loss 0.2670, train acc 0.902, test loss 0.3185, test acc 0.882, time 8.8 sec\n",
            "epoch 8, train loss 0.2594, train acc 0.904, test loss 0.3179, test acc 0.890, time 9.2 sec\n",
            "epoch 9, train loss 0.2470, train acc 0.907, test loss 0.3216, test acc 0.886, time 9.0 sec\n",
            "epoch 10, train loss 0.2392, train acc 0.911, test loss 0.3300, test acc 0.885, time 9.0 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udS_9i9MGu5T"
      },
      "source": [
        "A acurÃ¡cia atingida no teste Ã© praticamente a mesma para os dois modelos. No entanto, na rede com dilation o nÃºmero de parÃ¢metros Ã© quase 4 vezes menor, sendo assim, uma probabilidade menor de acontecer um overfitt. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfAUBwZiGWsM"
      },
      "source": [
        "## ConvoluÃ§Ã£o SeparÃ¡vel por Canal (*Depthwise Separable Convolution*)\n",
        "\n",
        "ApÃ³s o resurgimento das redes neurais, a cada nova arquitetura proposta, mais e mais camadas e parÃ¢metros foram sendo usados. Por exemplo, a primeira arquitetura dessa nova onda, a [AlexNet](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwi6usf1sqXjAhWFGLkGHXhPBC4QFjAAegQIAhAC&url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf&usg=AOvVaw2hqjjvSjIpuuCLLdojAmS5), tem **61.100.840** de parÃ¢metros.\n",
        "\n",
        "Claramente, pelo tamanho de parÃ¢metros, arquitetura como essas nÃ£o sÃ£o passÃ­veis de serem treinadas em dispositivos com menos memÃ³ria, como sistema embarcados, celulares, tablets, etc.\n",
        "Por isso, uma linha de pesquisa procura otimizar o uso dos parÃ¢metros em rede neurais.\n",
        "Para esse fim, essa linha de pesquisa propÃ´s uma nova camada, chamada ConvoluÃ§Ã£o SeparÃ¡vel por Canal (*Depthwise Separable Convolution*), que Ã© capaz de reproduzir arquiteturas convolucionais, obtendo resultados similar, porÃ©m com menos parÃ¢metros.\n",
        "\n",
        "A ideia por trÃ¡s dessa camada Ã© representada abaixo. Ao invÃ©s de ter uma Ãºnica camada de convoluÃ§Ã£o que processarÃ¡ toda a entrada (ou seja, terÃ¡ parÃ¢metros para todos os canais de entrada), essa convoluÃ§Ã£o Ã© dividida em duas partes. Na primeira parte, cada canal Ã© processado separadamente por um filtro especÃ­fico. Formalmente, suponha que a entrada tenha $c_i$ canais.\n",
        "Nesse caso, a primeira parte de convoluÃ§Ã£o terÃ¡  $c_i$ filtros de tamanho $k\\times k$, onde cada um desses filtros processarÃ¡ somente um canal da entrada, gerando $c_i$ *feature maps* de saÃ­da. Na segunda parte, esses *feature maps* serÃ£o processados por uma convoluÃ§Ã£o $1\\times 1$, que gerarÃ¡ a saÃ­da final esperada. Suponha que queiramos que essa camada gere $c_o$ canais de saÃ­da. Essa segunda parte terÃ¡ $c_o$ filtros de $1\\times 1$ que processarÃ£o os *feature maps* gerados na primeira parte, gerando a saÃ­da final com $c_o$ canais.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://cdn-images-1.medium.com/max/800/1*Voah8cvrs7gnTDf6acRvDw.png\">\n",
        "</p>\n",
        "\n",
        "Vamos examinar a diferenÃ§a entre a convoluÃ§Ã£o padrÃ£o e a convoluÃ§Ã£o separÃ¡vel por canal em termos de nÃºmero de parÃ¢metros. Suponha que:\n",
        "\n",
        "- n, seja a dimensÃ£o espacial (largura e altura), da entrada,\n",
        "- k, seja largura e altura do filtro,\n",
        "- c_i, seja o nÃºmero de canais de entrada, e\n",
        "- c_o, o nÃºmero de canais de saÃ­da.\n",
        "\n",
        "Uma convoluÃ§Ã£o regular tem k * k * c_i * c_o parÃ¢metros, porque, para cada canal de saÃ­da, hÃ¡ um filtro $k\\times k$ para cada canal de entrada.\n",
        "Em contrapartida, as convoluÃ§Ãµes separÃ¡veis por canal tem k * k * c_i parÃ¢metros na primeira parte e, em seguida,  1 * 1 * c_i * c_o parÃ¢metros para a segunda parte. Deve ser Ã³bvio que, para um c_o nÃ£o trivial, a soma desses dois Ã© significativamente menor que k * k * c_i * c_o.\n",
        "\n",
        "Agora, vamos comparar o custo computacional. Para uma convoluÃ§Ã£o regular, realizamos K * K * c_i operaÃ§Ãµes em cada posiÃ§Ã£o da entrada (para calcular a convoluÃ§Ã£o 2D em 3 dimensÃµes). Para toda a entrada, o nÃºmero de cÃ¡lculos Ã©, portanto, k * k * c_i * n * n e tomando todos os canais de saÃ­da, obtemos k * k * c_i * n * n * c_o.\n",
        "Para convoluÃ§Ãµes separÃ¡veis em profundidade, precisamos de operaÃ§Ãµes k * k * c_i * n * n para a parte de profundidade; entÃ£o precisamos de n * n * c_i * c_o operaÃ§Ãµes para a parte de mistura. \n",
        "\n",
        "Vamos usar alguns nÃºmeros reais para sentir a diferenÃ§a.\n",
        "Assumiremos \n",
        "\n",
        "- n = 128, \n",
        "- k = 3, \n",
        "- c_i = 3, \n",
        "- c_o = 16. \n",
        "\n",
        "Para convoluÃ§Ã£o regular:\n",
        "\n",
        "     ParÃ¢metros: 3 * 3 * 3 * 16 = 432\n",
        "     Custo de computaÃ§Ã£o: 3 * 3 * 3 * 128 * 128 * 16 = ~ 7e6\n",
        "\n",
        "Para a convoluÃ§Ã£o separÃ¡vel em profundidade:\n",
        "\n",
        "     ParÃ¢metros: 3 * 3 * 3 + 3 * 16 = 75\n",
        "     Custo de computaÃ§Ã£o: 3 * 3 * 3 * 128 * 128 + 128 * 128 * 3 * 16 = ~ 1.2e6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D33G5ucaGZUf"
      },
      "source": [
        "Frameworks modernos implementam esse tipo de camada de forma diferente. No Pytorch, nosso caso de estudo, a primeira parte dessa convoluÃ§Ã£o Ã© feita quando se coloca o [nÃºmero de grupos da camada convolucional igual ao nÃºmero de canais de entrada](https://github.com/apache/incubator-mxnet/issues/10142#issuecomment-373895855). Esse [parÃ¢metro](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d) Ã© usado para definir o agrupamento entre canais de entrada e filtros/neurÃ´nios. Logo, quando se tem um nÃºmero de canais de entrada igual ao nÃºmero de filtros, e tambÃ©m igual ao nÃºmero de grupos. Dessa forma, cada filtro processarÃ¡ somente um canal.\n",
        "\n",
        "JÃ¡ a segunda parte dessa convoluÃ§Ã£o Ã© feita naturalmente, usando o *kernel*=1.\n",
        "\n",
        "Abaixo, implementamos a LeNet-5 usando essa convoluÃ§Ã£o.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img width=700 src=\"https://cdn-images-1.medium.com/max/800/1*gNzz6vvWmF6tDN6pTRTd9g.jpeg\">\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwj2n_kxFjmI"
      },
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self,input_channels, classes=10, **kwargs):\n",
        "        super(LeNet, self).__init__(**kwargs)\n",
        "        self.conv1_1 = nn.Conv2d(in_channels=input_channels, out_channels=1, kernel_size=5, stride=1, padding=0, groups=1)\n",
        "        self.conv1_2 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=1, stride=1, padding=0)\n",
        "        self.avgpool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv2_1 = nn.Conv2d(in_channels=6, out_channels=6, kernel_size=5, stride=1, padding=0, groups=6)\n",
        "        self.conv2_2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=1, stride=1, padding=0)\n",
        "        self.avgpool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv3_1 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=5, stride=1, padding=0, groups=16)\n",
        "        self.conv3_2 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(120,84)\n",
        "        self.fc2 = nn.Linear(84,classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print('x', x.shape)\n",
        "        output_conv1_1 = self.conv1_1(x)\n",
        "        # print('conv1_1', x.shape)\n",
        "        output_conv1_2 = F.tanh(self.conv1_2(output_conv1_1))\n",
        "        # print('conv1_2', x.shape)\n",
        "        output_avgpool1 = self.avgpool1(output_conv1_2)\n",
        "        output_conv2_1 = self.conv2_1(output_avgpool1)\n",
        "        # print('conv2_1', x.shape)\n",
        "        output_conv2_2 = F.tanh(self.conv2_2(output_conv2_1))\n",
        "        # print('conv2_2', x.shape)\n",
        "        output_avgpool2 = self.avgpool2(output_conv2_2)\n",
        "        output_conv3_1 = self.conv3_1(output_avgpool2)\n",
        "        # print('conv3_1', x.shape)\n",
        "        output_conv3_2 = F.tanh(self.conv3_2(output_conv3_1))\n",
        "        # print('conv3_2', x.shape)\n",
        "        output_flatten = self.flatten(output_conv3_2)\n",
        "        output_fc1 = F.tanh(self.fc1(output_flatten))\n",
        "        output = self.fc2(output_fc1)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsDktcegK2YS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4f98a119b56347f0b6507cc4f17cbdb8",
            "ac09743b02b4482aa669eb4532bf080c",
            "de15ccf2a208435e932cae0513f58a83",
            "b591011763ac45d8b58170bb07b3d14e",
            "efa650b5c8a34c7e85be9ee9c1e7801d",
            "fe6aa21a949f471f95d0fe5401acd59f",
            "5c96474ef9ad46afbee8fd541d21717a",
            "1344d6457f3747b5bd8e301c508d5a76",
            "066e53e03c0f4853bbf31ef371ee5481",
            "979a94c4af4646b3bd75dab48f2118ca",
            "8b0dd833dd9c4fcbbf00260f40e06aad",
            "3b29bd16158e48fcb1a436183be5ca5b",
            "a3bf12b1a1e34b7ebd5830543859a72e",
            "ed1bdbedb21c441d992737260baa545f",
            "6e740503d57f4d06bce2e43f7f675657",
            "d5e3ffcec87a4e9393cea645080f3e63",
            "5075c71ab400490a82d9ef38852d7101",
            "dee46293e2c3441abff6bada87ffc27d",
            "64250143bb5d4047a0614d8119eacb31",
            "363ebf9d372d4425822a55d013181994",
            "8c40f2c086224305a3af5240b51284cd",
            "1ac177ef115c4c20954ed66aa4ec4257",
            "2db72b74256648979624c524d4fddbb3",
            "05eb1081bcdb4515831db8f7649e4666",
            "cae0ef027714421485b4dbfbd4b96f8c",
            "3c4caf0d429c4413a4541835f7e21a8b",
            "43c9061c05bb4e5fa497560908541609",
            "d8cd4e3a54be44928b90393305f9d87e",
            "429b0ed14a6b4bfbb5a412058d573f9c",
            "64d26bd877e648458b96955cf415c6ec",
            "4ca3e939294f4d2db516a012c4d4699e",
            "52d77e90be9f42518b9123116465592f"
          ]
        },
        "outputId": "6913e383-f98a-46a6-99f6-afc46d82654a"
      },
      "source": [
        "# parÃ¢metros: nÃºmero de epochs, learning rate (ou taxa de aprendizado), \n",
        "# tamanho do batch, e lambda do weight decay\n",
        "num_epochs, lr, batch_size, wd_lambda = 10, 0.01, 128, 0.000001\n",
        "\n",
        "# rede\n",
        "net = LeNet(1, 10)\n",
        "\n",
        "# Sending model to device\n",
        "net.to(device)\n",
        "print(summary(net,(1,32,32))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\n",
        "                                # and stored weights. \n",
        "\n",
        "# funÃ§Ã£o de custo (ou loss)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# carregamento do dado: mnist\n",
        "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=32)\n",
        "\n",
        "# trainer do gluon\n",
        "trainer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd_lambda)\n",
        "\n",
        "# treinamento e validaÃ§Ã£o via Pytorch\n",
        "train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n",
        "                num_epochs)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 1, 28, 28]              26\n",
            "            Conv2d-2            [-1, 6, 28, 28]              12\n",
            "         AvgPool2d-3            [-1, 6, 14, 14]               0\n",
            "            Conv2d-4            [-1, 6, 10, 10]             156\n",
            "            Conv2d-5           [-1, 16, 10, 10]             112\n",
            "         AvgPool2d-6             [-1, 16, 5, 5]               0\n",
            "            Conv2d-7             [-1, 16, 1, 1]             416\n",
            "            Conv2d-8            [-1, 120, 1, 1]           2,040\n",
            "           Flatten-9                  [-1, 120]               0\n",
            "           Linear-10                   [-1, 84]          10,164\n",
            "           Linear-11                   [-1, 10]             850\n",
            "================================================================\n",
            "Total params: 13,776\n",
            "Trainable params: 13,776\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.07\n",
            "Params size (MB): 0.05\n",
            "Estimated Total Size (MB): 0.13\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /root/.pytorch/datasets/fashion-mnist/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f98a119b56347f0b6507cc4f17cbdb8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/datasets/fashion-mnist/FashionMNIST/raw/train-images-idx3-ubyte.gz to /root/.pytorch/datasets/fashion-mnist/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /root/.pytorch/datasets/fashion-mnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "066e53e03c0f4853bbf31ef371ee5481",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/datasets/fashion-mnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /root/.pytorch/datasets/fashion-mnist/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /root/.pytorch/datasets/fashion-mnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5075c71ab400490a82d9ef38852d7101",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/datasets/fashion-mnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /root/.pytorch/datasets/fashion-mnist/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /root/.pytorch/datasets/fashion-mnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cae0ef027714421485b4dbfbd4b96f8c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/datasets/fashion-mnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.pytorch/datasets/fashion-mnist/FashionMNIST/raw\n",
            "Processing...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Done!\n",
            "training on cpu\n",
            "epoch 1, train loss 0.7170, train acc 0.723, test loss 0.6055, test acc 0.768, time 33.6 sec\n",
            "epoch 2, train loss 0.4949, train acc 0.814, test loss 0.4820, test acc 0.826, time 34.4 sec\n",
            "epoch 3, train loss 0.4623, train acc 0.828, test loss 0.4811, test acc 0.822, time 33.8 sec\n",
            "epoch 4, train loss 0.4400, train acc 0.837, test loss 0.4640, test acc 0.832, time 34.1 sec\n",
            "epoch 5, train loss 0.4333, train acc 0.839, test loss 0.4748, test acc 0.822, time 33.6 sec\n",
            "epoch 6, train loss 0.4303, train acc 0.842, test loss 0.4700, test acc 0.832, time 34.2 sec\n",
            "epoch 7, train loss 0.4226, train acc 0.845, test loss 0.4519, test acc 0.835, time 34.0 sec\n",
            "epoch 8, train loss 0.4199, train acc 0.846, test loss 0.4375, test acc 0.838, time 33.9 sec\n",
            "epoch 9, train loss 0.4146, train acc 0.847, test loss 0.4417, test acc 0.838, time 32.9 sec\n",
            "epoch 10, train loss 0.4103, train acc 0.849, test loss 0.4429, test acc 0.834, time 33.5 sec\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}