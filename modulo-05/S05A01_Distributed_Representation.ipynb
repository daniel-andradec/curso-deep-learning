{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "S05A01_Distributed_Representation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIlDh2MDNKvn"
      },
      "source": [
        "# Preâmbulo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjtSfzBqNKvs"
      },
      "source": [
        "!wget https://www.dropbox.com/s/f8k3xoywff0h3br/questions-words.csv\r\n",
        "!pip install torchtext==0.8.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddcqq2C_NKvt"
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "### LIB DE TEXTO DO PYTORCH\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2sTmjvbNKvt"
      },
      "source": [
        "## Analogias\n",
        "\n",
        "Uma forma intrínseca de avaliar a qualidade de um modelo de linguagem é realizar as chamadas analogias a partir das **representações distribuídas** gerada pelo modelo.\n",
        "\n",
        "Analogias são associações de mesma natureza entre palavras (como flexões de gênero ou número). A geometria dessas associações pode ser visualizada no espaço vetorial onde as palavras são projetadas e, em modelos bem treinados, deve ser possível encontrar semelhanças entre associações de mesma natureza.\n",
        "<img width=600 src=\"https://vecto.space/assets/img/queen.png\">\n",
        "\n",
        "Vamos trabalhar com um popular conjunto de validação através do método de analogias. Ele consiste em pares de associações, onde o primeiro par deve ser usado como referência para completar o segundo par. No exemplo a seguir, Brasil é a palavra que deve ser inferida a partir das três palavras marcadas em negrito. \n",
        "> **Buenos Aires** está para **Argentina** assim como **Brasília** está para <span style=\"color:red\"><u>**Brasil**</u></span>\n",
        "    \n",
        "Na prática, essa é a composição do conjunto `questions-words` para validação de modelos de linguagem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqCJ0i1hNKvu"
      },
      "source": [
        "df = pd.read_csv('questions-words.csv')\n",
        "display(df.head(10))\n",
        "display(df.tail(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIRziM3YNKvv"
      },
      "source": [
        "## Torchtext\n",
        "Documentação: https://pytorch.org/text/0.8.1/\n",
        "\n",
        "Similar ao `torchvision` para imagens, o pacote torchtext facilita o trabalho com dados textuais. Em sua documentação é possível explorar toda a sua gama de possibilidades, entre modelos pré-treinados, métricas, ferramentas, datasets, etc.\n",
        "\n",
        "Aqui vamos conhecer dois elementos importantes para o carregamento de dados.\n",
        "\n",
        "\n",
        "### Field\n",
        "\n",
        "Objeto que carrega informações de como os dados devem ser processados. A seguir temos a assinatura da sua classe com alguns exemplos de parâmetros que podemos controlar. \n",
        "\n",
        "```python\n",
        "torchtext.data.Field(dtype=torch.int64, preprocessing=None, lower=False, tokenize=None, tokenizer_language='en', include_lengths=False, batch_first=False, stop_words=None, is_target=False)\n",
        "```\n",
        "\n",
        "No nosso caso, ambos entrada e saída são sequências de caracteres que passarão pelo mesmo pré-processamento:\n",
        "* `tokenize`: Separação em **tokens**. Por padrão o Field realiza a tokenização `string.split`\n",
        "    * Ex: \"Bom dia Brasil!\" $\\rightarrow$ `[\"Bom\", \"dia\", \"Brasil\", \"!\"]` <br><br>\n",
        "    \n",
        "* `lower`: Conversão para letras minúsculas, assim evitamos duplicidade de palavras (Atenas $\\neq$ atenas).\n",
        "\n",
        "\n",
        "### TabularDataset\n",
        "\n",
        "É simples carregar dados tabulares utilizando a classe `TabularDataset`. Basta informar:\n",
        "* `path`: O caminho do sistema onde o arquivo se encontra <br><br>\n",
        "* `format`: A formatação do arquivo (csv, tsv, json) <br><br>\n",
        "* `fields`: Lista de tuplas `(nome, Field)` representando respectivamente o nome associado a cada coluna da sua tabela e o pré-processamento que os dados devem receber. <br><br>\n",
        "* `skip_header`: Se o seu arquivo possui uma linha de cabeçalho, você pode removê-la definindo esse parâmetro como `True`.\n",
        "\n",
        "```python\n",
        "torchtext.data.TabularDataset(path, format, fields, skip_header=False)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih62HgicNKvv"
      },
      "source": [
        "INPUT  = data.Field(lower = True)\n",
        "TARGET = data.Field(lower = True)\n",
        "\n",
        "dataset = data.TabularDataset('questions-words.csv', format='csv',\n",
        "                                           fields=[('input', INPUT), ('target',TARGET)],\n",
        "                                           skip_header=True\n",
        "                                        )\n",
        "\n",
        "for k, sample in enumerate(dataset):\n",
        "    if k % 1000 == 0:\n",
        "        print(k, vars(sample))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zdk0MwLNKvv"
      },
      "source": [
        "## Representando os dados como Tensores\n",
        "\n",
        "Para transformar palavras em dados numéricos, uma solução muito utilizada é mapeá-las em um dicionário contendo o vocabulário completo do conjunto. \n",
        "\n",
        "<img src=\"https://static.packt-cdn.com/products/9781786465825/graphics/B05525_03_01.jpg\" width=\"500\">\n",
        "\n",
        "A depender da quantidade de palavras em seu vocabulário, uma representação *One-Hot* pode ser computacionalmente inviável. Por isso utilizamos as **representações distribuídas**, associando vetores densos a cada palavra de nosso dicionário de modo que esse espaço vetorial aproxime palavras que costumam aparecer no mesmo contexto.\n",
        "\n",
        "Vamos explorar algumas maneiras de transformar palavras em representações distribuídas. A principal é a partir de **modelos de linguagem pré-treinados**. Através do pacote `torchtext` é possível consultar todos os modelos ali disponíveis.\n",
        "\n",
        "Algumas nomenclaturas comuns são:\n",
        "\n",
        "* charngram.**100d**: Indica que a representação desse modelo possui 100 dimensões. <br>\n",
        "* glove.**6B**.300d: Indica que o modelo foi treinado com 6 Bilhões de tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf9xab1XNKvw"
      },
      "source": [
        "torchtext.vocab.pretrained_aliases.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7zTQlUZNKvw"
      },
      "source": [
        "Vamos explorar por exemplo o modelo `glove.6B.100d`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngPZ-P87NKvw"
      },
      "source": [
        "glove = torchtext.vocab.GloVe(name='6B', dim=100)\n",
        "print(\"\\nUm total de %d tokens são mapeados por esse modelo.\"% len(glove.stoi))\n",
        "print(\"Os 10 primeiros tokens são\", glove.itos[:10])\n",
        "print(\"A dimensionalidade da matriz de representação é:\", glove.vectors.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMFR2bX2NKvw"
      },
      "source": [
        "Usando o objeto do tipo `Field` podemos **construir um vocabulário** contendo somente as palavras (e vetores) relevantes para o nosso problema."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrMjPPCyNKvx"
      },
      "source": [
        "MAX_VOCAB_SIZE=1000\n",
        "INPUT.build_vocab(dataset, \n",
        "                  max_size=MAX_VOCAB_SIZE,\n",
        "                  vectors='glove.6B.100d')\n",
        "\n",
        "print(\"Um total de %d tokens são mapeados por esse vocabulário.\"% len(INPUT.vocab.stoi))\n",
        "print(\"Os 10 primeiros tokens são\", INPUT.vocab.itos[:10])\n",
        "\n",
        "print('\\nÍndice da palavra \"fast\" no dicionário:', INPUT.vocab.stoi['fast'])\n",
        "print('Palavra do índice 100 do dicionário:', INPUT.vocab.itos[100])\n",
        "\n",
        "print('\\nDimensionalidade da representação distribuída:', INPUT.vocab.vectors.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-dHrmZINKvx"
      },
      "source": [
        "## Visualizando o espaço vetorial\n",
        "\n",
        "Como seria impraticável visualizar um espaço vetorial de centenas de dimensões, um artifício muito utilizado é a abordagem de redução de dimensionalidade intitulada **t-distributed Stochastic Neighbor Embedding (tSNE)**.\n",
        "\n",
        "O pacote Scikit-Learn nos traz essa funcionalidade de forma simplificada. Caso queira entender melhor o funcionamento desse método, recomendo a leitura [da documentação](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iggnkXOFNKvx"
      },
      "source": [
        "vectors2d = TSNE(n_components=2).fit_transform(INPUT.vocab.vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I4BFaV1NKvx"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(7, 7))\n",
        "\n",
        "examples = [11000,11080, 11102]\n",
        "\n",
        "for example in examples:\n",
        "    print(vars(dataset[example]))\n",
        "    sample = dataset[example]\n",
        "    entrada = sample.input\n",
        "    analogia = sample.target[0]\n",
        "\n",
        "    in_vec  = np.asarray([vectors2d[INPUT.vocab.stoi[e]] for e in entrada])\n",
        "    out_vec = vectors2d[INPUT.vocab.stoi[analogia]]\n",
        "\n",
        "\n",
        "    ax.scatter(in_vec[[0,2], 0], in_vec[[0,2], 1], s=30, color='dodgerblue')\n",
        "    ax.scatter(in_vec[1, 0], in_vec[1, 1], s=30, color='r')\n",
        "    ax.scatter(out_vec[0], out_vec[1], s=30, color='r')\n",
        "\n",
        "    for i, word in enumerate(entrada):\n",
        "        ax.text(in_vec[i,0]+0.2, in_vec[i,1], word, fontsize=14 )\n",
        "    ax.text(out_vec[0]+0.2, out_vec[1], analogia, fontsize=14 )\n",
        "        \n",
        "        \n",
        "plt.show()        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m593WNZNKvy"
      },
      "source": [
        "## Criando analogias\n",
        "\n",
        "Como dissemos, em um modelo pré-treinado, a geometria do espaço vetorial possui similaridades entre associações de mesma natureza. Podemos explorar essa característica para validar a qualidade de um modelo.\n",
        "\n",
        "Dado um conjunto de 3 palavras da nossa entrada, exemplo: <br>\n",
        "`palavras = ['man', 'king', 'woman'`]\n",
        "\n",
        "Podemos predizer a associaçao entre o primeiro par de palavras: <br>\n",
        "`associacao = palavra[1] - palavra[0]`\n",
        "\n",
        "e projetar essa associação na terceira palavra: <br>\n",
        "`projecao = palavra[2] + associacao`\n",
        "\n",
        "Essa projeção é um vetor no espaço da representação distribuída que deve estar na vizinhança da analogia que buscamos, nesse caso a palavra `queen`.\n",
        "\n",
        "<img width=400 src=\"https://pbs.twimg.com/media/DKWbi9nXoAAd_un.jpg\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DIwJfE1NKvy"
      },
      "source": [
        "def get_analogy(token_a, token_b, token_c, embed):\n",
        "    \n",
        "    vecs = [embed.vectors[embed.stoi[t]] \n",
        "                for t in [token_a, token_b, token_c]]\n",
        "    \n",
        "    analogy = vecs[1] - vecs[0] + vecs[2]\n",
        "    \n",
        "    distances = np.dot(embed.vectors, analogy) / np.linalg.norm(embed.vectors)\n",
        "    best = np.argsort(distances)\n",
        "    best = [embed.itos[best[k]] for k in range(-1, -4, -1) if embed.itos[best[k]] not in [token_a, token_b, token_c]]\n",
        "\n",
        "    return best[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAyHWRqlNKvy"
      },
      "source": [
        "idx = 100\n",
        "print(vars(dataset[idx]))\n",
        "words, analogy = dataset[idx].input, dataset[idx].target\n",
        "\n",
        "prediction = get_analogy(words[0], words[1], words[2], INPUT.vocab)\n",
        "print(f'\\n{words[0].capitalize()} is to {words[1].capitalize()} as {words[2].capitalize()} is to {prediction.capitalize()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C29_UXYrNKvz"
      },
      "source": [
        "## Como aprendemos esses vetores?\n",
        "\n",
        "Acabamos de ver a representação de palaras como ínidices de um vocabulário fixo. Apesar do índice informar a qual palavra estamos nos referindo, ele não incorpora nenhuma informação semântica sobre a palavra, como por exemplo o contexto no qual ela costuma aparecer. Essa representação semântica pode ser aprendida através de uma **camada de Embedding**.  \n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1pliMSOcjjOZAiR26ycowSeUJsj5cy9W_)\n",
        "\n",
        "Pense na camada de Embedding como uma tabela $V \\times D$, onde $V$ é o número de palavras do seu vocabulário e $D$ é o número de dimensões do espaço vetorial onde você deseja projetar. Colocando a camada de Embedding no início de sua rede neural, o treinamento vai otimizar os parâmetros da sua tabela encontrando o espaço vetorial que mapeia as relações intrínsecas entre as palavras dentro do contexto da otimização. Internamente, essa tabela nada mais é do que uma matriz de pesos a ser otimizada.\n",
        "\n",
        "\n",
        "No Pytorch, a instância dessa classe recebe como parâmetro ```(vocab_size, embedding_size, padding_idx)```\n",
        "* ```vocab_size```: Tamanho do vocabulário. Note que **não** se trata da dimensionalidade da entrada.\n",
        "* ```embedding_size```: Dimensionalidade do espaço latente. Caso haja o aproveitamento de embeddings pré treinadas deve-se definir a dimensionalidade da camada em função dos pesos que serão importados (ex: glove.6b.100d, ```embedding_size=100```)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YocCSgu8NKvz"
      },
      "source": [
        "class Embed(nn.Module):\n",
        "  \n",
        "  def __init__(self,vocab_size, embedding_size, embedding_weights=None):\n",
        "    super(Embed, self).__init__()\n",
        "    \n",
        "    self.embed = nn.Embedding(vocab_size, embedding_size)\n",
        "    \n",
        "    if embedding_weights is not None:\n",
        "        self.embed.weight.data.copy_(embedding_weights)\n",
        "    \n",
        "  def forward(self, X):\n",
        "    return self.embed(X)\n",
        "    \n",
        "\n",
        "embedding_size = INPUT.vocab.vectors.shape[1]\n",
        "vocab_size     = len(INPUT.vocab)\n",
        "\n",
        "pretrained_embeddings = INPUT.vocab.vectors\n",
        "\n",
        "net = Embed(vocab_size, embedding_size,\n",
        "           pretrained_embeddings)\n",
        "\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty5LDG8ENKvz"
      },
      "source": [
        "A seguir vamos refazer todos os passos do carregamento de dados para agregá-los em um só lugar. A única novidade aqui é o uso do `Iterator`, equivalente ao `DataLoader` que já conhecemos, mas com alguns facilitadores para trabalhar com dados textuais.\n",
        "\n",
        "```python\n",
        "torchtext.data.Iterator(dataset, batch_size, sort_key=None, device=None, shuffle=None, \n",
        "                        sort=None, sort_within_batch=None)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmpL6irsNKv0"
      },
      "source": [
        "#### Passo 1: Defina os fields e o carregamento do dataset\n",
        "\n",
        "INPUT  = data.Field(lower = True)\n",
        "TARGET = data.Field(lower = True)\n",
        "\n",
        "dataset = data.TabularDataset('questions-words.csv', format='csv',\n",
        "                                           fields=[('input', INPUT), ('target',TARGET)],\n",
        "                                           skip_header=True\n",
        "                                        )\n",
        "\n",
        "#### Passo 2: Defina o vocabulário **para todos os fields**\n",
        "\n",
        "MAX_VOCAB_SIZE=1000\n",
        "INPUT.build_vocab(dataset, \n",
        "                  max_size=MAX_VOCAB_SIZE,\n",
        "                  vectors='glove.6B.100d')\n",
        "\n",
        "TARGET.build_vocab(dataset, \n",
        "                  max_size=MAX_VOCAB_SIZE,\n",
        "                  vectors='glove.6B.100d')\n",
        "\n",
        "#### Passo 3: Defina o Iterator (nosso loader de batches)\n",
        "loader = data.Iterator(dataset, batch_size=10)\n",
        "\n",
        "for batch in loader:\n",
        "    \n",
        "    print(f'\\n\\nInput: {batch.input}\\nshape: {batch.input.shape}')\n",
        "    print(f'\\nTarget: {batch.target}\\nshape: {batch.target.shape}')\n",
        "    \n",
        "    inp = batch.input\n",
        "    lab = batch.target\n",
        "    \n",
        "    embed = net(inp)\n",
        "    print(f'\\nEmbed shape:{embed.shape}\\n\\n')\n",
        "    \n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6WOEguGNKv0"
      },
      "source": [
        "### Um pequeno exercício\n",
        "\n",
        "Refaça as analogias (funções copiadas abaixo) adaptando o código para usar a camada de embedding que definimos acima para adquirir as representações distribuídas de cada palavra. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUsP1moMNKv0"
      },
      "source": [
        "def get_analogy(token_a, token_b, token_c, embed):\n",
        "    \n",
        "    vecs = [embed.vectors[embed.stoi[t]] \n",
        "                for t in [token_a, token_b, token_c]]\n",
        "    \n",
        "    analogy = vecs[1] - vecs[0] + vecs[2]\n",
        "    \n",
        "    distances = np.dot(embed.vectors, analogy) / np.linalg.norm(embed.vectors)\n",
        "    best = np.argsort(distances)\n",
        "    best = [embed.itos[best[k]] for k in range(-1, -4, -1) if embed.itos[best[k]] not in [token_a, token_b, token_c]]\n",
        "\n",
        "    return best[0]\n",
        "\n",
        "idx = 100\n",
        "print(vars(dataset[idx]))\n",
        "words, analogy = dataset[idx].input, dataset[idx].target\n",
        "\n",
        "prediction = get_analogy(words[0], words[1], words[2], INPUT.vocab)\n",
        "print(f'\\n{words[0].capitalize()} is to {words[1].capitalize()} as {words[2].capitalize()} is to {prediction.capitalize()}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}