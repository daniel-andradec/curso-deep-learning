{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "S05A02_2_POS_Tagging(Gabarito).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwQ8q2eQ50GI"
      },
      "source": [
        "# Preâmbulo\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCa4ECYE6e2J",
        "outputId": "2d5a7777-e534-4acd-8499-a148cd3790b0"
      },
      "source": [
        "!wget https://www.dropbox.com/s/89xxqp80qhb550l/macmorpho.zip\r\n",
        "!unzip macmorpho.zip\r\n",
        "\r\n",
        "!pip install unidecode\r\n",
        "!pip install torchtext==0.6"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-16 00:15:45--  https://www.dropbox.com/s/89xxqp80qhb550l/macmorpho.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.18, 2620:100:6019:18::a27d:412\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/89xxqp80qhb550l/macmorpho.zip [following]\n",
            "--2021-03-16 00:15:45--  https://www.dropbox.com/s/raw/89xxqp80qhb550l/macmorpho.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucb6657df5ec4b9a0572f80e9fd6.dl.dropboxusercontent.com/cd/0/inline/BKyXn-FeycFqonW8nf58x3cbXAvyEWA6XAtBLYZp6dcgVqiKX8yWKpvvA1qhf1IKjYOgoTNpcajC9GCpQXegF0SGMHIIJYuYWHJ2yeheEJ17P-gdPvFI7vdmXz8QmnV2W0KsdTKAiCkvo57YLYeoWVkk/file# [following]\n",
            "--2021-03-16 00:15:46--  https://ucb6657df5ec4b9a0572f80e9fd6.dl.dropboxusercontent.com/cd/0/inline/BKyXn-FeycFqonW8nf58x3cbXAvyEWA6XAtBLYZp6dcgVqiKX8yWKpvvA1qhf1IKjYOgoTNpcajC9GCpQXegF0SGMHIIJYuYWHJ2yeheEJ17P-gdPvFI7vdmXz8QmnV2W0KsdTKAiCkvo57YLYeoWVkk/file\n",
            "Resolving ucb6657df5ec4b9a0572f80e9fd6.dl.dropboxusercontent.com (ucb6657df5ec4b9a0572f80e9fd6.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:6019:15::a27d:40f\n",
            "Connecting to ucb6657df5ec4b9a0572f80e9fd6.dl.dropboxusercontent.com (ucb6657df5ec4b9a0572f80e9fd6.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BKwKzBloWl5bQsGfe9yn-P0XOt-UbX8P71q91iUHtibuSda1Hccr3VT2Icq6_9Z8V26WixNM-6aOQYSclNv-1U_rdt8vtGcQJSHRJwLOtzmivobQ9olda09eQ0nhip5hLnU-0yqgefiheGhDXMJBMqttEFY4ut1hy2T5IfoQsDm1lBfF-dQx_HO2sY4rUnS1Ih3SCb5rdwqOmsbsm152SHt6XNXIxOurAUDyPjkVaOroP4k5yjUcydKFKbx87lWU1AyUm5UGpn-zpqlyQysBxEZjgAX9HejiXHvmbkUCZyOvqgDM8i4GHchRAaGl9S-fuStB77MSoAEbrrok7axIRRqI-9j9H8b7N_syKvPMEfKJP2fe05kd8nBjSaPmZq7mBUA/file [following]\n",
            "--2021-03-16 00:15:46--  https://ucb6657df5ec4b9a0572f80e9fd6.dl.dropboxusercontent.com/cd/0/inline2/BKwKzBloWl5bQsGfe9yn-P0XOt-UbX8P71q91iUHtibuSda1Hccr3VT2Icq6_9Z8V26WixNM-6aOQYSclNv-1U_rdt8vtGcQJSHRJwLOtzmivobQ9olda09eQ0nhip5hLnU-0yqgefiheGhDXMJBMqttEFY4ut1hy2T5IfoQsDm1lBfF-dQx_HO2sY4rUnS1Ih3SCb5rdwqOmsbsm152SHt6XNXIxOurAUDyPjkVaOroP4k5yjUcydKFKbx87lWU1AyUm5UGpn-zpqlyQysBxEZjgAX9HejiXHvmbkUCZyOvqgDM8i4GHchRAaGl9S-fuStB77MSoAEbrrok7axIRRqI-9j9H8b7N_syKvPMEfKJP2fe05kd8nBjSaPmZq7mBUA/file\n",
            "Reusing existing connection to ucb6657df5ec4b9a0572f80e9fd6.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2463669 (2.3M) [application/zip]\n",
            "Saving to: ‘macmorpho.zip’\n",
            "\n",
            "macmorpho.zip       100%[===================>]   2.35M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-03-16 00:15:47 (151 MB/s) - ‘macmorpho.zip’ saved [2463669/2463669]\n",
            "\n",
            "Archive:  macmorpho.zip\n",
            "  inflating: macmorpho-dev.txt       \n",
            "  inflating: macmorpho-test.txt      \n",
            "  inflating: macmorpho-train.txt     \n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/25/723487ca2a52ebcee88a34d7d1f5a4b80b793f179ee0f62d5371938dfa01/Unidecode-1.2.0-py2.py3-none-any.whl (241kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 25.8MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.2.0\n",
            "Collecting torchtext==0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6) (4.41.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 31.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6) (1.8.0+cu101)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.6) (3.7.4.3)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.9.0\n",
            "    Uninstalling torchtext-0.9.0:\n",
            "      Successfully uninstalled torchtext-0.9.0\n",
            "Successfully installed sentencepiece-0.1.95 torchtext-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctFqKwZJmkS2",
        "outputId": "2e0bb419-8728-4df2-ec70-f1586dc8e171"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os, unidecode\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext import data\n",
        "import torchtext\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV4Dgo3KmkSu"
      },
      "source": [
        "# POS Tagging\n",
        "\n",
        "**P**art-**o**f-**S**peech tagging, ou classificação sintática de sentenças, é uma área de pesquisa cujo objetivo é rotular palavras de uma frase de acordo com a sua categoria sintática.\n",
        "\n",
        "Em linguagens naturais se trata de um problema fortemente dependente de contexto, visto palavras de escrita e fala idênticas podem ter significados completamente diferentes. Ex:\n",
        "\n",
        "* \"*O **começo** da aula foi essencial.*\" $\\rightarrow$ **N**ome  \n",
        "* \"*Eu **começo** a trabalhar às 8:00.*\" $\\rightarrow$ **V**erbo\n",
        "\n",
        "Usaremos o conjunto de dados intitulado [MAC-MORPHO](http://www.nilc.icmc.usp.br/macmorpho/#ref1), com textos jornalísticos em português, extraídos da Folha de S. Paulo. Uma amostra do MAC-MORPHO é aparesentada na imagem a seguir. Para conhecer melhor as categorias desse conjunto, consulte [o manual](http://nilc.icmc.usp.br/macmorpho/macmorpho-manual.pdf) construído pelos autores. <br><br>\n",
        "\n",
        "<img width=650 src=\"https://www.dropbox.com/s/nesqjcl2opd7vo3/MAC-MORPHO.png?dl=1\">\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0MpAF87mkS4"
      },
      "source": [
        "## Carregamento de dados\n",
        "\n",
        "Para criar o dataset, exploramos as vantagens do pacote [Torchtext](https://torchtext.readthedocs.io/en/latest/). Como vimos anteriormente, suas ferramentas facilitam tarefas essenciais como construção de vocabulário e carregamento de sequências de tamanho variável.\n",
        "\n",
        "Uma novidade aqui é a construção de um Dataset customizado, sem o recurso de carregamento de dados tabulares. Podemos criar uma classe que herda as característica da classe [`data.Dataset`](https://torchtext.readthedocs.io/en/latest/data.html#torchtext.data.Dataset) do torchtext, ganhando liberdade para construir nosso conjunto de dados.\n",
        "\n",
        "Para incializar nosso conjunto, basta construir no método `__init__()` as seguintes estruturas de dados:\n",
        "* `examples`: uma lista de objetos tipo `data.Example`.\n",
        "  * Cada exemplo é uma tupla `([amostra, rotulo], fields)`\n",
        "* `fields`: uma lista de tuplas `(str, data.Field)`\n",
        "\n",
        "Ao final do nosso `__init__()` customizado, devemos inicializar a classe \"mãe\" `data.Dataset` com a lista de exemplos e os fields definidos:\n",
        "```python\n",
        "super().__init__(self.examples, self.fields)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y48SxRLmkS4"
      },
      "source": [
        "class MacMorpho(data.Dataset):\n",
        "    \n",
        "    def __init__(self, path, fields):\n",
        "        \n",
        "        fields = fields\n",
        "        lines = open(path).read().split('\\n')\n",
        "        samples, labels = [], []\n",
        "        \n",
        "        examples = [] \n",
        "        for line in lines[:-1]:\n",
        "\n",
        "            sample, label = [], []\n",
        "            for word_cat in line.split():\n",
        "                \n",
        "                word, lab = word_cat.split('_')\n",
        "                word = unidecode.unidecode(word.lower())\n",
        "                sample.append(word)\n",
        "                \n",
        "                label.append(lab.split('+')[0])\n",
        "                \n",
        "            samples.append(sample)\n",
        "            labels.append(label)\n",
        "        \n",
        "            examples.append(data.Example.fromlist([' '.join(sample), ' '.join(label)], fields))\n",
        "        super().__init__(examples, fields)\n",
        "\n",
        "\n",
        "### Defina os fields\n",
        "TEXT = data.Field(include_lengths=True)\n",
        "TARGET = data.Field()\n",
        "\n",
        "### Carregue os dados\n",
        "trainset, devset, testset = MacMorpho.splits(path='.',\n",
        "                                             root='.',\n",
        "                                             train='macmorpho-train.txt',\n",
        "                                             validation='macmorpho-test.txt',\n",
        "                                             test='macmorpho-dev.txt',\n",
        "                                             fields=[('text', TEXT), ('target', TARGET)]\n",
        "                                             )\n",
        "\n",
        "### Construa o vocabulário\n",
        "TEXT.build_vocab(trainset, max_size=20_000)\n",
        "TARGET.build_vocab(trainset)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGqGJg1-Hhe7",
        "outputId": "31571319-6958-4451-8110-93cdb21c2aea"
      },
      "source": [
        "for sample in testset:\r\n",
        "  print(sample.text )\r\n",
        "  print(sample.target)\r\n",
        "\r\n",
        "  break"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ainda', 'em', 'dezembro', 'de', '1990', ',', 'foi', 'editada', 'a', 'famosa', '289', ',', 'que', 'modificava', 'a', 'sistematica', 'da', 'arrecadacao', 'do', 'itr', 'e', 'alterava', 'suas', 'aliquotas', '.']\n",
            "['ADV', 'PREP', 'N', 'PREP', 'N', 'PU', 'V', 'PCP', 'ART', 'ADJ', 'N', 'PU', 'PRO-KS', 'V', 'ART', 'N', 'PREP', 'N', 'PREP', 'NPROP', 'KC', 'V', 'PROADJ', 'N', 'PU']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DePhh6McKv-z"
      },
      "source": [
        "### BucketIterator\r\n",
        "\r\n",
        "Essa classe do Torchtext funciona de forma análoga ao DataLoader do PyTorch,  porém leva em consideração a construção de **batches com sequências de comprimento variável**. Internamente ele agrega sequências de comprimento similar, **minimizando a quantidade de padding necessária**. \r\n",
        "\r\n",
        "Além disso, os dados já saem preparados para serem empacotados pela função ```pack_padded_sequence``` ordenados por comprimento de sequência e informando o comprimento real de cada amostra (sem padding).\r\n",
        "\r\n",
        "> Exemplo: Para compor um tensor com 5 amostras de frases com tamanhos variáveis, a segunda dimensão é definida pela frase de maior comprimento. Amostras menores são complementadas com tokens nulos (`<pad>`). \r\n",
        "\r\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1uOf8NpztcNyV0Dq9Ch5oJoKuPnwPptqK\" width=\"450\">\r\n",
        "\r\n",
        "\r\n",
        "Documentação: https://torchtext.readthedocs.io/en/latest/data.html?highlight=BucketIterator#torchtext.data.BucketIterator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "426U75dZKs8g"
      },
      "source": [
        "### Construa o iterator (nosso loader de dados)\r\n",
        "train_iterator = data.BucketIterator(trainset, \r\n",
        "                                     batch_size=32, \r\n",
        "                                     sort_key=lambda x: len(x.text), \r\n",
        "                                     sort_within_batch=True)\r\n",
        "\r\n",
        "test_iterator = data.BucketIterator(testset, batch_size=32, sort_key=lambda x: len(x.text), sort_within_batch=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL4bGmFdLXfO",
        "outputId": "a3f65dd5-d62c-4f97-f50e-07dae6116420"
      },
      "source": [
        "for batch in test_iterator:\r\n",
        "\r\n",
        "    inp, tam = batch.text\r\n",
        "    lab = batch.target\r\n",
        "    \r\n",
        "    print(f'Entrada (shape): {inp.shape}, comprimentos (shape): {tam.shape}')\r\n",
        "    print(f'\\nComprimentos: {tam}')\r\n",
        "    print(f'\\nRotulos (shape): {lab.shape}')\r\n",
        "\r\n",
        "    break"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entrada (shape): torch.Size([41, 32]), comprimentos (shape): torch.Size([32])\n",
            "\n",
            "Comprimentos: tensor([41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 40, 40, 40,\n",
            "        40, 40, 40, 40, 40, 40, 40, 40, 40, 39, 39, 39, 39, 39])\n",
            "\n",
            "Rotulos (shape): torch.Size([41, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEjzRR8EXUUU"
      },
      "source": [
        "## Padding and Packing (Preenchendo e empacotando)\r\n",
        "\r\n",
        "O pacote de funções de rnn, ```nn.utils.rnn```, oferece meios de processar batches contendo sequências de tamanho variável. Isso é realizado através do **padding** da sequência (ex: preenchimento com zeros),  de modo que elas aparentem ter igual comprimento, porém internamente as posições preenchidas não são processadas pela RNN.\r\n",
        "\r\n",
        "*  Vamos lembrar do nosso batch de frases com tamanhos variáveis:\r\n",
        "\r\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1uOf8NpztcNyV0Dq9Ch5oJoKuPnwPptqK\" width=\"450\">\r\n",
        "\r\n",
        "\r\n",
        "*  O empacotamento precisa receber os dados em ordem decrescente de comprimento, e internamente são criados \"mini batches\" com o seu batch. Dessa forma, apenas os timesteps que contém informação relevante sobre o dado são apresentadas à rede. Igualmente, somente esses timesteps impactam no backpropagation.\r\n",
        "\r\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1ySh4IdDO4Iw3G8p2iSdo62MW_z4kR5fd\" width=\"450\">\r\n",
        "\r\n",
        "\r\n",
        "Para isso basta realizar o padding das suas sequências, **preservando os comprimetos originais** em outra variável. Na prática, o forward recebe mais um parâmetro, aqui chamamos de **```tamanhos```**, referente ao comprimento de cada amostra dentro do batch **```X```**, ordenado de forma descrescente.\r\n",
        "\r\n",
        "Tendo em mãos (1) o batch de sequências preenchidas e ordenadas, e (2) o comprimento original de cada amostra, basta realizar as seguintes operações no forward da rede:\r\n",
        "\r\n",
        "```python\r\n",
        "## Empacote a sequência antes de alimentar a unidade recorrente\r\n",
        "packed_input = nn.utils.rnn.pack_padded_sequence(X, tamanhos)\r\n",
        "\r\n",
        "## Forward recorrente\r\n",
        "packed_output, hidden = self.rnn(packed_input, hidden )\r\n",
        "\r\n",
        "## Desempacote a sequência para continuar o fluxo na rede.\r\n",
        "output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\r\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9H5YeH7IXUFT",
        "outputId": "88e5ab20-4008-4725-8b2e-bbbba831486d"
      },
      "source": [
        "# Simulando um init \r\n",
        "hidden_size = 128\r\n",
        "rnn = nn.RNN( 1, hidden_size ).to(device)\r\n",
        "\r\n",
        "# Simulando um forward\r\n",
        "for batch in test_iterator:\r\n",
        "\r\n",
        "  X, tamanhos = batch.text\r\n",
        "  print(X.size(), tamanhos.size())\r\n",
        "  hidden = torch.zeros(1, X.size(1), hidden_size).to(device)\r\n",
        "\r\n",
        "  ## Empacote a sequência antes de alimentar a unidade recorrente\r\n",
        "  packed_input = nn.utils.rnn.pack_padded_sequence(X.unsqueeze(-1).float().to(device), tamanhos)\r\n",
        "  print('\\npacked_input.batch_sizes:', packed_input.batch_sizes)\r\n",
        "\r\n",
        "  ## Forward recorrente\r\n",
        "  packed_output, hidden = rnn(packed_input, hidden )\r\n",
        "  print('\\npacked_output.batch_sizes:', packed_output.batch_sizes)\r\n",
        "  print('\\nhidden:', hidden.size())\r\n",
        "\r\n",
        "  ## Desempacote a sequência para continuar o fluxo na rede.\r\n",
        "  output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\r\n",
        "  print('\\noutput:', output.size())\r\n",
        "  \r\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([7, 32]) torch.Size([32])\n",
            "\n",
            "packed_input.batch_sizes: tensor([32, 32, 32, 32, 32, 32, 32])\n",
            "\n",
            "packed_output.batch_sizes: tensor([32, 32, 32, 32, 32, 32, 32])\n",
            "\n",
            "hidden: torch.Size([1, 32, 128])\n",
            "\n",
            "output: torch.Size([7, 32, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2hICTxHmkS5"
      },
      "source": [
        "## Exercício\n",
        "\n",
        "1) Vamos implementar uma RNN simples com  a seguinte arquitetura:\n",
        "* [`nn.Embedding`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
        "* [`nn.RNN`](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html?highlight=rnn#torch.nn.RNN)\n",
        "* [`nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html?highlight=linear#torch.nn.Linear) com ativação [`LogSoftmax`](https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html#torch.nn.LogSoftmax).\n",
        "\n",
        "Note que se trata de um problema **muitos para muitos**, ou seja, precisamos realizar ambos o passo recorrente e a inferência com a camada linear em todos os elementos da sequência. Para tal, a camada `nn.Linear` suporta tensores de quaisquer dimensões `(N, *, H_in)`, aplicando a transformação linear apenas na última dimensão.\n",
        "\n",
        "2) Modifique agora o seu modelo para uma **RNN bidirecional**. \n",
        "> Note que essa arquitetura na prática dobra a quantidade de pesos em relação à RNN unidirecional. Sugiro dividir pela metade o hiperparâmetro que você definiu no passo 1 para o `hidden_size` para comparar as duas redes com igual complexidade.\n",
        "![](https://drive.google.com/uc?export=view&id=158b3Y_o-7yXsKMe5VdaifhPg0Du4A6dp) <br>\n",
        "Na implementação, o que muda em relação à camada unidirecional é:\n",
        "*  Ao instanciar a camada recorrente, defina o parâmetro **```bidirectional = True```**\n",
        "*  O hidden state tem dimensionalidade **```(num_layers * 2, batch_size, hidden_size)```**\n",
        "*  O output tem dimensionalidade **```(seq_len, batch_size, hidden_size * 2)```**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eYhV5iqmkS5"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, out_size, \n",
        "                 num_layers, dropout=0.5):\n",
        "        super(RNN, self).__init__()\n",
        "        \n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        self.embed  = nn.Embedding(vocab_size, embed_size)\n",
        "\n",
        "        self.rnn    = nn.RNN(embed_size, hidden_size,  \n",
        "                              num_layers=self.num_layers)\n",
        "        \n",
        "        self.linear = nn.Linear(hidden_size, out_size)\n",
        "        \n",
        "    def forward(self, X, lengths):\n",
        "        # X: S x B x D\n",
        "        \n",
        "        # HIDDEN: L x B x H\n",
        "        hidden = torch.zeros(self.num_layers, X.size(1), self.hidden_size).to(device)\n",
        "        \n",
        "        embed = self.embed(X)\n",
        "        # EM: S x B x E\n",
        "\n",
        "        ## Empacote a sequência antes de alimentar a unidade recorrente\n",
        "        packed_input = nn.utils.rnn.pack_padded_sequence(embed, lengths)\n",
        " \n",
        "        ## Forward recorrente\n",
        "        packed_output, hidden = self.rnn(packed_input, hidden )\n",
        "        \n",
        "        ## Desempacote a sequência para continuar o fluxo na rede.\n",
        "        outputs, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "        # OUT: S x B x H , HIDDEN: L x B x H\n",
        "\n",
        "        output = F.log_softmax(self.linear( outputs ), dim=-1)\n",
        "        # OUT: S x B x O\n",
        "        \n",
        "        return output\n",
        "        \n",
        "        \n",
        "net = RNN( len(TEXT.vocab), 50, 128, len(TARGET.vocab), 2).to(device)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Wb7vghcMxwd"
      },
      "source": [
        "### TODO: ARQUITETURA BIDIRECIONAL\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd9bdbrzmkS6"
      },
      "source": [
        "### Definindo otimizador e função de perda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzoNBLzTmkS6"
      },
      "source": [
        "optimizer = optim.Adam(net.parameters(), lr=1e-3, weight_decay=5e-4)\n",
        "criterion = nn.NLLLoss().to(device)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTJ0jYJkmkS6"
      },
      "source": [
        "### Fluxo de Treinamento e Validação "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwNFds9SmkS6"
      },
      "source": [
        "def forward(iterator, epoch, optimizer, criterion, mode):\n",
        "    \n",
        "    acc = 0.\n",
        "    epoch_loss = []\n",
        "    for sample in iterator:\n",
        "        \n",
        "        text, lengths = sample.text\n",
        "        text = text.to(device)\n",
        "        label = sample.target\n",
        "        label = label.to(device)\n",
        "        \n",
        "        out = net(text, lengths)\n",
        "        # S x B x C\n",
        "\n",
        "        loss = criterion(out.view(out.size(0)*out.size(1), -1),\n",
        "                         label.view(label.size(0)*label.size(1)))\n",
        "        \n",
        "        epoch_loss.append(loss.detach().cpu().item())\n",
        "        \n",
        "        _, pred = torch.max(out.detach(), dim=-1)\n",
        "        acc += torch.sum(pred == label).item()/(pred.size(0)*pred.size(1)) \n",
        "\n",
        "        if mode == 'train':\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "    epoch_loss = np.asarray(epoch_loss)\n",
        "    print(f'Epoch {epoch} - Loss: {epoch_loss.mean():.4f}+/-{epoch_loss.std():.4f}, Acc: {(acc/len(iterator))*100:.2f}%')\n",
        "    \n",
        "    return epoch_loss.mean()\n",
        "        "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L0l2bvDY8ui",
        "outputId": "6af2566c-d303-4422-ee52-c08011c3aead"
      },
      "source": [
        "train_loss, test_loss = [], []\r\n",
        "for epoch in range(30):\r\n",
        "    \r\n",
        "    loss = forward(train_iterator, epoch, optimizer, criterion, 'train')\r\n",
        "    train_loss.append(loss)\r\n",
        "    \r\n",
        "    loss = forward(test_iterator, epoch, optimizer, criterion, 'test')\r\n",
        "    test_loss.append(loss)\r\n",
        "    \r\n",
        "    print('--'*20)\r\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 - Loss: 1.0278+/-0.3345, Acc: 68.92%\n",
            "Epoch 0 - Loss: 0.7930+/-0.1693, Acc: 76.81%\n",
            "----------------------------------------\n",
            "Epoch 1 - Loss: 0.6485+/-0.1675, Acc: 80.20%\n",
            "Epoch 1 - Loss: 0.5364+/-0.1537, Acc: 84.40%\n",
            "----------------------------------------\n",
            "Epoch 2 - Loss: 0.4376+/-0.1303, Acc: 87.13%\n",
            "Epoch 2 - Loss: 0.3824+/-0.1300, Acc: 89.37%\n",
            "----------------------------------------\n",
            "Epoch 3 - Loss: 0.3425+/-0.1077, Acc: 90.13%\n",
            "Epoch 3 - Loss: 0.3450+/-0.0963, Acc: 90.32%\n",
            "----------------------------------------\n",
            "Epoch 4 - Loss: 0.3107+/-0.0819, Acc: 90.97%\n",
            "Epoch 4 - Loss: 0.3171+/-0.0878, Acc: 90.94%\n",
            "----------------------------------------\n",
            "Epoch 5 - Loss: 0.2969+/-0.0758, Acc: 91.27%\n",
            "Epoch 5 - Loss: 0.3222+/-0.0791, Acc: 90.22%\n",
            "----------------------------------------\n",
            "Epoch 6 - Loss: 0.2859+/-0.0662, Acc: 91.44%\n",
            "Epoch 6 - Loss: 0.3083+/-0.0789, Acc: 90.73%\n",
            "----------------------------------------\n",
            "Epoch 7 - Loss: 0.2791+/-0.0577, Acc: 91.50%\n",
            "Epoch 7 - Loss: 0.2931+/-0.0661, Acc: 91.32%\n",
            "----------------------------------------\n",
            "Epoch 8 - Loss: 0.2729+/-0.0594, Acc: 91.64%\n",
            "Epoch 8 - Loss: 0.2836+/-0.0562, Acc: 91.33%\n",
            "----------------------------------------\n",
            "Epoch 9 - Loss: 0.2674+/-0.0561, Acc: 91.74%\n",
            "Epoch 9 - Loss: 0.2848+/-0.0561, Acc: 91.34%\n",
            "----------------------------------------\n",
            "Epoch 10 - Loss: 0.2635+/-0.0542, Acc: 91.86%\n",
            "Epoch 10 - Loss: 0.2766+/-0.0594, Acc: 91.33%\n",
            "----------------------------------------\n",
            "Epoch 11 - Loss: 0.2599+/-0.0528, Acc: 91.95%\n",
            "Epoch 11 - Loss: 0.2791+/-0.0547, Acc: 91.39%\n",
            "----------------------------------------\n",
            "Epoch 12 - Loss: 0.2560+/-0.0537, Acc: 92.05%\n",
            "Epoch 12 - Loss: 0.2898+/-0.0638, Acc: 90.75%\n",
            "----------------------------------------\n",
            "Epoch 13 - Loss: 0.2541+/-0.0501, Acc: 92.05%\n",
            "Epoch 13 - Loss: 0.2704+/-0.0582, Acc: 91.29%\n",
            "----------------------------------------\n",
            "Epoch 14 - Loss: 0.2516+/-0.0507, Acc: 92.11%\n",
            "Epoch 14 - Loss: 0.2847+/-0.0646, Acc: 91.30%\n",
            "----------------------------------------\n",
            "Epoch 15 - Loss: 0.2492+/-0.0514, Acc: 92.24%\n",
            "Epoch 15 - Loss: 0.2652+/-0.0555, Acc: 91.92%\n",
            "----------------------------------------\n",
            "Epoch 16 - Loss: 0.2473+/-0.0521, Acc: 92.26%\n",
            "Epoch 16 - Loss: 0.2693+/-0.0521, Acc: 91.55%\n",
            "----------------------------------------\n",
            "Epoch 17 - Loss: 0.2454+/-0.0514, Acc: 92.33%\n",
            "Epoch 17 - Loss: 0.2659+/-0.0617, Acc: 91.76%\n",
            "----------------------------------------\n",
            "Epoch 18 - Loss: 0.2435+/-0.0510, Acc: 92.39%\n",
            "Epoch 18 - Loss: 0.2657+/-0.0632, Acc: 91.64%\n",
            "----------------------------------------\n",
            "Epoch 19 - Loss: 0.2416+/-0.0512, Acc: 92.47%\n",
            "Epoch 19 - Loss: 0.2642+/-0.0514, Acc: 91.84%\n",
            "----------------------------------------\n",
            "Epoch 20 - Loss: 0.2413+/-0.0497, Acc: 92.43%\n",
            "Epoch 20 - Loss: 0.2579+/-0.0587, Acc: 92.11%\n",
            "----------------------------------------\n",
            "Epoch 21 - Loss: 0.2386+/-0.0514, Acc: 92.57%\n",
            "Epoch 21 - Loss: 0.2600+/-0.0552, Acc: 91.68%\n",
            "----------------------------------------\n",
            "Epoch 22 - Loss: 0.2386+/-0.0503, Acc: 92.50%\n",
            "Epoch 22 - Loss: 0.2629+/-0.0575, Acc: 91.87%\n",
            "----------------------------------------\n",
            "Epoch 23 - Loss: 0.2377+/-0.0528, Acc: 92.61%\n",
            "Epoch 23 - Loss: 0.2614+/-0.0566, Acc: 91.77%\n",
            "----------------------------------------\n",
            "Epoch 24 - Loss: 0.2363+/-0.0495, Acc: 92.59%\n",
            "Epoch 24 - Loss: 0.2589+/-0.0504, Acc: 91.72%\n",
            "----------------------------------------\n",
            "Epoch 25 - Loss: 0.2347+/-0.0487, Acc: 92.66%\n",
            "Epoch 25 - Loss: 0.2613+/-0.0519, Acc: 91.86%\n",
            "----------------------------------------\n",
            "Epoch 26 - Loss: 0.2346+/-0.0489, Acc: 92.69%\n",
            "Epoch 26 - Loss: 0.2641+/-0.0543, Acc: 91.72%\n",
            "----------------------------------------\n",
            "Epoch 27 - Loss: 0.2338+/-0.0471, Acc: 92.70%\n",
            "Epoch 27 - Loss: 0.2605+/-0.0546, Acc: 91.82%\n",
            "----------------------------------------\n",
            "Epoch 28 - Loss: 0.2327+/-0.0498, Acc: 92.73%\n",
            "Epoch 28 - Loss: 0.2594+/-0.0534, Acc: 91.86%\n",
            "----------------------------------------\n",
            "Epoch 29 - Loss: 0.2316+/-0.0481, Acc: 92.80%\n",
            "Epoch 29 - Loss: 0.2584+/-0.0627, Acc: 92.05%\n",
            "----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEGC-xp4mkS7"
      },
      "source": [
        "### Predizendo instâncias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAmc7cfPmkS8",
        "outputId": "09fca83c-39e2-4954-a086-ed256657ce8f"
      },
      "source": [
        "def pred( sentence ):\n",
        "\n",
        "  text  = [unidecode.unidecode(word.split('_')[0]).lower() for word in sentence.split()]\n",
        "  label = [TARGET.vocab.stoi[word.split('_')[1].split('+')[0]] for word in sentence.split()]\n",
        "  print(text)\n",
        "  text = [TEXT.vocab.stoi[t] for t in text]\n",
        "\n",
        "  text = torch.LongTensor(text)\n",
        "  text = text.view(text.size(0), 1).to(device)\n",
        "  out = net(text, torch.LongTensor( [len(text)] ))\n",
        "\n",
        "  _, pred = torch.max(out, -1)\n",
        "  print([TARGET.vocab.itos[p] for p in pred.squeeze() ],'\\n') \n",
        "\n",
        "  return np.asarray(label), pred.detach().cpu().numpy().squeeze()\n",
        "\n",
        "with open('macmorpho-dev.txt') as fp:\n",
        "  sentences = fp.read().split('\\n')\n",
        "  for i in range(10):\n",
        "    sentence = sentences[i]\n",
        "    ytrue, ypred = pred(sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ainda', 'em', 'dezembro', 'de', '1990', ',', 'foi', 'editada', 'a', 'famosa', '289', ',', 'que', 'modificava', 'a', 'sistematica', 'da', 'arrecadacao', 'do', 'itr', 'e', 'alterava', 'suas', 'aliquotas', '.']\n",
            "['PDEN', 'PREP', 'N', 'PREP', 'N', 'PU', 'V', 'PCP', 'ART', 'ADJ', 'N', 'PU', 'PRO-KS', 'V', 'ART', 'N', 'PREP', 'N', 'PREP', 'NPROP', 'KC', 'V', 'PROADJ', 'N', 'PU'] \n",
            "\n",
            "['porem', ',', 'como', 'a', 'previsao', 'indica', 'entrada', 'de', 'frente', 'fria', ',', 'deve', '-se', 'aguardar', 'ate', 'quarta-feira', 'e', 'irrigar', 'somente', 'se', 'o', 'total', 'de', 'chuva', 'for', 'inferior', 'a', '30', 'mm', '.']\n",
            "['KC', 'PU', 'PREP', 'ART', 'N', 'V', 'N', 'PREP', 'N', 'ADJ', 'PU', 'V', 'PROPESS', 'V', 'PREP', 'N', 'KC', 'N', 'PDEN', 'KS', 'ART', 'N', 'PREP', 'N', 'V', 'ADJ', 'PREP', 'NUM', 'N', 'PU'] \n",
            "\n",
            "['\"', 'o', 'crescimento', 'e', 'expressivo', 'mas', ',', 'mesmo', 'assim', ',', 'estamos', 'abaixo', 'da', 'media', 'historica', 'do', 'setor', ',', 'que', 'e', 'de', '45', 'mil', 'tratores', 'por', 'ano', '\"', ',', 'diz', 'pastre', '.']\n",
            "['PU', 'ART', 'N', 'V', 'V', 'KC', 'PU', 'PDEN', 'ADV', 'PU', 'V', 'PREP', 'PREP', 'N', 'ADJ', 'PREP', 'N', 'PU', 'PRO-KS', 'V', 'PREP', 'NUM', 'NUM', 'N', 'PREP', 'N', 'PU', 'PU', 'V', 'NPROP', 'PU'] \n",
            "\n",
            "['o', 'programa', 'atende', 'ainda', 'as', 'culturas', 'de', 'feijao', '(', 'primeira', 'e', 'segunda', 'safras', ')', ',', 'arroz', 'de', 'varzea', 'e', 'mamona', ',', 'cujas', 'estimativas', 'de', 'producao', 'ainda', 'nao', 'foram', 'elaboradas', '.']\n",
            "['ART', 'N', 'V', 'ADV', 'ART', 'N', 'PREP', 'N', 'PU', 'ADJ', 'KC', 'ADJ', 'N', 'PU', 'PU', 'N', 'PREP', 'N', 'KC', 'N', 'PU', 'V', 'N', 'PREP', 'N', 'ADV', 'ADV', 'V', 'PCP', 'PU'] \n",
            "\n",
            "['de', 'qualquer', 'maneira', ',', 'toda', 'essa', '\"', 'informalidade', '\"', 'na', 'producao', 'de', 'sementes', 'nao', 'foi', 'obstaculo', 'a', 'um', 'enorme', 'crescimento', 'deste', 'segmento', 'da', 'agricultura', '.']\n",
            "['PREP', 'PROADJ', 'N', 'PU', 'PROADJ', 'PROADJ', 'PU', 'N', 'PU', 'PREP', 'N', 'PREP', 'N', 'ADV', 'V', 'PCP', 'PREP', 'ART', 'ADJ', 'N', 'PREP', 'N', 'PREP', 'N', 'PU'] \n",
            "\n",
            "['e', 'divulgar', 'procedimentos', 'adequados', 'de', 'manejo', 'do', 'solo', ',', 'dar', 'assistencia', 'tecnica', 'eficaz', 'ao', 'produtor', 'e', 'implantar', 'programas', 'de', 'educacao', 'ambiental', 'nas', 'escolas', '.']\n",
            "['KC', 'V', 'N', 'N', 'PREP', 'N', 'PREP', 'N', 'PU', 'V', 'N', 'ADJ', 'ADJ', 'PREP', 'N', 'KC', 'V', 'N', 'PREP', 'N', 'ADJ', 'PREP', 'N', 'PU'] \n",
            "\n",
            "['os', 'paises', 'ricos', 'nao', 'concordam', '.']\n",
            "['ART', 'N', 'ADJ', 'ADV', 'V', 'PU'] \n",
            "\n",
            "['evita', ',', 'dessa', 'forma', ',', 'que', 'plantios', 'inadequados', 'ao', 'tipo', 'de', 'solo', 'acelerem', 'o', 'processo', 'de', 'erosao', '.']\n",
            "['V', 'PU', 'PREP', 'N', 'PU', 'PRO-KS', 'V', 'V', 'PREP', 'N', 'PREP', 'N', 'ADJ', 'ART', 'N', 'PREP', 'N', 'PU'] \n",
            "\n",
            "['um', 'exemplo', 'e', 'a', 'bacia', 'do', 'vale', 'do', 'piracicaba', '(', 'a', '170', 'quilometros', 'a', 'noroeste', 'de', 'sao', 'paulo', ')', '.']\n",
            "['ART', 'N', 'V', 'ART', 'N', 'PREP', 'NPROP', 'PREP', 'NPROP', 'PU', 'ART', 'NUM', 'N', 'PREP', 'N', 'PREP', 'NPROP', 'NPROP', 'PU', 'PU'] \n",
            "\n",
            "['a', 'terra', ',', 'que', 'escoa', 'junto', ',', 'chega', 'ao', 'rio', 'e', 'diminui', 'o', 'seu', 'leito', '(', 'assoreamento', ')', '.']\n",
            "['ART', 'NPROP', 'PU', 'PRO-KS', 'V', 'PREP', 'PU', 'V', 'PREP', 'NPROP', 'KC', 'V', 'ART', 'PROADJ', 'N', 'PU', 'N', 'PU', 'PU'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImjHiciVmkS8"
      },
      "source": [
        "### Matriz de confusão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyiEe1iYmkS9"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "dev_iterator = data.BucketIterator(devset, batch_size=32, sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
        "predictions, labels = [], []\n",
        "for sample in dev_iterator:\n",
        "    \n",
        "    text, lengths = sample.text\n",
        "    label = sample.target\n",
        "    \n",
        "    out = net(text.to(device), lengths)\n",
        "    _, pred = torch.max(out, -1)\n",
        "    \n",
        "    predictions.extend(list(pred.view(-1).cpu().numpy()))\n",
        "    labels.extend( list(label.view(-1).numpy() )  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "v7xwYGW8mkS9",
        "outputId": "4803bde5-ede6-4c67-ec34-fdb08670d160"
      },
      "source": [
        "conf = confusion_matrix(y_true=labels, y_pred=predictions, normalize='true')\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.imshow(conf, cmap='coolwarm')\n",
        "plt.colorbar()\n",
        "plt.xticks(np.arange(0, len(TARGET.vocab)-1), TARGET.vocab.itos[1:], rotation=90)\n",
        "plt.yticks(np.arange(0, len(TARGET.vocab)-1), TARGET.vocab.itos[1:])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAFvCAYAAABOy2yvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd7gdVb3/8fcnIYFAqCIdaSJNOpafgFKvgCCoKESugqKxIQroVZSr6LVcFQQp6o0KiFeaBYlcEBAEUVEInQTpLfQmEEra+fz+WLOTOTuz9zkzZ9ec7+t59pM9a8+aWfucnFkzq3yXbBNCCCHUjOl2AUIIIfSWqBhCCCEMEhVDCCGEQaJiCCGEMEhUDCGEEAaJiiGEEMIgUTGEEEIfk3SapCck3dbgc0k6SdLdkm6RtM1Qx4yKIYQQ+tsZwB5NPt8T2DB7TQZ+NNQBo2IIIYQ+ZvvPwDNNdtkXONPJ34EVJK3e7JhLtLKAIYQQFtp2zDJ+3vMr57+b2dOBV3JJU2xPKXmYNYGHctszs7RHG2WIiiGEENrkec/nxCXWqZx/73l3vmJ7uxYWaViiYgghhHYRaJyq55/XklI8DKyd214rS2soKoYQQmgTSYxZYgQVQ2tMBQ6TdA7wJuA52w2bkSAqhhBC6GuSzgZ2AlaWNBP4KjAOwPaPgYuAvYC7gZeADw11zKgYQgihXQQa197Bn7YnDfG5gU+VOWZUDCGE0C6iF5qSSouKIYQQ2mWknc9dEhPcQgghDBJPDCGE0CY9MiqptKgYQgihXfq0KSkqhhBCaJfofA4hhJAnQGP7r2KIzucQQgiDxBNDCCG0i2BMHz4xRMUQQghtIzQmKoYQQgg1Ao3tvxb7qBhCCKFNRH82JfVfVRZCCKGt4okhhBDaRUQfQwghhDz1ZVNSVAwhhNAmUkxwCyGEsBiIJ4YQQmgjjem/+++oGEIIoV2i8zmEEMJg0fkcQgghR336xNB/jV8hhBDaKp4YQgihjaLzOYQQwkJ92pQ06iqG5TXWqzCuVJ5Hl1+nTaUJIfSq2S89xtw5z43wqh6dz31hFcZxwthyF/pv7zilTaUJIfSqm6+e3O0idM2oqxhCCKFT+nVUUt9UDJLuB7az/VS3yxJCCMMVnc91JI0Hxtl+scXHXdH2s608ZgghtFyfPjG0pSqTtImk44E7gNdlafdL+q6kWyVdK+m1Wfo+kv4h6UZJf5S0apb+KkmXSpou6aekxZBqpkn6paRdJPXfTz2EMEqkNZ+rvrqlZRWDpGUkfUjSX4CfADOALWzfmNvtOdubA6cAJ2ZpfwHebHtr4BzgP7L0rwJ/sb0ZcD7wmtxxXgecDRwGzJD0JUlrNCnbZEnTJE17jvkj/7IhhLAYa2VT0qPALcBHbP+zwT5n5/49IXu/FnCupNWB8cB9WfpbgXcD2P4/SQuajmzPBy4ELpT0auDbwIOS3mL72vqT2p4CTAHYUEu5+lcMIYRyRntT0v7Aw8BvJX1FUtGYUBe8Pxk4JXuS+Biw1HBOJml5SR8DpgIbAh8mVUwhhNAT0qikMZVf3dKyM9u+1PYBwI7Ac8AFWZ/BurndDsj9e032fnlShQJwcG7fPwPvB5C0J7Bi7QNJ/wvcAKwHfND222yfafuVVn2fEEJohTFjVfnVLS0flWT7aeAHwA8kvREGNeqvKOkWYDYwKUs7FvhV1lR0BeliD/A14GxJ04G/AQ/mjnMecIjtea0ufwghtIy624lcVVuHqxa093/P9hfq9rkAuKAg79PAvzU47tSWFTKEEMIgfTPBrVUeXX6d0iEuvvfIUaXP8/k1ji+dp6wqI3XHTxhWF84gs196udT+Y8aOLX2OgfkxWiwsnmKCWxO21+3UuUIIoRdESIwQQgiL6MeKof+ecTKSnM2urm1/TtKxXSxSCCEsFvq2YiCNbHq3pJW7XZAQQiim0T2PoQvmkWYzH9HtgoQQQqGsj6HfYiX1ex/DqcAtkr7b7YKEEMKiFKOSOs3285LOBA4HGo6plDQZmAwwfsKqHSpdCCGQhib1mf6ryhZ1InAosEyjHWxPsb2d7e3GjV++cyULIYQ+1PcVg+1nSCEyDu12WUIIIU992sfQ9xVD5nggRieFEHpOP45K6ts+BtsTc+8fB5buYnFCCGFREURv8VUl7tE3bv90qf2P2eTk0uewy685VDbuEcD4pZYstf+cV2aXPkcIi6t+HJXUfyUOIYTQVvHEEEIIbRRNSSGEEBaI6KrDJGk+cGt27tuBg22/VJd+H/AB2//Klga9Hbgjd5jv2z5T0v3AC6T1ox8jLfP5WKe+SwghNCeIPoZhedn2VrZfD8wBPl6Q/gzwqVyee7LPaq8zc5/tbHsLYBrwpY58gxBCWIx1uyq7GnhtQfo1wJolj/XnBscKIYSukVT51S1d62OQtASwJ/CHuvSxwK7Az3LJG0i6Kbf9adtX1x1yb1JTVNG5IlZSCKHzFMNVh2tCdpGfBjzIwgqglv4YsCpwWS5PfVNSvlL4U5ZvOeDbRSeMWEkhhO6oHg5juJ3WkvaQdIekuyV9seDz10j6k6QbJd0iaa+hjtmNJ4aXbW/VKF3S0sAlpD6Gk4ZxvJ1tP9XSEoYQQiuItnY+Zy0spwK7AzOB6yRNtT0jt9sxwHm2fyRpU+AiYN1mx+25ZxzbL5HCaB+VNTeFEEIo9kbgbtv32p4DnAPsW7ePSS0qAMsDjwx10J688Nq+UdItwCRSB3V9H8NptofzNBFCCF3V5nkMawIP5bZnAm+q2+dY4FJJnyYtT7DbUAfteMWQD37XLN32PrnNCQ3yrNu6koUQQmsJIY2oYWZlSdNy21NsTyl5jEnAGbaPl/T/gF9Ier3tgUYZevKJYXFQNije0RdPLn2Ob+9Z9v9HNREUL4SKBIzsieEp29s1+fxhYO3c9lpZWt6hwB4Atq+RtBRpmYInGh205/oYQghhcdLm9RiuAzaUtJ6k8cCBwNS6fR4kTQFA0ibAUsCTzQ4aFUMIIfQp2/OAw0gjOW8njT6aLunrkt6Z7XYU8FFJNwNnA4d4iJj90ZQUQght1O4gerYvIg1Bzad9Jfd+BrB9mWP2/BODpPmSbpJ0m6RfSVpa0rqSbqvb71hJn+tWOUMIYREpvGr1V5f0fMVA46B7IYTQ89o987kd+qFiyGsUdC+EEEKL9E0fQ6Oge8PMG0H0Qgjd0YdB9PqhYpiQm/V8NSno3uoN9i3sac8mhEwBmLjCRk1740MIoVW6HT67qn6oGBYJuifpaWDFuv1WIq38FkIIvaMPnxj6r8SA7VnAo5J2AZC0Emlm31+6WrAQQqjTj53P/fDE0MgHgVMlfT/b/prte7pZoBBCWBz0fMXQJOjeDGDnDhcnhBCGrzaPoc/0fMXQC5aauHTpPK/MeqnU/lUC4p065z9L5/n0hG+VzjMwf36p/ZcYV/6/1by580rnGbfk+PLnmTO31P5DRA4IYWhdbBKqKiqGEEJooxGG3e6KqBhCCKFdRh52uyv6ryoLIYTQVn1bMUj6k6S316V9VtKPulWmEEIYTO1ej6Et+rZiIMUVP7Au7cAsPYQQeoNU/dUl/Vwx/Bp4R7ZqEZLWBdYghc0IIYTuE2nmc9VXl/RtxWD7GeBaUmA9SE8L5xWtTCRpsqRpkqbNnfNcJ4sZQgh9p28rhky+OalhM5LtKba3s73duPHLd6xwIYTRbgTNSF1sSur34aoXACdI2gZY2vb13S5QCCHkdbMTuaq+rhhsz5L0J+A0otM5hNBrRITE6JKzgfNZdIRSCCF0mfpyglvfVwy2f0eql0MIIbRA31cMnbDF9puUzjPj2rtL7T/r2fKjpT677HdK57n0PVeVzvNv5+5Qav9xE5YqfY55c2eVzjN39pzSeULoJBGxkkIIIeT1aaykqBhCCKFtYj2GEEII9bo4H6GqllZlkizp+Nz25yQdm70/VtLDkm6SdJukdxakz5A0KZdfko6RdJekO7PAeZvlPr9f0q2SbpF0qaTVWvl9QghhNGr1M85s4N2SVm7w+Qm2twLeC5ymhb0ytfR9gf+RNC5L/xTwFmBL268Dvg1MlZTv3dzZ9hbANOBLLf4+IYQwMhEriXnAFOCIZjvZvj3bd+W69LuAl4AVs6QvAIfZfin7/FLgb8BBBYf9M/DakRQ+hBBaqrbmc9VXl7TjzKcCB0lqGJRI0puAAeDJuvRtgLtsPyFpOWAZ2/fWZZ8GbMai9gZubXC+CKIXQuiOMar+6pKWdz7bfl7SmcDhwMt1Hx8h6d+BF4ADbFupY+YISR8CXgfsU/KUf5I0H7gFOKZBmaaQnmSYuMJGsbp7CCE00a5RSScCNwCn16WfYPu4gv1PsH1c1iH9M0kbZBXMi5LWr3tq2BbIz9La2fZTrS1+CCG0SB8OV21LibO1Es4DDi2ZbyqpqejgLOl7wEmSJgBI2g3YATirdaUNIYQ2irDbgxwPHFYh39eBsyT9BDiZ1BF9a9Zc9Biwr+36JqoQQug9UldHF1XV0orB9sTc+8eBpXPbxzbIc2zd9vXARrmkr2WvorzrVi5sCCF0Qh9OcIuZz8Nw7SXl1/8ZM3ZsG0oyWJUgcrud9f9K5znmqo+W2v8bb/tx6XOEEHpHVAwhhNBOfdj5HBVDCCG0S5/2MfRciSXtl8Vc2jjbXlfSy7lYSmdKWjXbvknSY7lYSzdJGt/t7xBCCAvEqKSWmAT8Jfv3q1naPba3kjQWuAzYLYutRBakb1aD+REhhNBdfdiU1FMlljSRNE/hUArWcLY9H7gWWLPDRQshhFGjpyoGUnTVP9i+E3ha0rb5D7Ooqm8C/lDmoBErKYTQHSNoRupiU1KvVQyTgHOy9+dk2wAbSLoJeBx41PYtZQ5qe4rt7WxvN258w9h+IYTQWqIvw273TB+DpJWAXYDNJRkYC5gUrbXWx7Ay8FdJ78zCZ4QQQs8y4D6c4NZLTwz7A7+wvY7tdW2vDdwHrF3bIQuW90Xg6C6VMYQQFnu9VDFMAs6vS/sNi1YCvwOWlrRjR0oVQgiV9edCPT3TlGR754K0k4CT6tIMbJnbPrbthQshhKr6cLhqz1QMvWztTdYrneeh2+9rQ0kGG7/UkqXzjFuy/Py/srGPzt/8tNLneNetHy6dp4qy379KPKoQ8vqxjyEqhhBCaJfams99pv9KHEIIoa3iiSGEENqpD5uSevKJoUkgvRsl3S7pWkmH5PY/RNIpXStwCCE0EhPcWqZRIL2tASStD/xWkmyf3qUyhhDCENSXnc8998QwVCA9ANv3AkcCh3ewaCGEMCr04hPDgkB6kmqB9J4u2O8GYOPhHFDSZGAywPgJq7asoCGE0JSIUUkt0iiQXr1hP59FEL0QQrdYYyq/uqWnnhiGCKRXb2vg9g4WL4QQSupu+Oyqeu2JYchAepBGKQHHASd3vIQhhFBCu58YJO0h6Q5Jd0v6YoN93pctjTxd0llDHbOnnhhIzUbfqUurBdLbQNKNwFLAC8BJts/I9lkCmN2pQoYQQi/Iljs+FdgdmAlcJ2mq7Rm5fTYkXUO3t/2spFWGOm5PVQzDDaRXYDPgrrYUKoQQRqK9TUlvBO7ORmoi6RzSAJ4ZuX0+Cpxq+1kA208MddCeqhiqkHQxMB44tl3nePaxZ0rnWWmNISvlQZ55ZMjf1SJSoNlyXp71Uuk8Kvkf+8B7PlX6HBe+5YzSefa5pnA0c1Pz5swtnaessj8vAFWYzDQwf37pPJ1QJVDjYhuscOSxklaWNC23PcX2lNz2msBDue2ZpOWP816XiqK/kvptj7XddHnkvq8YbO/Z7TKEEEKRFqzg9pTt7UZYjCWADYGdgLWAP0va3Pa/mmUIIYTQLu0ddvowgwfnrJWl5c0E/mF7LnCfpDtJFcV1jQ7aa6OSQgghDN91wIaS1pM0nhQtYmrdPr8jPS0gaWVS09K9zQ7aExVDmaB5kt4m6Zq6/EtIelzSGl0ofgghNGRU+TXkse15wGHAJaR5XefZni7p65Leme12CfC0pBnAn4DP2y6KJrFArzQlDTtoHvBzYC1J69h+INt3N2C67Uc6XO4QQmhCbZ/BbPsi4KK6tK/k3psUW+7I4R6z608MZYPm2R4Azqvb90Dg7DYXNYQQytOY6q8u6XrFQC5oHulxZ9sG++WD5p1NVjFIWhLYizQRrpCkyZKmSZo2d85zrSt5CCEshnqhYigdNM/2NGCipI2APUk97g0nG0QQvRBCVygNV6366pau9jGMMGhe7alhE6IZKYTQg9yBPoZ26Hbncy1o3sdqCZKuYnhB884mDctantQ/EUIIvacPo6t2u2KoGjQP27dLehG43vaLHSpvCCGUEk8MJY0gaF5t361aXqgQQhjluv3E0BdmPVt+JJP+1f7Hx2VftULpPFWC9ZU1+6WXS+fZ77qDSuf50cCXS+f5uL5WOk9ZVYIbukcD4lWx2AbEq2R4E9V6TVQMIYTQRtGUFEIIYSERnc8hhBDyhHtiulg5fVFiSbNy7/eSdKekdSStJukcSfdIul7SRZJe182yhhBCv+urJwZJu5JGLL0deBD4G/Bz27XwGFsCqwJ3dq2QIYSQacFCPV3RNxWDpLcCPwH2sn2PpF2AubZ/XNvH9s1dK2AIIRSIzuf2WZJssQnb/8zSXg9cP5zMkiYDkwHGT1i1LQUMIYQi/ThctV+qsrmkZqNKoS8iiF4IIQxfv1QMA8D7gDdK+lKWNh1oFKI7hBB6QAqiV/XVLf1SMWD7JeAdwEGSDgWuAJbMmokAkLSFpB27VcYQQqgXYbfbzPYzkvYA/gw8CbwLOFHSF4BXgPuBz3avhCGEsJDpzz6GvqgYbE/MvX8IWC/38fs6X6IQQhgGxXoMi621Nlq3dJ6Zd9zf8nLUqxKsbMJyE4feqc7Lz88aeqecVddds/Q5Hr//4dJ5qgTEu/Sdl5Xa/+2//7fS56gSRC+EXhIVQwghtFE0JYUQQhgkmpJGSNJ84FZSuW4HDrb9kqTVgBOBNwD/Ah4ndTLPyfa7AxhP6pT+pO2BLhQ/hBAW0Y9PDL1Wlb1seyvbrydd9D8uScD5wJW2N7C9LWnpz9oU5nuyldy2ADYF9utGwUMIoZ77dB5DTz0x1LmadLHfmQYxkSStm0ubJ+lvwGs7W8wQQli89NoTAwCSlgD2JDUrDSsmkqSlgV2zPCGE0BOcLe9Z5dUtvfbEMEHSTdn7q4GfAR8fIs8GWR4DF9i+uH6HCKIXQuiWCLs9ci9n/QULSJoO7N8kzz31eerZngJMAZi4wkYxyDyE0DF2/1UMPdmUVCdiIoUQQgf1fMXgNI30XcBu2RKe04FvA491t2QhhDCUtOZz1Ve39FRTUj4mUl36IzSOifT69pUohBCqiyB6i7G5s+d2uwiFZj3zXOk8Y5cYWzrPsq9aodT+TzzwSOlzdMq/Td291P7nrnty6XMccP9hpfOExVdUDCGEEAbpx4qh5/sYQgghdFY8MYQQQtt0d6JaVV17YpBkScfntj8n6djs/RmS9q/bf1b277pZ3m/kPltZ0lxJp3So+CGEMCy2Kr+6pZtNSbOBd0tauULe+0jrP9e8F5jeklKFEEKL1EYl9VtIjG5WDPNIs5GPqJD3JeB2Sdtl2wcA57WqYCGE0CpRMZR3KnCQpOUr5D0HOFDS2sB8oOEYSUmTJU2TNG3unPJDPEMIYTTpasVg+3ngTODw+o+Kdq/b/gOwO3AgcO4Q55liezvb240bX6UOCiGEauKJoZoTgUOBZXJpTwMr1jYkrQQ8lc9kew4pHPdRwK/bX8wQQiiresfzaO18BsD2M6T+gUNzyVcCB0gan20fAvypIPvxwBeyY4QQQk8xMIAqv7qlV+YxHA8siCNg+0JJ2wLXZ+tA30PBugy2pxOjkUIIoaW6VjHkA+bZfhxYuu7zrwFfK8h3PwWB82yfAZzR4mKGEMKI9OMEt155Yuhpj9//cLeLUEhjyrcEzps7r3SeF57+V6n9lxhX/r/VmLHlg/vNeWV26TxlVQmI96P5Xymd51Pjv1k6z8D8+aXzlFXl9+KBgfJ5vJiun+X+XKgnKoYQQmijeGIIIYSQ093RRVV1fVRSCCGE3jLiikHSfEk3SbpN0q8kLV2Q/ntJK+TybCbpCkl3SLpL0n9KUt1xb5J0Tl3aGZLuk3SzpDslnSlprdzn91eMvRRCCC03mmMlvWx7K9uvB+awcFhpPv0Z4FMAkiYAU4H/tr0RsCXwFuCTtQNK2gQYC+woKT/xDeDztrcENgJuBK7IzXcIIYSeEhPc4GrgtQXp1wBrZu/fD/zV9qUAtl8izWH4Ym7/ScAvgEuBfYtO5OQE4DFgz5aUPoQQWmxgBK9uaVnFIGkJ0gX61rr0scCupKcEgM1IoSwWsH0PMFHSclnSAaQgeWeTKolmbgA2HqJsEUQvhNAVo/WJYYKkm4BpwIPAz+rSHwNWBS4bzsGyUNpP2X4QuBzYOouV1DDLUMeMIHohhDB8rexj2Mr2p7PgdgvSgXVIF+9PZekzgG3zB5C0PjAri7Y6CdhY0v2kUBjLAe9pcv6tgdtb8D1CCKGlRtLx3O+dz01lfQiHA0dlzU2/BHaQtBss6Iw+CfiupDHA+4DNba9re11SH8MizUlKDgdWJ4XgDiGEnjNam5KGZPtG4BZgku2XSRf7YyTdQeqTuA44BdgReNh2ftGdPwObSlo92/6epJuBO4E3ADvnnlKWIC0ZGkIIPaHdTwyS9siG/t8t6YtN9nuPJOdWvmxoxDOf88HwmqXb3if3/lZgp4JsVwFvrss3H1gt2zykUTkkvRqQ7ReGU+4QQuh32eCeU0mLls0ErpM01faMuv2WBT4D/GM4x10sQmJIeifwXeDoNh2/dJ5Xv2b1oXfKeeKBhiuTNtSJIGpVVAnUN65CQMBe9YmxXy+d5+Kdzy+d55C7P1Fq/1nPPl/6HC8+F/dZI2IYaG98wDcCd9u+FyCbFLwvqS8377+A7wCfH85BF4u/RttTbW9s+8xulyWEEGpaMPN55dpQ++w1ue4UawIP5bZnsnDOGACStgHWtv1/wy33YvHEEEIIvWqEnchP2R6yT6CRbEDP92nSDF8kKoYQQmijNi818TCwdm57rSytZlnSwmZXZk3iqwFTJb3T9rRGB+2LpiRJs3Lv98oC6K0jaSNJV2YB926XNKWb5QwhhA67DthQ0npZzLgDWRhlAtvP2V45N/z/70DTSgH67IlB0q6kOQ9vt/2ApEuAE2xfkH2+eVcLGEIIg4iBNk5Usz1P0mHAJaTAo6fZni7p68A021ObH6FY31QMkt4K/ATYK4utBGly28zaPtkw2BBC6Amm/Ut72r4IuKgurXB9Wds7DeeY/VIxLAn8DtjJ9j9z6SeQwm7/jRSJ9XTbiyxQnPXkTwYYP2HVDhQ3hBCSflzOui/6GIC5wN+AQ/OJtk8HNgF+RZow93dJS9ZnjiB6IYRuiVhJ7TNAiqH0Rklfyn9g+xHbp9neF5hH6oEPIYRQUb9UDLVgfO8ADpJ0KCyIETIue78a8CoGD9UKIYTuyWY+V311S7/0MQBg+xlJewB/lvQkqfnoB5JeyXb5vO3HulbAEELI6UTnczv0RcWQD8hn+yFgvWxzKnBkVwoVQgjD0I+dz31RMXSbK/xmn3zw0TaUpDvKBhGs8vOaO3vO0Dv1iXFLji+d5xOPHVE6z/+sWDgisaH97j+49DmWX+VVpfM898TTpfOE3hIVQwghtFE7J7i1S1QMIYTQRv3YlDTiUUmS5mexim6T9CtJSxek/17SCrk8m0m6Ilt16C5J/6kG7RWSjpX0uez9UpIuk3Rstv1lSdMl3ZKd600j/T4hhNAqpvqynv2+tOfLtrey/XpgDvDxgvRngE/BgjWepwL/bXsjYEvgLcAnm50kCxD1G+B628dK+n/A3sA2trcAdmNwXPIQQuiuPh2u2up5DFcDry1Iv4aFi0e8H/ir7UthwfyEw4CGa5WSmrzOBe6yXdtvdVKs8tnZcZ6qWys6hBBCBS2rGCQtAewJ3FqXPhbYlYWhYDcDrs/vkwXFmyhpuQaH/w9gju3P5tIuBdbOQnD/UNLbWvA1Qgihpezqr25pRcUwQdJNwDTgQeBndemPAasCl43gHH8B3iLpdbUE27OAbUnB8Z4EzpV0SFFmSZNrS+PNnfPcCIoRQgjljNZYSbW+hK1sf9r2nHw6sA4gsj4G0iLV2+YPIGl9YJbt5yV9M+tIvim3y5+BzwIXS1q9lmh7vu0rbX+V1Bz1nqICRhC9EEI3mOhjKJT1IRwOHJU1N/0S2EHSbrCgM/ok4LvZ/l+uVTR1x/kNcBzwB0krZKu3bZjbZSvggXZ/nxBCWNx1JIie7RuBW4BJtl8G9gWOkXQHqU/iOuCUYRznR8D5pP6KlYGfS5oh6RZgU+DY9nyDEEKoph/7GEY8wS0fx6hZuu19cu9vJQXAG87xjy3YrqW9ZdgFDSGELujHCW4x87lNlhg/rtT+VWIFlY1hVNXSyxXW/Q29+NwLbSpJf6jyu7z/tnuG3qnOfpSLfXTSC0eXPsfhfLt0nrCQDQMRXTWEEEJePz4x9M1CPSGEEDojnhhCCKGNFssnhlYHyZN0iKQns7wzJH20IL322lTSGEknZee5VdJ1ktbL8nw4S7sl+3zf9vyYQgihmsV1HkM7guSdm81T2An4lqRV8+m51wzgAGANYAvbmwPvAv4laS3gy8AOWRC9N5OGxIYQQk+oLe25uEdXbWmQPNtPAPeQZkc3sjrwqO2BLM9M288CqwAvALOy9Fm27yv5fUIIoX1GMIehL2IltSNIXhYKY33g7izpgLqmpAnAecA+2fbxkrbO9r0ZeBy4T9LpkvahgYiVFEIIwzeciqEdQfIOyPKeDXzM9jNZen1T0su2ZwIbAUcDA8Dlkna1PR/YA9gfuBM4obaAT72IlRRC6JZ+7GMYzqikWjC8wvSsM/oSUh/DSaQgeW/N71gXJA9SBXDYcAuZrblwMSmI3uPAfsDlTqvOXwtcK+ky4HQiLEYIoUekPoZul6K8Ec9jKBskryxJ20haI3s/BtgCeEDSGpK2ye0aQfRCCD2nH/sYWjKPwfaNWSC7SbZ/kQ0bPVnSqe3LeBYAACAASURBVMBY4BcMI0geqYlph9z2J4HlgJ9IWjJLuzY71qrAcVml8QppTYaPE0IIYUSGrBhaHSTP9hnAGcNNz/yhIO0BYJcG+4cQQk/oZl9BVTHzeRiqBKsbM3ZsG0oy2Nglyp9joML/0ipB4coat+T40nk6Ua4qVllnjdJ5/vX406XzrLjayqX2P/z+8gHxLtv/qtJ5dv91rLK7QJebhKqKiiGEENrEwMBAt0tRXlQMIYTQRv34xBDRVUMIIQxSumJoQ1C9VSVdKOnmLKjeRVn6TpIurDv3GZL2z95fmR3vJkm3S5o8kh9ECCG0Qz8OV63yxNDqoHpfBy6zvaXtTSmIqdTEQdnku+2B70gq34MZQght4hHMeu716KrNtCKo3urAzFpG21UipE4EXgTmV8gbQghtY7vyq1sqVwwtDKp3KvAzSX+S9OXaLOdh+mU2se4O4L+y+ElFZY0geiGErhgtTUktDapn+xJShNWfABsDN0p6NWmkV2GW3PuDsrUYXgN8TlJh+O4IohdCCMM3kj6GrWx/2vacfDppbQWR9TGQguptmz9APqgegO1nbJ9l+wPAdaQgfE8DK9adeyXgqfoC2X4SuAF4U4XvE0IIbTMwUP3VLS0frlo2qJ6kXXIjm5YFNiA9idwFrCFpk+yzdUgd1zfVnzPLvzVp0Z8QQugJI2lG6vsgevVKBtXbFjhF0jxSRfVT29cBSPp34HRJSwFzgY/YzncS/FLSy8CSwBm2B/VlhBBCt42KWEltCKr3PeB7DT77K2kt56LPCo8XQghhZCIkxjBUGTa29HLLlNp/9ksvlz5HFQPzy4/onVMhT1lLL79s6TxVfmavzHqpdJ6ynnzw0bafA+Dx+x9u+znefn75AMYXbHtG6Tz7Xv+B0nn6RT+GxIiKIYQQ2sh92JYUFUMIIbRJbeZzv4mKIYQQ2qgfm5I6Fl11GMH3pmeB9I7K1nauBdJ7Lvu89qoNe7Wk43PH/5ykYzv1fUIIYXHVybDbQwXf2wzYnRRm46u5fFfnJtRtZfuPWfps4N2Syi1jFUIIHTQw4MqvbunWegyFwfdsPwFMBg6rheVuYh4wBTii9cULIYSRM/05wa3jFUOj4Hs1tu8lTYJbJUvasa4paYPc7qcCB0lqGgApguiFELoiZj4PqRZkD9ITw8+a7Zxzte29iz6w/bykM0khOBoOarc9hfR0wcQVNurDrqAQQn8yA33Y+9zJiqEWZK+pLMDefOAJYJNhHPdEUgC900dWvBBCCNBjaz5n4bZ/DJziYU43tv0McB5waDvLFkIIVXig+qtbemEeQ62JaRypQ/kXwPdzn++Ya4IC+IbtX9cd43jSqnAhhNAzUudzNCU11CT43tgmea4ECjuW88ez/Tiw9AiLGEIIreX2r6sgaQ/gB6RBOz+1/d91nx8JfIR04/0k8GHbDzQ7Zi88MSyWnn1skfWEWm7e3HltP0enPPfE090uQsv04x1iI1WCLlYJiHf0xZNL7f/tPaeUPsfiKFtK+VTSHLCZwHWSptqekdvtRmA72y9J+gRpLZwDmh23p/oYQghhcWO78msY3gjcbfvebDXNc4B9687/p2wBNYC/A2sNddB4YgghhDYxIw6it7KkabntKdnw+5o1gYdy2zNpvsTxocDFQ520JyoGSauRhp2+AfgX8DjwO+Cd+TkMks4ALrT9a0lXAqsDr5BCbHzU9iLLfoYQQtd4xGG3n7K9XSuKkq2IuR3wtqH27XpTUhb64nzgStsb2N4WOBpYdRjZD7K9JfBDGqwCF0II3dTmmc8PA2vnttfK0gbJgo9+mXSzPXuog3a9YgB2Buba/nEtwfbNpNnRw3UN6ZEqhBBGk+uADSWtJ2k8cCAwNb+DpK2B/yFVCk8M56C90JT0euD6ER5jD1LTUwgh9JR2Rkm1PU/SYcAlpOGqp9meLunrwDTbU0mtKROBX2WxSR+0/c5mx+2FiqGRRj/NfPovs1pyItAw3IakyaSorYyfMJwWqhBCGLkSo4tGco6LgIvq0r6Se79b2WP2QlPSdGDbgvSngRXr0lYC8hMEDgLWB34OnNzoBLan2N7O9nbjxjcNxBpCCC3VjyExeqFiuAJYMrurB0DSFsCrgDUkbZKlrQNsCQwaeZTFVPpP4M2SNu5YqUMIYRgG7Mqvbul6xZBd2N8F7CbpHknTgW8DjwD/DpyexUr6NfAR24ssqGD7ZVK8pM93ruQhhLB46ok+BtuPAO8r+Ogu4M0N8uxUt3180X4hhNBN/RgipScqhsXRPh/codT+vz/zL6XPMfTqp93Rj38IrVTl9/KBw3Ysned/f/jXUvtXiXvUKWVjH/3w+8NZqmWwTx55e+k8I2W3d1RSu0TFEEIIbdSP90ld72MIIYTQW+KJIYQQ2miEsZK6omVPDJL2k+TakFFJ60p6WdKNkm6XdK2kQ7LP3ibpmrr8S0h6XNIadelnSNo/e79SdrwPSRoj6SRJt0m6VdJ1ktZr1fcJIYSR8giGqnZzuGornxgmAX/J/v1qlnaP7a0BJK0P/DYLmvdzYC1J6+RWEtoNmJ6NUFqEpOVJ076n2D5d0iRgDWAL2wOS1gJebOH3CSGEERu1TwySJgI7kGJ9H1i0j+17gSOBw20PAOfV7XsgcHaDU0wkxRA/y/aPsrTVgUezY2F7pu1nR/pdQgihlTzgyq9uaVVT0r7AH2zfCTwtqSjEBcANQG128tlkFYOkJYG9gN80yPd94C+2T8ilnQfsI+kmScdnEQQLSZosaZqkaXPnLDI/LoQQQk6rKoZJpCXlyP6d1GC/BQO8bU8DJkraCNgT+IftZxrkuwLYV9IqufwzgY1IazcMAJdL2rUoc8RKCiF0hdMKblVf3TLiPgZJKwG7AJtLMin0q0kLVNfbGsjPMqk9NWySvUfS6dl+j9jeK9vvHOCvwEWSdrb9AkC24MTFwMWSHgf2Ay4f6XcKIYRWMP3Zx9CKzuf9gV/Y/lgtQdJVDF5VCEnrAscxOArq2aRFJZYn9U9g+0NFJ7F9QrYE6G8lvYO0jsNjth+RNAbYArilBd8nhBBapP1ht9uhFRXDJOA7dWm/ITXxbCDpRmAp4AXgJNtn1HayfbukF4HrbQ85osj2F7Inil+QRjb9JOufALgWOGWkXyaEEFpmtIbEsL1zQdpJwEnDzN9wgZ3s80PqtvNPFBcRQgihpWLm8zAcfPhbS+c5e8o/2lCSwfb+wPZtPwfAP666t9T+T818vPQ5Vl6r/Mp6TzxQOOWlqfFLLTn0TjlzXhly3fRFVGk6KBsQD8oHxRszdmzpc4yfUO7nBfDKrJdK5ymrGwHxqhqtTUkhhBAKjObO5xBCCEXcnxVDRFcNIYQwSF9VDJJmZf+umwXs+3Tus1NqQfpCCKE39GcQvb6qGOo8AXxG0vhuFySEEBoZzbGSuuFJ0izng7tdkBBCKGLSqKSqr27p987n75DCYZzWbCdJk4HJAOMnlB8WGUIIlfTpBLd+fmKohfL+B/D+IfaLIHohhDBM/f7EAPAt4NfAVd0uSAgh1Ivhql1g+5/ADGCfbpclhBAGq96/EH0MI/dN4MZuFyKEEPJs8MBAt4tRWl9VDLYnZv/eTwq7XUu/mcXg6SeEEHpBX1UMrfDic3c+9bcLd3qg4KOVgaeK8vztwoaHa5inRfs3zdPCclXJ04lzdCpPr5arU3l6tVxV8rTyHOuUPE6hfhyVNOoqBtuvLkqXNM32dmWOVTZPJ87RqTy9Wq4qeXq1XJ3K06vlqpKnU+UqI6KrhhBCWMjdncFcVVQMIYTQJv0adjs6bBea0oE8nThHp/L0armq5OnVcnUqT6+Wq0qeTpVrsaZ+bP8KIYR+sOKqm3vnA86vnP/8kze8vp39H41EU1IIIbRLny7UExVDCCG0iYnO5xBCCHX6sbk+Op/7mKRTJW3fgfPEDUQIo0hUDICk7Vq9EpykVSSdKOlCSd+WtFwrj5+5EzhO0v2Svitp6zaV7dqRF3XIMq1WMd9riypHSdtL2qBBnv0kfU7S26ucc5jlWqnJa5lhHmOcpK0lrdJknzfkf3aSPijpAkknSVqpFd8lO+4SkpS9X1vS/sP9/zbC875O0k8K0teRtHxue2dJP5B0ZE+t6mgYGBio/OqWUT8qSdLqwAPAh2z/ssl+X2lyGNv+r7r9/wBcD/wZ2BtY1vYhQ5TlyPrjkqbq/8X2fU3yrQMcmL0mAGcDZ9u+s8H+pcom6Ubbw74ISDo5K3uR2cA9wC9tv5DL8xhwW1b239j+1zDPdSFwtO1b69I3B75le5+69B8CmwF/A3YFfl//uys4x0nNPrd9eEGe+0g/AxVkqT2BfTH/f07Sj4GTbU/PLnrXAPOBlYDP2T674Dw3ALvZfkbSW4FzgE8DWwGb2N6/bv99gFtsP5BtfwV4D+lv4DNF/88kfZS0KNYs4L+AzwM3AFsDp9n+TkGesn8vWwDHAWsAvwNOBU4B3gQcb/uEuv3/AbzL9iOStgL+CHwb2AKYa/sjRSeW9MEm5cL2mc0+L2uFV7/eO+x3XuX8//fTzboyKikqBumLwAbAa23v3GS/owqSlwY+AryqFuAvt//NtrfMbd9ge5shyvLVguSVgLcDx9o+p1n+7BhbA6cBW9ge22CfUmWTNBP4fqPPbQ/6TFKz5VaXIF2YN7e9ey7PWGA3UuW2F/B3UiVxge2Xm5TtOttvaPDZrbY3r0u7DdjS9nxJSwNX2962SXmRNIdUaZ0HPELdxd72z5vlb3DMVwNX2d40lzbd9mbZ+88CO9neL3siuLiocs7/LiWdCjxp+9hs+ybbW9XtfwvwZtsvSdqb9HudRLrIv9f2Ik9RkqYDOwDLArcD69h+Kvv5XVcrc12esn8v/wB+RKoM9wC+BPwc+IrtVwqOf4vtLbL3xwEDtv9D0hjgptpnBflOLkoH3gmsabulzabLv3oz77DvuZXzX/SzzWO4apd8AHgbMFXSBrbvKdrJ9vG195KWBT4DfJh0h3Z8UR5JK7LwIjI2v237mYJzfK3BcVYi3REVVgxZH8CepIvqrsCVwLFF+1Ys21hgIhTe/S5iOBdKSRfV5ZkPXAJckjUF1L7PiZIut31Qg0Ot0OQ0EwrS5mTnIrs4Duc7rQ68FzgAmAecC/x6qKea3O9l4yxpBnCJ7Xm2n5T0hfqy5d7vDvwqK+djTYo5VtIStueRfveTc58V/X3b9kvZ+3cDP7N9PXC9pE82OMcc288Cz0q62/ZT2YFeyirNopOU/XtZ0vYZ2fs7JH3G9n80KA8M/r+4C3B0dt6BZr9S25/OlUvAQcAXSDci32xyvlFlVFcMknYG/pnd/ZwBHEq6U2m0/0rAkaT/TD8Htsn+YIosT2quyf8vvSH718D6wy1n1kywyP92SbuT7vb2IvUDnANMtv3iEIcsW7ZHbX99uOXNynYw6WKwUZZ0O3BS7VHd9l6N8tqeI2lGlmdbYJMmp5om6aO2B7VDS/oI6TvW2zi7a4b0/TfItpVOveidpu2ngR8DP5a0FqnCmiHpC7Z/UVQoSWsCVwCPktYKEanZ7vuSdrb9iO3f12X7V3YX/zCwPen/Y62CKarkID1VXSXpKeBl4Oosz2uB54qLponAS6SK5Ie5z5ZqcI4J2ZPoGGB89l7Zq1Gesn8vS+WOCzA7v237hrr9r5B0HunnuyLpZ11rGi6srHLlWgI4BPgcqULY3/YdzfJUFvMY+tKHgZ9l788h3TUdY3uRXh9J3yPdYU0hNYPManZg2+u2qpBZBVb0B3U0cBZwVJM/uEVUKFvDWzBJ29v+a13awcBnSReFG7L82wDfk+QmF9O1SRfdScAypIveO51W6Wvks8D5kg5iYUWwHTAeeFfB/s0qmaYkbZOVbXfgYoornppvAj+yfWLdMQ4ntYUXNbd9DDgJWA34rO3HsvRdgf8rOontb0q6nPRUc6kXtg2PIV346p0I3AQ8D9xue1pWrq1JF9kij7GwKTH/vra9iLJ/Lw2OW9s26akg77OkJ7jVgR1sz83SVwOOaXQSSZ8i3bBcDuzhtLZLW/VjxTBq+xgkrQBMAzas/TFJ+gVwru1FVjqQNEDqOJ3H4I7V2p3mcnX7/7vt/83eD7p4SjrM9ikF57i17tiQ+hgeAT44xAWylKy55iBSez/AdOAs27ML9l2FdHFaE/iD7duyO9svARPq274l/R04sP6PTtK6wDm231xwjr9lx/8VqeO82UU3n29t2w9llWdt8abptq+QtHf97zK7k161oDLbHnisqClR0teBd5CeYM7JfgbzhijXP21v3OCzO2xvVJC+tu2HGuRZ5Ltk6V8peppT6ry+wPZOBZ+tCawC3Fy7Ccr6McbbfrDZ9xqusn8vFY5/cFGTpaRxwJm2JzUp1xPAkw3KVdg3UdXyK2/qN7/jrMr5Lz1z6+h8XpzkO3TrO3frt3Pp9QuDGHh6GE1DZcu2KTAV+CsL73q3JTVf7Gt7et3+ZwBrk5qr3kSqqLYjjar5XcHxZ+Q7VYfzmdKImqtd8j+kpH9ScOcn6UPAMbY3qEsvNYop+2wAuI/U/AILLygNLyZqMpKr0WdNvsuHgS/Xf5fss0tJHcBfzqWtSuqv+W19pZH9H/uX7eey7Z2B/Uijkk6xvUgzjKR31yXVRsvd5NzIspEoew6l0Vg/tj0ll7YMcD7wkO1DG5yn6eI7zkZrtcpyr9rUb96r4WDHIV32v9tE53OnaIjx3QWdr5VO0+B90XbN48DHgdcCt5I6BpvemVZ0MvAJ25cNKpS0G2mIYP3orDeQmgMGJC1FeszfIGt7L9JwFFGjz2z/WdLBWVNL7U57UL9EA0cCl0p6h+27su9xNPB+0qCCeqvWVwrZ+W/NnmiKrNfk/I0sX3Cxg/S7b3S3XPa7QBpN82tJ37d9pKQNSc1cx9n+ccH+55Ga2J5TGub5K1LT1pak/oaiYZ6LVJakJ9ktJB1q+4pFvqS0Sy1d0nrODYOV9G7bvx3hOXYD/iBpKdsnKY3yugi43PYXC44FtP7Cv7galRUD6S65Nsb8NaT2e5FGuDxItQtBPTd4X7Rd83NgLqkDcU9gU1J7aKutWV8pANj+o4qH882uNTnYfkXSvU0qBYBNch28eaJBp3vVfgnbF0maDVwsaT/She2NwFsb9LuUHcVU9WJyFcUXO0jzR4rOU/a71H4f7wLOlXQ28BZS/0SjkJ4TbD+Svf930jyE45UN82xwjg8VpWd33+eRniLrHUf6/QH8JvceUh/AoIqh7DmcBmTsRvpZrQHsS3qC+EHRcXLHe4Hiv7+WNHEVcRcnqlU1KisG2+sBKM2oPN/2Rdn2nqTH6laojX7Jj3yBJhdHYFNn4+4l/Yz2zTgeI2nJ+v6E7Gmg6P9Es5E8A87NicgUdfCK1Bx1dIMyfYI0Yen+XNoVkt5DatcvrBgAbF+eNR1dSZq4tosLxr5nyo5iKrqY1Jo5/gR8oaiSbHShy463aou+C1o4KfIfwH+QbirWq6W7bo4JVBvm2aCsD2Rt+oVFa/C+aLv0OXJPY1NIndSXAw/V0gueSGrHW3a4526JGJXUl95s+6O1DdsXS/pui45dZfRLbWQFtueV/UMt4UzgN5I+5YUzYNcljYgpugCXutDn77CVRru8nzQP4D7S3WOR5erb1rNj3a8mITtyF20BS5I6yZ9Q+uEV3QGWHcVUeDFRmvdxCGkY63sblS+3/wqkGcbvJ/0812jBd4E06azmpIK0epWHeRaUdyNSB3ORKk/MRefYuME58k9jU+vSTN0TSfeYgkGOPW+0VwyPSDoG+N9s+yBSx+qINWp+yB7ZJ5E6++ptKen52q6k8ePP0+LHXNvfkHQYcLXS7FWAF0nt0os0JZW90Et6Hek7TiLdWZ9LGujQcGY5FfolsrKVugO0/TjwFg0exfR/Re3kQxznWeAESR9otI+kCaQmjveTZhYvS3oibdSUVPpu1g0mRTbRbJjnl4sySPo9xaPlVic1RxVZX9JUsifk7D3Z9iJNtWXP0eyJrJcYGIgnhr4zCfgqaSQDpD/YwmFuZWV3uZ8iDcGcClwGHAYcBdwMLDJUwQ1CWLSD03DZU5RmpdJsdEmFC/0/SU0ae9u+OzvGEUMUqXS/RBVZc1lLOvizJo7CvyFJZwE7ApeSOvuvAO62fWWVc5UsV7MQJxs5C60iaclaou0bJS0yjDhzXN22gaeBu4pGMWX2bZK/fhvS38iqZBP0cud4FWl46ZAkXWh77+HsG5ob1RVDNvqoHZ27kJpkniXFfvkIacy/gP1sF3bydZJSbKIVnYU3UJrXcAhwhO36pqOyF/p3kyaq/UkpYN85DN2uXKVfoor6Dv5NSHfRDTUYXbQi6c771w2ybUr6/d9Omkg2X1Knbh2b/azPYmFH8DUM7hT+Yd02ALavGnRw6VXAW0nNXfUzkhfJk40YwvaTTcq1L42HEZ9I4478vDWHsU9nOTqf+072H/Y/SJO8Fkztt10/y7KK9XMdyT8ltem+pllHYqdIOhD4H+BFSXeRZumeBlxHak6rV+pC7zS34XfZuPJ9SRfeVST9iNTZf2lBnir9ElVU6eCvvyjV7mZ/YLvRjOStsvbxScAflUJWLCtp1aw5q50Ky5Qp3SmsNPfji04TG1cnVQbTSIMQprhudneWR8BXSJFex2RJ80jRY4vCq5QaRixpNS+cGV5zY1H5uytWcOtHvyQ1i+xNal44mDQjshXyHcnzJc3shUohcwywre27lcI8XEOKF1MfuweodqHP8r1IukM9K+usfS8pYNki+1fsl6iidAd/1fZsp5nqXwW+KmlbUmV3XfZ/4S1VjtmMUgwkbDcMCUG1TuH1bN+Wvf8QcJntD2bNkH8l3dHXO4IUkfUNtTkMktYHfiTpCNeF0ab8MOKblCLlLgjTbvvDTY7RNe3ufJa0B/ADUrDLn9r+77rPlyQNONmWdENzQNFAj0F5PIpnPku63va2GhzCt2EY55LHnk/q0K1deSaQZs62bbx0ibLVz8S+zfbrm+UpOEbtQn+A7V1bUKYBUvPOobnmqnttt6x/ITtm7fcCWQc/Q/xeVHJtgYL8tQv2rOxOekfbhR3QVShFRf0iKb6UgBeA79j+YcG+T7Dwie8AFkbsFfA+24sMpVUufLdSXKaf5PopFgntnaXfCOxea6rMpb+aFNOpPozK2cAVDYYR7277gLr0SmHaO23ZFTf21jv9tHL+q3+3Y9OZz9nP4U5S/K6ZpKf+SbZn5Pb5JCkM/8ez1oJ31f886432J4ba3eOjkt5BGpHUklWvOtmRXMEqGrwo0Ar57YKx74vIRuVMyV6tUKVforSKv5eikCTLkKKfvoq0eM0ichfsidl2wwt2VdmoureQ1m64N0tbH/iBpJVsf6Muy+dz76fVfVa/XfOQpE+TLjzbAH/IzjMBaDSPYVx9pQCpn0HFcx9KDSN29TDtndX+eQxvJA1qqP3uzyE91c/I7bMvC8Pw/5o06ERu8lQw2iuGbygFGzuKNHJkOdIj8IjVjX65hTTDtB3hLar4CYPHutdvd1zV5qoOla1obYEP0XwtjrIX7Ko+QFp4aEEzpe17Jb2PNPpt0Hls/zy7a1+HdEEZzkp5hwJfJ92hH5DL82bg9AZ5ms2JWOSzkQwjdrkw7R1l3O7O5zWBfODFmSw6E33BPlnz6XOkG5pFKu6aUd2U1E6SzmXw6JcHbLdrBFQlklYuuqvrFa1urhphWerXFviBm4Q6l3QHdRfsLH0CKarp61pUrmZRXBf5LGua+RZpedX1SOt3TC3K3+CYC5rFhtivvik1H3hwKduNnjSGTcVh2s9xC6MQj1T29LvyCA6xFJD/PzTFgwMH7k8KvPiRbPsDwJtsH5bb57Zsn5nZ9j3ZPg3/9kf1E0PtDg74f8AAqRP2iNod3gh1KrxFaUohs08H5mZt+++z/bcuF2sRbWiuqkTl1xaA1PewyGAD2y9nP/NWeVjSrrYvzydK2oXi9RU+C2yWNemsTxqAMWTFIOkTpGHDy6TN5s1i7W5K1eAw7R/1MMO0d5rtPdp8iodJQ7pr1srSivaZqbRI0fKkTuiGRnXFQBoxcyoL2zAPJN11FAUFK6tT4S2q+BapA/Sfkt4EfJfG0TtDamqcTRrN9eXc77LZQIKyF+yqDgcukPQXBrfNb8/gSWY1c5zNJ8ianJYs2GeQKs1iHWhK/SIVwrQvhq4DNpS0HqkCOJA0+i1vKmnE5TXA/qRO/qY/t1HdlJQfjZRLW7C4+giPXXr0S6cUjEpqNlM2VCBpM+ACoPCC7bo1L0Z4rqVIF4PaokszgF8WPbHkRiXVHJjftn14QZ7SzWKdaEpVishbNkz7YkfSXqQhw2NJFfA3lRaXmmZ7avb/4xeksCzPkBbRatoqMtorhu+QZqeeQ2oDPYA0o/V70LJ1GXqOpJkMXkbxyPz2cEYlhaGVuWC34dxjSMMWf1mXXrSk6AIuXhWtVD9Gln5rril1CeDaVt58qEmYduBENwjTHoZntFcM9zX52K0eQ98rJH212ecuH5gtDFOjC/YIjpePyXUB8Mds+3Oku/mi5qRa3uF2JF9OWt2uqFnsP10wCbHdT6WqsHxsGL5RXTGE0C4juWCXPM8FLIzJtStpLWcBn3GDmFx1HckAs2jSkVylWazdTamqsHxsGL5RWzEohZve0PbNubTXAPNt1/fqL1Y0wpm8YWhVLtgVz5NvshnLEDG5ch3Jh9V3JAP/aDS/opvNYg3Kc73tbct+FoZnNFcM40hRQ7dwiumD0sLqX7LdaAboYkHSUQXJC2by2p7Y4SItdspesEdwnlJNNq2cX9HqZrEyJL0E3F30ESmA5TIFn4VhGrXDVW3PlXQ+8D7g9Oxp4dWLe6UA1WbyhtI6FUSxtrjTgphcar64U+n5FUM1i1GwtkgHdCpM+6g0aiuGzE9Jk5ZOBz5I4+n9i52CmbzbWqyQCQAAAZJJREFUNJvJG0ore8GupMJEsirzK/Jri3yUtNJbV9cWcefCtI9Ko7piyCZ4SSnk84GkFbcWexVn8oYS2j3zt6bCRLKyE+KgB9cWUefCtI9Ko7aPoUbSIcCHgYdtt2RZz16XNRnMBuYxOAZ/1yffLS46MPO3dp7SE8nKdiT34oRIdShM+2gVFUManfQo8B7bf+x2ecLioRMzf7PztGQiWbOOZPXg2iKS9iM95W9PCgN+DmmRmvU6XZbF0aivGEJoh3bP/M2dp+yopI7Mr+gULQzTPgnYhbRSWVfDtC8OomIIoQ061fxSdiJZxQlxvby2yALqoTDt/S4qhhDaoFeDKFaZX9GpZrHQO0b1qKQQ2qVTo5IqqDK/omfXFgntERVDCKNLlfkVvby2SGiDaEoKITTVq81ioX2iYghhFOmXjuTQXVExhDCKREdyGI6oGEIYRTo1vyL0tzHdLkAIoaMGdSR3syChd8UTQwijSHQkh+GIiiGEEMIg0ZQUQghhkKgYQgghDBIVQwghhEGiYgghhDDI/wfZkr6OWwoS4wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}