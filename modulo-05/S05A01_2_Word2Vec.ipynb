{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S05A01_2_Word2Vec.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq3GjT6YgNMh"
      },
      "source": [
        "# Word2Vec\r\n",
        "\r\n",
        "<img width=600 src=\"https://www.researchgate.net/profile/Daniel-Braun-6/publication/326588219/figure/fig1/AS:652185784295425@1532504616288/Continuous-Bag-of-words-CBOW-CB-and-Skip-gram-SG-training-model-illustrations.png\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsBX3PzCgBWn",
        "outputId": "53af686d-8bad-4a17-c379-a6f817571ba3"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "\r\n",
        "def make_context_vector(context, word_to_ix):\r\n",
        "    idxs = [word_to_ix[w] for w in context]\r\n",
        "    return torch.tensor(idxs, dtype=torch.long)\r\n",
        "\r\n",
        "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\r\n",
        "EMDEDDING_DIM = 100\r\n",
        "\r\n",
        "raw_text = \"\"\"we are about to study the idea of a computational process\r\n",
        "computational processes are abstract beings that inhabit computers\r\n",
        "as they evolve processes manipulate other abstract things called data\r\n",
        "the evolution of a process is directed by a pattern of rules\r\n",
        "called a program people create programs to direct processes in effect\r\n",
        "we conjure the spirits of the computer with our spells\"\"\".split()\r\n",
        "\r\n",
        "\r\n",
        "# By deriving a set from `raw_text`, we deduplicate the array\r\n",
        "vocab = set(raw_text)\r\n",
        "vocab_size = len(vocab)\r\n",
        "\r\n",
        "word_to_ix = {word:ix for ix, word in enumerate(vocab)}\r\n",
        "ix_to_word = {ix:word for ix, word in enumerate(vocab)}\r\n",
        "\r\n",
        "data = []\r\n",
        "for i in range(2, len(raw_text) - 2):\r\n",
        "    context = [raw_text[i - 2], raw_text[i - 1],\r\n",
        "               raw_text[i + 1], raw_text[i + 2]]\r\n",
        "    target = raw_text[i]\r\n",
        "    data.append((context, target))\r\n",
        "\r\n",
        "data[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['we', 'are', 'to', 'study'], 'about')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPYfR7_CftS5",
        "outputId": "9687dbff-8345-45ec-c003-cf5f45f29b18"
      },
      "source": [
        "class CBOW(torch.nn.Module):\r\n",
        "    def __init__(self, vocab_size, embedding_dim):\r\n",
        "        super(CBOW, self).__init__()\r\n",
        "\r\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\r\n",
        "        self.linear1 = nn.Linear(embedding_dim, 128)\r\n",
        "        self.activation_function1 = nn.ReLU()\r\n",
        "        \r\n",
        "        self.linear2 = nn.Linear(128, vocab_size)\r\n",
        "        self.activation_function2 = nn.LogSoftmax(dim = -1)\r\n",
        "        \r\n",
        "\r\n",
        "    def forward(self, inputs):\r\n",
        "        embeds = sum(self.embeddings(inputs)).view(1,-1)\r\n",
        "        out = self.linear1(embeds)\r\n",
        "        out = self.activation_function1(out)\r\n",
        "        out = self.linear2(out)\r\n",
        "        out = self.activation_function2(out)\r\n",
        "        return out\r\n",
        "\r\n",
        "    def get_word_emdedding(self, word):\r\n",
        "        word = torch.tensor([word_to_ix[word]])\r\n",
        "        return self.embeddings(word).view(1,-1)\r\n",
        "\r\n",
        "\r\n",
        "model = CBOW(vocab_size, EMDEDDING_DIM)\r\n",
        "\r\n",
        "loss_function = nn.NLLLoss()\r\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\r\n",
        "\r\n",
        "#TRAINING\r\n",
        "for epoch in range(50):\r\n",
        "    total_loss = 0\r\n",
        "\r\n",
        "    for context, target in data:\r\n",
        "        context_vector = make_context_vector(context, word_to_ix)  \r\n",
        "\r\n",
        "        log_probs = model(context_vector)\r\n",
        "\r\n",
        "        total_loss += loss_function(log_probs, torch.tensor([word_to_ix[target]]))\r\n",
        "\r\n",
        "    #optimize at the end of each epoch\r\n",
        "    optimizer.zero_grad()\r\n",
        "    total_loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "#TESTING\r\n",
        "context = ['people','create','to', 'direct']\r\n",
        "context_vector = make_context_vector(context, word_to_ix)\r\n",
        "a = model(context_vector)\r\n",
        "\r\n",
        "#Print result\r\n",
        "print(f'Raw text: {\" \".join(raw_text)}\\n')\r\n",
        "print(f'Context: {context}\\n')\r\n",
        "print(f'Prediction: {ix_to_word[torch.argmax(a[0]).item()]}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Raw text: we are about to study the idea of a computational process computational processes are abstract beings that inhabit computers as they evolve processes manipulate other abstract things called data the evolution of a process is directed by a pattern of rules called a program people create programs to direct processes in effect we conjure the spirits of the computer with our spells\n",
            "\n",
            "Context: ['people', 'create', 'to', 'direct']\n",
            "\n",
            "Prediction: programs\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}