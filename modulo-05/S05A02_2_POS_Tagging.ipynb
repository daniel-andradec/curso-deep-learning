{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"S05A02_2_POS_Tagging.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"JwQ8q2eQ50GI"},"source":["# Preâmbulo\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"zCa4ECYE6e2J"},"source":["!wget https://www.dropbox.com/s/89xxqp80qhb550l/macmorpho.zip\r\n","!unzip macmorpho.zip\r\n","\r\n","!pip install unidecode\r\n","!pip install torchtext==0.6"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ctFqKwZJmkS2"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import os, unidecode\n","\n","import torch\n","from torch import nn, optim\n","import torch.nn.functional as F\n","\n","from torchtext import data\n","import torchtext\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dV4Dgo3KmkSu"},"source":["# POS Tagging\n","\n","**P**art-**o**f-**S**peech tagging, ou classificação sintática de sentenças, é uma área de pesquisa cujo objetivo é rotular palavras de uma frase de acordo com a sua categoria sintática.\n","\n","Em linguagens naturais se trata de um problema fortemente dependente de contexto, visto palavras de escrita e fala idênticas podem ter significados completamente diferentes. Ex:\n","\n","* \"*O **começo** da aula foi essencial.*\" $\\rightarrow$ **N**ome  \n","* \"*Eu **começo** a trabalhar às 8:00.*\" $\\rightarrow$ **V**erbo\n","\n","Usaremos o conjunto de dados intitulado [MAC-MORPHO](http://www.nilc.icmc.usp.br/macmorpho/#ref1), com textos jornalísticos em português, extraídos da Folha de S. Paulo. Uma amostra do MAC-MORPHO é aparesentada na imagem a seguir. Para conhecer melhor as categorias desse conjunto, consulte [o manual](http://nilc.icmc.usp.br/macmorpho/macmorpho-manual.pdf) construído pelos autores. <br><br>\n","\n","<img width=650 src=\"https://www.dropbox.com/s/nesqjcl2opd7vo3/MAC-MORPHO.png?dl=1\">\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"O0MpAF87mkS4"},"source":["## Carregamento de dados\n","\n","Para criar o dataset, exploramos as vantagens do pacote [Torchtext](https://torchtext.readthedocs.io/en/latest/). Como vimos anteriormente, suas ferramentas facilitam tarefas essenciais como construção de vocabulário e carregamento de sequências de tamanho variável.\n","\n","Uma novidade aqui é a construção de um Dataset customizado, sem o recurso de carregamento de dados tabulares. Podemos criar uma classe que herda as característica da classe [`data.Dataset`](https://torchtext.readthedocs.io/en/latest/data.html#torchtext.data.Dataset) do torchtext, ganhando liberdade para construir nosso conjunto de dados.\n","\n","Para incializar nosso conjunto, basta construir no método `__init__()` as seguintes estruturas de dados:\n","* `examples`: uma lista de objetos tipo `data.Example`.\n","  * Cada exemplo é uma tupla `([amostra, rotulo], fields)`\n","* `fields`: uma lista de tuplas `(str, data.Field)`\n","\n","Ao final do nosso `__init__()` customizado, devemos inicializar a classe \"mãe\" `data.Dataset` com a lista de exemplos e os fields definidos:\n","```python\n","super().__init__(self.examples, self.fields)\n","```\n"]},{"cell_type":"code","metadata":{"id":"9Y48SxRLmkS4"},"source":["class MacMorpho(data.Dataset):\n","    \n","    def __init__(self, path, fields):\n","        \n","        fields = fields\n","        lines = open(path).read().split('\\n')\n","        samples, labels = [], []\n","        \n","        examples = [] \n","        for line in lines[:-1]:\n","\n","            sample, label = [], []\n","            for word_cat in line.split():\n","                \n","                word, lab = word_cat.split('_')\n","                word = unidecode.unidecode(word.lower())\n","                sample.append(word)\n","                \n","                label.append(lab.split('+')[0])\n","                \n","            samples.append(sample)\n","            labels.append(label)\n","        \n","            examples.append(data.Example.fromlist([' '.join(sample), ' '.join(label)], fields))\n","        super().__init__(examples, fields)\n","\n","\n","### Defina os fields\n","TEXT = data.Field(include_lengths=True)\n","TARGET = data.Field()\n","\n","### Carregue os dados\n","trainset, devset, testset = MacMorpho.splits(path='.',\n","                                             root='.',\n","                                             train='macmorpho-train.txt',\n","                                             validation='macmorpho-test.txt',\n","                                             test='macmorpho-dev.txt',\n","                                             fields=[('text', TEXT), ('target', TARGET)]\n","                                             )\n","\n","### Construa o vocabulário\n","TEXT.build_vocab(trainset, max_size=20_000)\n","TARGET.build_vocab(trainset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BGqGJg1-Hhe7"},"source":["for sample in testset:\r\n","  print(sample.text )\r\n","  print(sample.target)\r\n","\r\n","  break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DePhh6McKv-z"},"source":["### BucketIterator\r\n","\r\n","Essa classe do Torchtext funciona de forma análoga ao DataLoader do PyTorch,  porém leva em consideração a construção de **batches com sequências de comprimento variável**. Internamente ele agrega sequências de comprimento similar, **minimizando a quantidade de padding necessária**. \r\n","\r\n","Além disso, os dados já saem preparados para serem empacotados pela função ```pack_padded_sequence``` ordenados por comprimento de sequência e informando o comprimento real de cada amostra (sem padding).\r\n","\r\n","> Exemplo: Para compor um tensor com 5 amostras de frases com tamanhos variáveis, a segunda dimensão é definida pela frase de maior comprimento. Amostras menores são complementadas com tokens nulos (`<pad>`). \r\n","\r\n","<img src=\"https://drive.google.com/uc?export=view&id=1uOf8NpztcNyV0Dq9Ch5oJoKuPnwPptqK\" width=\"450\">\r\n","\r\n","\r\n","Documentação: https://torchtext.readthedocs.io/en/latest/data.html?highlight=BucketIterator#torchtext.data.BucketIterator"]},{"cell_type":"code","metadata":{"id":"426U75dZKs8g"},"source":["### Construa o iterator (nosso loader de dados)\r\n","train_iterator = data.BucketIterator(trainset, batch_size=32, sort_key=lambda x: len(x.text), sort_within_batch=True)\r\n","test_iterator = data.BucketIterator(testset, batch_size=32, sort_key=lambda x: len(x.text), sort_within_batch=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XL4bGmFdLXfO"},"source":["for batch in test_iterator:\r\n","\r\n","    inp, tam = batch.text\r\n","    lab = batch.target\r\n","    \r\n","    print(f'Entrada (shape): {inp.shape}, comprimentos (shape): {tam.shape}')\r\n","    print(f'\\nComprimentos: {tam}')\r\n","    print(f'\\nRotulos (shape): {lab.shape}')\r\n","\r\n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IEjzRR8EXUUU"},"source":["## Padding and Packing (Preenchendo e empacotando)\r\n","\r\n","O pacote de funções de rnn, ```nn.utils.rnn```, oferece meios de processar batches contendo sequências de tamanho variável. Isso é realizado através do **padding** da sequência (ex: preenchimento com zeros),  de modo que elas aparentem ter igual comprimento, porém internamente as posições preenchidas não são processadas pela RNN.\r\n","\r\n","*  Vamos lembrar do nosso batch de frases com tamanhos variáveis:\r\n","\r\n","<img src=\"https://drive.google.com/uc?export=view&id=1uOf8NpztcNyV0Dq9Ch5oJoKuPnwPptqK\" width=\"450\">\r\n","\r\n","\r\n","*  O empacotamento precisa receber os dados em ordem decrescente de comprimento, e internamente são criados \"mini batches\" com o seu batch. Dessa forma, apenas os timesteps que contém informação relevante sobre o dado são apresentadas à rede. Igualmente, somente esses timesteps impactam no backpropagation.\r\n","\r\n","<img src=\"https://drive.google.com/uc?export=view&id=1ySh4IdDO4Iw3G8p2iSdo62MW_z4kR5fd\" width=\"450\">\r\n","\r\n","\r\n","Para isso basta realizar o padding das suas sequências, **preservando os comprimetos originais** em outra variável. Na prática, o forward recebe mais um parâmetro, aqui chamamos de **```tamanhos```**, referente ao comprimento de cada amostra dentro do batch **```X```**, ordenado de forma descrescente.\r\n","\r\n","Tendo em mãos (1) o batch de sequências preenchidas e ordenadas, e (2) o comprimento original de cada amostra, basta realizar as seguintes operações no forward da rede:\r\n","\r\n","```python\r\n","## Empacote a sequência antes de alimentar a unidade recorrente\r\n","packed_input = nn.utils.rnn.pack_padded_sequence(X, tamanhos)\r\n","\r\n","## Forward recorrente\r\n","packed_output, hidden = self.rnn(packed_input, hidden )\r\n","\r\n","## Desempacote a sequência para continuar o fluxo na rede.\r\n","output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\r\n","```"]},{"cell_type":"code","metadata":{"id":"9H5YeH7IXUFT"},"source":["# Simulando um init \r\n","hidden_size = 128\r\n","rnn = nn.RNN( 1, hidden_size ).to(device)\r\n","\r\n","# Simulando um forward\r\n","for batch in test_iterator:\r\n","\r\n","  X, tamanhos = batch.text\r\n","  print(X.size(), tamanhos.size())\r\n","  hidden = torch.zeros(1, X.size(1), hidden_size).to(device)\r\n","\r\n","  ## Empacote a sequência antes de alimentar a unidade recorrente\r\n","  packed_input = nn.utils.rnn.pack_padded_sequence(X.unsqueeze(-1).float().to(device), tamanhos)\r\n","  print('\\npacked_input.batch_sizes:', packed_input.batch_sizes)\r\n","\r\n","  ## Forward recorrente\r\n","  packed_output, hidden = rnn(packed_input, hidden )\r\n","  print('\\npacked_output.batch_sizes:', packed_output.batch_sizes)\r\n","  print('\\nhidden:', hidden.size())\r\n","\r\n","  ## Desempacote a sequência para continuar o fluxo na rede.\r\n","  output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\r\n","  print('\\noutput:', output.size())\r\n","  \r\n","  break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R2hICTxHmkS5"},"source":["## Exercício\n","\n","1) Vamos implementar uma RNN simples com  a seguinte arquitetura:\n","* [`nn.Embedding`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n","* [`nn.RNN`](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html?highlight=rnn#torch.nn.RNN)\n","* [`nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html?highlight=linear#torch.nn.Linear) com ativação [`LogSoftmax`](https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html#torch.nn.LogSoftmax).\n","\n","Note que se trata de um problema **muitos para muitos**, ou seja, precisamos realizar ambos o passo recorrente e a inferência com a camada linear em todos os elementos da sequência. Para tal, a camada `nn.Linear` suporta tensores de quaisquer dimensões `(N, *, H_in)`, aplicando a transformação linear apenas na última dimensão.\n","\n","2) Modifique agora o seu modelo para uma **RNN bidirecional**. \n","> Note que essa arquitetura na prática dobra a quantidade de pesos em relação à RNN unidirecional. **Sugiro dividir pela metade o hiperparâmetro que você definiu no passo 1 para o `hidden_size`** para comparar as duas redes com igual complexidade.\n","![](https://drive.google.com/uc?export=view&id=158b3Y_o-7yXsKMe5VdaifhPg0Du4A6dp) <br>\n","Na implementação, o que muda em relação à camada unidirecional é:\n","*  Ao instanciar a camada recorrente, defina o parâmetro **```bidirectional = True```**\n","*  O hidden state tem dimensionalidade **```(num_layers * 2, batch_size, hidden_size)```**\n","*  O output tem dimensionalidade **```(seq_len, batch_size, hidden_size * 2)```**\n","\n"]},{"cell_type":"code","metadata":{"id":"-eYhV5iqmkS5"},"source":["class RNN(nn.Module):\n","    \n","    def __init__(self):\n","        super(RNN, self).__init__()\n","        # TODO\n","        \n","        \n","    def forward(self):\n","        # TODO\n","       \n","        \n","net = # TODO RNN(...)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qd9bdbrzmkS6"},"source":["### Definindo otimizador e função de perda\r\n","\r\n","Como definimos a ativação LogSoftmax para a camada de inferência, o ideal é utilizar a função de perda [NLLLoss](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html). "]},{"cell_type":"code","metadata":{"id":"LzoNBLzTmkS6"},"source":["optimizer = # TODO ...\n","criterion = # TODO ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WTJ0jYJkmkS6"},"source":["### Fluxo de Treinamento e Validação "]},{"cell_type":"code","metadata":{"id":"PwNFds9SmkS6"},"source":["def forward(iterator, epoch, optimizer, criterion, mode):\n","    \n","    acc = 0.\n","    epoch_loss = []\n","    for sample in iterator:\n","        \n","        text, lengths = sample.text\n","        text = text.to(device)\n","        label = sample.target\n","        label = label.to(device)\n","        \n","        # TODO\n","        out = # forward na rede\n","        loss = # cálculo da loss (atente para a dimensionalidade de dados esperada pela função de custo)\n","        \n","        epoch_loss.append(loss.detach().cpu().item())\n","        \n","        _, pred = torch.max(out.detach(), dim=-1)\n","        acc += torch.sum(pred == label).item()/(pred.size(0)*pred.size(1)) \n","\n","        if mode == 'train':\n","            #TODO passos de otimização\n","            \n","    epoch_loss = np.asarray(epoch_loss)\n","    print(f'[{mode.capitalize()}] Epoch {epoch} - Loss: {epoch_loss.mean():.4f}+/-{epoch_loss.std():.4f}, Acc: {(acc/len(iterator))*100:.2f}%')\n","    \n","    return epoch_loss.mean()\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"YwliUu1HmkS7"},"source":["train_loss, test_loss = [], []\n","for epoch in range(30):\n","    \n","    loss = forward(train_iterator, epoch, optimizer, criterion, 'train')\n","    train_loss.append(loss)\n","    \n","    loss = forward(test_iterator, epoch, optimizer, criterion, 'test ')\n","    test_loss.append(loss)\n","    \n","    print('--'*20)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bEGC-xp4mkS7"},"source":["### Predizendo instâncias"]},{"cell_type":"code","metadata":{"id":"bAmc7cfPmkS8"},"source":["def pred( sentence ):\n","\n","  text  = [unidecode.unidecode(word.split('_')[0]).lower() for word in sentence.split()]\n","  label = [TARGET.vocab.stoi[word.split('_')[1].split('+')[0]] for word in sentence.split()]\n","  print(text)\n","  text = [TEXT.vocab.stoi[t] for t in text]\n","\n","  text = torch.LongTensor(text)\n","  text = text.view(text.size(0), 1).to(device)\n","  out = net(text, torch.LongTensor( [len(text)] ))\n","\n","  _, pred = torch.max(out, -1)\n","  print([TARGET.vocab.itos[p] for p in pred.squeeze() ],'\\n') \n","\n","  return np.asarray(label), pred.detach().cpu().numpy().squeeze()\n","\n","with open('macmorpho-dev.txt') as fp:\n","  sentences = fp.read().split('\\n')\n","  for i in range(10):\n","    sentence = sentences[i]\n","    ytrue, ypred = pred(sentence)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ImjHiciVmkS8"},"source":["### Matriz de confusão"]},{"cell_type":"code","metadata":{"id":"AyiEe1iYmkS9"},"source":["from sklearn.metrics import confusion_matrix\n","\n","dev_iterator = data.BucketIterator(devset, batch_size=32, sort_key=lambda x: len(x.text), sort_within_batch=True)\n","predictions, labels = [], []\n","for sample in dev_iterator:\n","    \n","    text, lengths = sample.text\n","    label = sample.target\n","    \n","    out = net(text.to(device), lengths)\n","    _, pred = torch.max(out, -1)\n","    \n","    predictions.extend(list(pred.view(-1).cpu().numpy()))\n","    labels.extend( list(label.view(-1).numpy() )  )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v7xwYGW8mkS9"},"source":["conf = confusion_matrix(y_true=labels, y_pred=predictions, normalize='true')\n","plt.figure(figsize=(6,6))\n","plt.imshow(conf, cmap='coolwarm')\n","plt.colorbar()\n","plt.xticks(np.arange(0, len(TARGET.vocab)-1), TARGET.vocab.itos[1:], rotation=90)\n","plt.yticks(np.arange(0, len(TARGET.vocab)-1), TARGET.vocab.itos[1:])\n","plt.show()"],"execution_count":null,"outputs":[]}]}