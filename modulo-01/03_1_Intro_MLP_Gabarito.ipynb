{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_1_Intro_MLP_Gabarito.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NG-mVsVuE0if",
        "3f-q6bCNzEmx"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG-mVsVuE0if"
      },
      "source": [
        "# Preâmbulo\n",
        "\n",
        "Imports, funções, downloads e instalação do Pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEHmMCjR4PJw"
      },
      "source": [
        "# Basic imports.\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils import data\n",
        "from torch.backends import cudnn\n",
        "\n",
        "from torchvision import models\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "from skimage import io\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "cudnn.benchmark = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQa4-lUw7Rmp"
      },
      "source": [
        "## Casting para o dispositivo correto\n",
        "\n",
        "Como usaremos processamento vetorial principalmente em GPUs para aprendizado profundo, primeiramente é possível verificar se há uma GPU disponível com o trecho de código abaixo, armazenando os tensores nos dispositivos apropriados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX0bBEM863sY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57150e11-9cb5-4d13-c7cd-faec53022458"
      },
      "source": [
        "# Checking if GPU/CUDA is available.\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x5UK0uib2tk"
      },
      "source": [
        "# Intro MLP\n",
        "\n",
        "## O perceptron e a camada `nn.Linear`\n",
        "\n",
        "A camada Linear do Pytorch ([nn.Linear](https://pytorch.org/docs/stable/nn.html#torch.nn.Linear)) é responsável por aplicar uma transformação linear no dado de entrada. Esta camada recebe como parâmetro a dimensão (número de *features*) da entrada e da saída (que na verdade, representa o número de neurônios dessa camada). Por padrão o bias já é incluído. **Um** perceptron pode ser facilmente representado como a seguir, desconsiderando a função de ativação:\n",
        "\n",
        "```\n",
        "perceptron = nn.Linear(in_dimension, 1)\n",
        "```\n",
        "Mas de uma forma geral, uma camada Linear com diversas *features* de entrada e diversas *features* de saída pode ser representada como:\n",
        "```\n",
        "nn.Linear(in_features, out_features)\n",
        "```\n",
        "![](./figs/nn_linear.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlQA_vtGg8bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f06dbae-457d-4ef7-c1da-051e72bea15e"
      },
      "source": [
        "linear = nn.Linear(2,3)\n",
        "print(linear)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear(in_features=2, out_features=3, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AhNyLrLmFcT"
      },
      "source": [
        "Como é possível ver no código abaixo, o Pytorch já inicia os pesos da camada aleatoriamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLOlOhQVmPuj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd253d2a-0424-4776-f3d8-a3b858bc8c0e"
      },
      "source": [
        "for p in linear.parameters():\n",
        "  print(p)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.1371,  0.4394],\n",
            "        [ 0.3149,  0.4315],\n",
            "        [-0.5239, -0.6747]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.2386, -0.3142,  0.4806], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAEaJGtDoZD7"
      },
      "source": [
        "O **forward** consiste em passar seu dado de entrada pela rede, gerando um resultado ao final. Considerando a camada linear instanciada anteriormente, o resultado do forward é o mesmo do somatório da multiplicação de seus pesos pelas respectivas entradas juntamente com o bias:\n",
        "\n",
        "w1\\*x1 + w2\\*x2 + ... + wn\\*xn + b\n",
        "\n",
        "No Pytorch, realizamos o **forward** chamando a função onde nossa rede/modelo está instanciada, conforme exemplo abaixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ibb8t7zpmpUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28fac2dd-1370-4a2d-c9f3-d2ea1284fa21"
      },
      "source": [
        "perceptron = nn.Linear(2,1)\n",
        "X = torch.FloatTensor([2,3]) # dado de entrada de exemplo considerando o perceptron definido como nn.Linear(2,1)\n",
        "print('Pytorch: ', perceptron(X))\n",
        "\n",
        "# acessamos os pesos do modelo com .weight e o bias com .bias\n",
        "print('Manual: ', torch.mul(X, perceptron.weight).sum() + perceptron.bias)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pytorch:  tensor([1.1275], grad_fn=<AddBackward0>)\n",
            "Manual:  tensor([1.1275], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8LMX6OMrEbw"
      },
      "source": [
        "## Exemplo Perceptron simples\n",
        "\n",
        "O código abaixo cria um perceptron simples usando `nn.Linear` e implemente o fluxo de treinamento para esse preceptron, ou seja, faz o forward nessa camada, calcula a loss, e otimiza a camada. Invista um pouco de tempo para entender a célula abaixo pois usaremos essa ideia para implementar a função de treino mais a frente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPJ9s5ckoA5T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afb29944-9e25-4a02-a784-9c807834ca8c"
      },
      "source": [
        "def loss_fn(predict, label):  # definindo a loss\n",
        "    return torch.pow(label - predict, 2)\n",
        "\n",
        "perceptron = nn.Linear(1,1) # Camada linear com 1 feature de entrada (mais o bias) e uma de saída\n",
        "perceptron.to(device) # casting do perceptron para GPU\n",
        "learning_rate = 0.01\n",
        "print('Parametros iniciais: ', list(perceptron.parameters()))\n",
        "\n",
        "dataset = [] # dados de exemplo que seguem a função y = 2x+3\n",
        "for x in range(10):\n",
        "    dataset.append((x, 2*x+3))\n",
        "\n",
        "for epoch in range(101):\n",
        "    epoch_loss = 0\n",
        "    for iteration, data in enumerate(dataset):\n",
        "        X, y = data\n",
        "        X, y = torch.FloatTensor([X]).to(device), torch.FloatTensor([y]).to(device) # conversão para Tensor\n",
        "  \n",
        "        y_pred = perceptron(X)  # forward\n",
        "        loss = loss_fn(y_pred, y)  # calcula a loss\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            for param in perceptron.parameters():\n",
        "                param -= learning_rate * param.grad  # atualização dos parametros (pesos e bias) com base no gradiente\n",
        "                param.grad.zero_()  # resetando o gradiente\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(\"Epoch {} - loss: {}\".format(epoch, epoch_loss))\n",
        "print('Parametros finais: ', list(perceptron.parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parametros iniciais:  [Parameter containing:\n",
            "tensor([[-0.0700]], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([-0.9873], device='cuda:0', requires_grad=True)]\n",
            "Epoch 0 - loss: 288.4102809987962\n",
            "Epoch 10 - loss: 10.214067387394607\n",
            "Epoch 20 - loss: 3.5298936692997813\n",
            "Epoch 30 - loss: 1.219899281160906\n",
            "Epoch 40 - loss: 0.42158502485835925\n",
            "Epoch 50 - loss: 0.14569592762563843\n",
            "Epoch 60 - loss: 0.05035081384994555\n",
            "Epoch 70 - loss: 0.01740083147888072\n",
            "Epoch 80 - loss: 0.006013804901158437\n",
            "Epoch 90 - loss: 0.0020783275831490755\n",
            "Epoch 100 - loss: 0.0007182354429460247\n",
            "Parametros finais:  [Parameter containing:\n",
            "tensor([[2.0016]], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([2.9845], device='cuda:0', requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9uRk8mAwGIB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "098dc427-de94-4598-a206-b74a14b4b6b4"
      },
      "source": [
        "print(perceptron(torch.FloatTensor([20]).to(device))) # forward do valor 20 para conferir resultado, saida deve ser aproximadamente = 2x+3 = 2*20+3 = 43"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([43.0172], device='cuda:0', grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f-q6bCNzEmx"
      },
      "source": [
        "## O módulo `nn.Sequential`\n",
        "\n",
        "Na prática, criaremos redes com diversas camadas. O bloco `nn.Sequential` permite agrupar as camadas de forma sequencial para que o forward seja realizado na ordem desejada. Veja um exemplo para um *Multilayer Perceptron (MLP)* abaixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCK_OkqCzdUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd4000e5-4932-4078-be8e-2f3c373eb728"
      },
      "source": [
        "in_features = 28\n",
        "hidden_1 = 64\n",
        "hidden_2 = 32\n",
        "out_features = 8\n",
        "\n",
        "MLP = nn.Sequential(nn.Linear(in_features, hidden_1), nn.ReLU(), \n",
        "                    nn.Linear(hidden_1, hidden_2), nn.ReLU(), \n",
        "                    nn.Linear(hidden_2, out_features))\n",
        "print(MLP)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=28, out_features=64, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=32, out_features=8, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkhjCepK0kjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42cb74f0-80bb-4a14-c70b-ef0d444af37b"
      },
      "source": [
        "test_data = torch.randn((10,28)) # 10 dados de input aleatórios com 28 features\n",
        "output = MLP(test_data) # forward da rede\n",
        "print(output.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9LoXL0cUYMT"
      },
      "source": [
        "## Sua vez\r\n",
        "\r\n",
        "Vamos agora treinar um MLP simples em dados aleatórios. A célula abaixo define as dimensões de entrada e saída e gera os dados aleatórios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi3Zh8fQ4X_3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b5562a5-d04a-4ca2-a048-e3914b6a40d8"
      },
      "source": [
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# Create random Tensors to hold inputs and outputs\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "# Casting tensors to the appropriate device.\n",
        "x = x.to(device)\n",
        "y = y.to(device)\n",
        "\n",
        "# Printing sizes of tensors.\n",
        "print('x: ', x.size())\n",
        "print('y: ', y.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x:  torch.Size([64, 1000])\n",
            "y:  torch.Size([64, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMDN1viW-0Eg"
      },
      "source": [
        "Modifique o código abaixo para criar um módulo `nn.Sequential` de nome **model** que representa um MLP com, pelo menos, uma camada escondida (seguindo os valores N, D_in, H e D_out definidos anteriormente), **usando um ReLU como função de ativação entre as camadas**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYO7HWC29Ahy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cade123-a7bb-47f2-c04a-94e3db07b361"
      },
      "source": [
        "model = nn.Sequential(nn.Linear(D_in, H), nn.ReLU(), \n",
        "                      nn.Linear(H, H), nn.ReLU(), \n",
        "                      nn.Linear(H, D_out))\n",
        "\n",
        "model.to(device)  # sempre eh necessario fazer o casting da rede para joga-la para GPU\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=1000, out_features=100, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWrn_MUHBz7o"
      },
      "source": [
        "Abaixo, definimos uma loss e um otimizador usando o Torch. Não se preocupem como isso agora, pois iremos ver em detalhes como definir e usar diferentes losses and otimizadores com o Torch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oQ2T8jm9BE9"
      },
      "source": [
        "# Use the nn package to define our loss function.\n",
        "loss_mse = nn.MSELoss(reduction='sum').to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa5DcYBf82iD"
      },
      "source": [
        "# Use the optim package to define an Optimizer that will update the weights of\n",
        "# the model for us. Here we will use SGD; the optim package contains many other\n",
        "# optimization algorithms. The first argument tells the\n",
        "# optimizer which Tensors it should update.\n",
        "learning_rate = 1e-4\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPQtOnNr-kAG"
      },
      "source": [
        "Implemente abaixo a forward e cálculo da loss como feito anteriormente. Estude essa função, pois usaremos esse fluxo de treino mais a frente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsMFRIDv80I3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74768666-e130-481b-8956-751e95571cbc"
      },
      "source": [
        "# Creating list of losses for each epoch.\n",
        "loss_list = []\n",
        "\n",
        "# Iterating over epochs.\n",
        "for epoch in range(500):\n",
        "\n",
        "    preds = model(x)\n",
        "    loss = loss_mse(preds, y)\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print('Epoch ' + str(epoch + 1) + ': loss = ' + str(loss.item()))\n",
        "    \n",
        "    # Updating list of losses for printing.\n",
        "    loss_list.append(loss.item())\n",
        "\n",
        "    # Before the backward pass, use the optimizer object to zero all of the\n",
        "    # gradients for the variables it will update (which are the learnable\n",
        "    # weights of the model). This is because by default, gradients are\n",
        "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
        "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to model\n",
        "    # parameters\n",
        "    loss.backward()\n",
        "\n",
        "    # Calling the step function on an Optimizer makes an update to its\n",
        "    # parameters\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 10: loss = 550.152099609375\n",
            "Epoch 20: loss = 491.513916015625\n",
            "Epoch 30: loss = 432.72039794921875\n",
            "Epoch 40: loss = 369.6939697265625\n",
            "Epoch 50: loss = 302.154541015625\n",
            "Epoch 60: loss = 234.55767822265625\n",
            "Epoch 70: loss = 173.6392822265625\n",
            "Epoch 80: loss = 124.05020141601562\n",
            "Epoch 90: loss = 86.89012145996094\n",
            "Epoch 100: loss = 60.46564483642578\n",
            "Epoch 110: loss = 42.45393371582031\n",
            "Epoch 120: loss = 30.2360897064209\n",
            "Epoch 130: loss = 21.7821102142334\n",
            "Epoch 140: loss = 15.816312789916992\n",
            "Epoch 150: loss = 11.538751602172852\n",
            "Epoch 160: loss = 8.483081817626953\n",
            "Epoch 170: loss = 6.273039817810059\n",
            "Epoch 180: loss = 4.66347599029541\n",
            "Epoch 190: loss = 3.4928414821624756\n",
            "Epoch 200: loss = 2.6250698566436768\n",
            "Epoch 210: loss = 1.9842159748077393\n",
            "Epoch 220: loss = 1.5087389945983887\n",
            "Epoch 230: loss = 1.1542065143585205\n",
            "Epoch 240: loss = 0.8890576362609863\n",
            "Epoch 250: loss = 0.6898928880691528\n",
            "Epoch 260: loss = 0.5392681360244751\n",
            "Epoch 270: loss = 0.42409276962280273\n",
            "Epoch 280: loss = 0.335199773311615\n",
            "Epoch 290: loss = 0.2661093473434448\n",
            "Epoch 300: loss = 0.21211205422878265\n",
            "Epoch 310: loss = 0.16978974640369415\n",
            "Epoch 320: loss = 0.13644874095916748\n",
            "Epoch 330: loss = 0.11003081500530243\n",
            "Epoch 340: loss = 0.08895178139209747\n",
            "Epoch 350: loss = 0.07213261723518372\n",
            "Epoch 360: loss = 0.058642297983169556\n",
            "Epoch 370: loss = 0.04778995364904404\n",
            "Epoch 380: loss = 0.039043128490448\n",
            "Epoch 390: loss = 0.031970176845788956\n",
            "Epoch 400: loss = 0.026224011555314064\n",
            "Epoch 410: loss = 0.02154373750090599\n",
            "Epoch 420: loss = 0.017732135951519012\n",
            "Epoch 430: loss = 0.014622428454458714\n",
            "Epoch 440: loss = 0.012082861736416817\n",
            "Epoch 450: loss = 0.010000703856348991\n",
            "Epoch 460: loss = 0.008289535529911518\n",
            "Epoch 470: loss = 0.006880117114633322\n",
            "Epoch 480: loss = 0.005713226739317179\n",
            "Epoch 490: loss = 0.004750893451273441\n",
            "Epoch 500: loss = 0.0039548263885080814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toQyqq98-68X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "50b50842-2de6-43ab-a461-c4baba47160e"
      },
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
        "\n",
        "ax.plot(np.asarray(loss_list))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfb4zBjO0Lua"
      },
      "source": [
        "Informação sobre outras camadas lineares, como nn.Bilinear e nn.Identity, podem ser vistas na documentação: https://pytorch.org/docs/stable/nn.html#linear-layers"
      ]
    }
  ]
}