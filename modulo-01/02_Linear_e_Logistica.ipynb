{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GBvUmcHxonaS"
      },
      "source": [
        "# Aprendizado Profundo - UFMG\n",
        "\n",
        "## Preâmbulo\n",
        "\n",
        "O código abaixo consiste dos imports comuns. Além do mais, configuramos as imagens para ficar de um tamanho aceitável e criamos algumas funções auxiliares. No geral, você pode ignorar a próxima célula."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "W-iRUIgyouKm"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf8\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "plt.rcParams['figure.figsize']  = (18, 10)\n",
        "plt.rcParams['axes.labelsize']  = 20\n",
        "plt.rcParams['axes.titlesize']  = 20\n",
        "plt.rcParams['legend.fontsize'] = 20\n",
        "plt.rcParams['xtick.labelsize'] = 20\n",
        "plt.rcParams['ytick.labelsize'] = 20\n",
        "plt.rcParams['lines.linewidth'] = 4\n",
        "torch.set_printoptions(precision=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "r5J4r1Joonac"
      },
      "outputs": [],
      "source": [
        "plt.ion()\n",
        "\n",
        "plt.style.use('seaborn-v0_8-colorblind')\n",
        "plt.rcParams['figure.figsize']  = (12, 8)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "r1hxSo7nonag"
      },
      "source": [
        "Para testar o resultado dos seus algoritmos vamos usar o módulo testing do numpy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cKAN6JuJonah"
      },
      "outputs": [],
      "source": [
        "from numpy.testing import assert_equal\n",
        "from numpy.testing import assert_almost_equal\n",
        "from numpy.testing import assert_array_almost_equal"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8FVe1G2wonak"
      },
      "source": [
        "## Regressão Linear e Logística from Scratch\n",
        "\n",
        "Para brincar um pouco mais com essa diferenciação automatica, presente em frameworks como pytorch e mxnet, nesta aula vamos implementar a regressão linear e logística do zero. Vamos fazer duas versões de cada:\n",
        "\n",
        "1. Derivando na mão, não é complicado.\n",
        "2. Derivando com autograd de pytorch"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "waN0vx9fonal"
      },
      "source": [
        "## Conjunto de Problemas 1: Mais Derivadas"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uK0g7SKdonam"
      },
      "source": [
        "Antes de entrar na regressão, vamos brincar um pouco de derivadas dentro de funções. Dado dois números `x` e `y`, implemente a função `log_exp` que retorna:\n",
        "\n",
        "$$-\\log\\left(\\frac{e^x}{e^x+e^y}\\right)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OsgyDlAHpBdZ"
      },
      "outputs": [],
      "source": [
        "def log_exp(x, y):\n",
        "    intermediate = (torch.exp(x) / (torch.exp(x) + torch.exp(y)))\n",
        "    result = -torch.log(intermediate)\n",
        "    return result"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EnoHouBPonap"
      },
      "source": [
        "1. Abaixo vamos testar o seu código com algumas entradas simples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2fd-sln-w2Op"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1.3132617474])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x, y = torch.tensor([2.0]), torch.tensor([3.0])\n",
        "z = log_exp(x, y)\n",
        "z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LQNEAUNoonau"
      },
      "outputs": [],
      "source": [
        "# Teste. Não apague\n",
        "assert_almost_equal(1.31326175, z.numpy())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TdhvPzMxonax"
      },
      "source": [
        "2. A função a seguir computa $\\partial z/\\partial x$ e $\\partial z/\\partial y$ usando `autograd`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lHBQrZD7qsYN"
      },
      "outputs": [],
      "source": [
        "# O argumento funcao_forward é uma função python. Será a sua log_exp.\n",
        "# A ideia aqui é deixar claro a ideia de forward e backward propagation, depois\n",
        "# de avaliar a função chamamos backward e temos as derivadas.\n",
        "def grad(funcao_forward, x, y):\n",
        "    x.requires_grad_(True)\n",
        "    y.requires_grad_(True)\n",
        "    z = funcao_forward(x, y)\n",
        "    z.backward()\n",
        "    return x.grad, y.grad"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-WFpkBMvona2"
      },
      "source": [
        "Testando"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vMVfDIKQrAJL"
      },
      "outputs": [],
      "source": [
        "x, y = torch.tensor([2.0], dtype = torch.double) ,torch.tensor([3.0], dtype = torch.double)\n",
        "dx, dy = grad(log_exp, x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oIkTfFH0snPD"
      },
      "outputs": [],
      "source": [
        "assert_almost_equal(-0.7310586, dx.numpy())\n",
        "assert_almost_equal(0.7310586, dy.numpy())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1oNpz1wIona9"
      },
      "source": [
        "4. Agora teste com números maiores, algum problema?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0qEsHY5VsuH_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([nan], dtype=torch.float64), tensor([nan], dtype=torch.float64))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x, y = torch.tensor([400.0]).double() ,torch.tensor([800.0]).double()\n",
        "grad(log_exp, x, y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quando o número é muito grande, podemos ter um overflow ao calcular o resultado de log_exp()."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XGUiPmJLonbB"
      },
      "source": [
        "5. Pense um pouco sobre o motivo do erro acima. Usando as propriedade de logaritmos, é possível fazer uma função mais estável. Abaixo segue a implementação da mesma. O problema aqui é que o exponencial \"explode\" quando x ou y são muito grandes. Este [link](http://www.wolframalpha.com/input/?i=log[e%5Ex+%2F+[e%5Ex+%2B+e%5Ey]]) pode ajudar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rnj8B4EyttvL"
      },
      "outputs": [],
      "source": [
        "x, y = torch.tensor([400.0], dtype = torch.double) ,torch.tensor([800.0], dtype = torch.double)\n",
        "def stable_log_exp(x, y):\n",
        "    return torch.log(torch.exp(y-x))\n",
        "\n",
        "dx, dy = grad(stable_log_exp, x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "B9QIVgN1onbF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([400.], dtype=torch.float64, grad_fn=<LogBackward0>)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stable_log_exp(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "aVWzzA4-t9J2"
      },
      "outputs": [],
      "source": [
        "# Teste. Não apague\n",
        "assert_equal(-1, dx.numpy())\n",
        "assert_equal(1, dy.numpy())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "esV2XR7jonbL"
      },
      "source": [
        "O exemplo acima mostra um pouco de problemas de estabilidade númerica. Às vezes é melhor usar versões alternativas de funções. Isto vai ocorrer quando você ver vários nans na sua frente :-) Claro, estamos assumindo que existe uma outra função equivalente que é mais estável para o computador."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3qI91TX7onbM"
      },
      "source": [
        "## Conjunto de Problemas 2: Regressão Linear\n",
        "\n",
        "Agora, vamos explorar uma regressão linear. Embora não vamos fazer uso da logexp acima, a ideia de derivar parcialmente dentro de funções pode nos ajudar. Lembrando da regressão linear, inicialmente temos um conjunto observações representadas como tuplas $(\\mathbf{x}_i, y_i)$. Aqui, $\\mathbf{x}_i$ é um vetor de atributos. Vamo forçar $\\mathbf{x}_{i0} = 1$, capturando assim o intercepto. Além do mais, $\\mathbf{x}_{ij}$ quando $j\\neq 0$, são os outros atributos de entrada. $y_i$ um valor real representando uma resposta. Nossa regressão visa capturar:\n",
        "\n",
        "$$y_i = 1 + \\theta_1 x_{i1} + \\theta_2 x_{i2} + \\cdots + \\theta_k x_{if}$$\n",
        "\n",
        "Lembrando da regressão linear multivariada, podemos representar as equações como uma multiplicação de uma matriz com um vetor\n",
        "\n",
        "![](./figs/linear.png)\n",
        "\n",
        "7. Crie uma função de previsao. A mesma recebe uma matrix $\\mathbf{X}$ e um vetor de parâmetros $\\theta$. Sua função deve retornar um vetor de previsões para cada linha de $\\mathbf{X}$. Não use nenhum laço!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "HveutorucYMJ"
      },
      "outputs": [],
      "source": [
        "def previsao(X, theta):\n",
        "    return torch.matmul(X, theta.float())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iNRX8E0MonbP"
      },
      "source": [
        "**Erros quadrados**. Para aprender os parâmetros ótimos da regressão linear, precisamos fazer uso de um modelo de erros quadrados. Em particular nosso objetico é aprender os parâmetros que minimizam a função:\n",
        "\n",
        "$$L(\\mathbf{\\theta}) = n^{-1} \\sum_i ({\\hat{y}_i - y_i})^2$$\n",
        "\n",
        "Onde $\\hat{y}_i$ é uma previsão (vêm da sua função python acima). $y_i$ é o valor real dos dados.\n",
        "\n",
        "8. Implemente uma função para a média dos os erros quadrados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "sS7y5Wb2cusy"
      },
      "outputs": [],
      "source": [
        "def media_erros_quadrados(X, theta, y):\n",
        "    return torch.mean((previsao(X, theta) - y) ** 2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EVqJCucconbT"
      },
      "source": [
        "9. Agora, crie uma função que deriva o erro acima. A função deve usar o autograd do pytorch (função backward). Lembre-se que temos um vetor de parâmetros $\\theta$. Por sorte, você pode fazer derivadas de tais vetores também."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "_ao1G8uSc8Bp"
      },
      "outputs": [],
      "source": [
        "def derivada_torch(X, theta, y): #Lembre que o theta passado devera ser uma variavel com requires_grad == True\n",
        "    e = media_erros_quadrados(X, theta, y)\n",
        "    e.backward()\n",
        "    return theta.grad"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rnWTcJubonba"
      },
      "source": [
        "10. A versão a seguir não usa autograd. As derivadas são implementadas do zero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "DBpOTZjPdLrq"
      },
      "outputs": [],
      "source": [
        "def derivada_navera(X, theta, y):\n",
        "    return ((torch.matmul(X, theta) - y) * X.T).mean(axis=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Tj5LkKLzonbf"
      },
      "source": [
        "11. Por fim, otimize sua função usando o algoritmo de gradiente descendente abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "j-9buFPGfVPG"
      },
      "outputs": [],
      "source": [
        "def gd(d_fun, loss_fun, X, y, lambda_=0.01, tol=0.00001, max_iter=10000):\n",
        "    '''\n",
        "    Executa Gradiente Descendente. Aqui:\n",
        "    \n",
        "    Parâmetros\n",
        "    ----------\n",
        "    d_fun : é uma função de derivadas\n",
        "    loss_fun : é uma função de perda\n",
        "    X : é um vetor de fatores explanatórios.\n",
        "        Copie seu código de intercepto da primeira aula.\n",
        "        para adicionar o intercepto em X.\n",
        "    y : é a resposta\n",
        "    lambda : é a taxa de aprendizado\n",
        "    tol : é a tolerância, define quando o algoritmo vai parar.\n",
        "    max_ter : é a segunda forma de parada, mesmo sem convergir\n",
        "              paramos depois de max_iter iterações.\n",
        "    '''\n",
        "    theta = torch.randn(X.shape[1])\n",
        "    theta.requires_grad_(True)\n",
        "    \n",
        "    print('Iter {}; theta = '.format(0), theta)\n",
        "    \n",
        "    old_err_sq = np.inf\n",
        "    i = 0\n",
        "    while True:\n",
        "        # Computar as derivadas\n",
        "                \n",
        "        theta.requires_grad_(True)  #Necessario pois ao final, theta recebe o theta novo, que não tem requires_grad == True\n",
        "        grad = d_fun(X,theta,y)\n",
        "\n",
        "        # Atualizar\n",
        "        with torch.no_grad(): \n",
        "            theta_novo = theta - lambda_ * grad\n",
        "        \n",
        "        #Parar quando o erro convergir\n",
        "        err_sq = loss_fun(X, theta, y)\n",
        "        if torch.abs(old_err_sq - err_sq) <= tol:\n",
        "            break\n",
        "        \n",
        "         #Atualizar parâmetros e erro\n",
        "        theta = theta_novo\n",
        "        old_err_sq = err_sq\n",
        "        \n",
        "        # Informação de debug\n",
        "        print('Iter {}; theta = '.format(i+1), theta)\n",
        "        i += 1\n",
        "        if i == max_iter:\n",
        "            break\n",
        "        \n",
        "    return theta"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Esta função acima calcula os pesos para os quais o erro quadrático da função a ser calculada é mínimo, o que é, de fato, o aprendizado da máquina."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "RVWvK5mffuqd"
      },
      "outputs": [],
      "source": [
        "# Para testes, não apague!!!\n",
        "X = torch.zeros(1000, 2)\n",
        "X[:, 0] = 1.0\n",
        "X[:, 1] = torch.randn(1000)\n",
        "theta_0_real = 7.0\n",
        "theta_1_real = 9.0\n",
        "y = theta_0_real + theta_1_real * X[:, 1] # escolhemos os pesos theta_0 e theta_1 arbitrariamente, para ver se o modelo converge para estes números."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "IxE4o8ALonbm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter 0; theta =  tensor([0.6083199978, 1.3785887957], requires_grad=True)\n",
            "Iter 1; theta =  tensor([0.7342270613, 1.5286618471])\n",
            "Iter 2; theta =  tensor([0.8576538563, 1.6757799387])\n",
            "Iter 3; theta =  tensor([0.9786493182, 1.8200011253])\n",
            "Iter 4; theta =  tensor([1.0972613096, 1.9613823891])\n",
            "Iter 5; theta =  tensor([1.2135368586, 2.0999798775])\n",
            "Iter 6; theta =  tensor([1.3275218010, 2.2358481884])\n",
            "Iter 7; theta =  tensor([1.4392614365, 2.3690412045])\n",
            "Iter 8; theta =  tensor([1.5487999916, 2.4996113777])\n",
            "Iter 9; theta =  tensor([1.6561808586, 2.6276106834])\n",
            "Iter 10; theta =  tensor([1.7614463568, 2.7530894279])\n",
            "Iter 11; theta =  tensor([1.8646383286, 2.8760974407])\n",
            "Iter 12; theta =  tensor([1.9657975435, 2.9966833591])\n",
            "Iter 13; theta =  tensor([2.0649640560, 3.1148948669])\n",
            "Iter 14; theta =  tensor([2.1621770859, 3.2307786942])\n",
            "Iter 15; theta =  tensor([2.2574751377, 3.3443803787])\n",
            "Iter 16; theta =  tensor([2.3508958817, 3.4557452202])\n",
            "Iter 17; theta =  tensor([2.4424765110, 3.5649170876])\n",
            "Iter 18; theta =  tensor([2.5322530270, 3.6719393730])\n",
            "Iter 19; theta =  tensor([2.6202611923, 3.7768542767])\n",
            "Iter 20; theta =  tensor([2.7065355778, 3.8797032833])\n",
            "Iter 21; theta =  tensor([2.7911105156, 3.9805271626])\n",
            "Iter 22; theta =  tensor([2.8740193844, 4.0793657303])\n",
            "Iter 23; theta =  tensor([2.9552950859, 4.1762580872])\n",
            "Iter 24; theta =  tensor([3.0349698067, 4.2712426186])\n",
            "Iter 25; theta =  tensor([3.1130750179, 4.3643565178])\n",
            "Iter 26; theta =  tensor([3.1896417141, 4.4556369781])\n",
            "Iter 27; theta =  tensor([3.2647001743, 4.5451202393])\n",
            "Iter 28; theta =  tensor([3.3382799625, 4.6328415871])\n",
            "Iter 29; theta =  tensor([3.4104104042, 4.7188353539])\n",
            "Iter 30; theta =  tensor([3.4811198711, 4.8031358719])\n",
            "Iter 31; theta =  tensor([3.5504364967, 4.8857765198])\n",
            "Iter 32; theta =  tensor([3.6183876991, 4.9667897224])\n",
            "Iter 33; theta =  tensor([3.6850004196, 5.0462079048])\n",
            "Iter 34; theta =  tensor([3.7503008842, 5.1240620613])\n",
            "Iter 35; theta =  tensor([3.8143150806, 5.2003831863])\n",
            "Iter 36; theta =  tensor([3.8770682812, 5.2752017975])\n",
            "Iter 37; theta =  tensor([3.9385852814, 5.3485469818])\n",
            "Iter 38; theta =  tensor([3.9988906384, 5.4204478264])\n",
            "Iter 39; theta =  tensor([4.0580081940, 5.4909329414])\n",
            "Iter 40; theta =  tensor([4.1159610748, 5.5600299835])\n",
            "Iter 41; theta =  tensor([4.1727724075, 5.6277666092])\n",
            "Iter 42; theta =  tensor([4.2284646034, 5.6941695213])\n",
            "Iter 43; theta =  tensor([4.2830595970, 5.7592649460])\n",
            "Iter 44; theta =  tensor([4.3365793228, 5.8230786324])\n",
            "Iter 45; theta =  tensor([4.3890447617, 5.8856353760])\n",
            "Iter 46; theta =  tensor([4.4404764175, 5.9469604492])\n",
            "Iter 47; theta =  tensor([4.4908952713, 6.0070781708])\n",
            "Iter 48; theta =  tensor([4.5403208733, 6.0660119057])\n",
            "Iter 49; theta =  tensor([4.5887727737, 6.1237854958])\n",
            "Iter 50; theta =  tensor([4.6362700462, 6.1804213524])\n",
            "Iter 51; theta =  tensor([4.6828317642, 6.2359418869])\n",
            "Iter 52; theta =  tensor([4.7284765244, 6.2903690338])\n",
            "Iter 53; theta =  tensor([4.7732219696, 6.3437247276])\n",
            "Iter 54; theta =  tensor([4.8170862198, 6.3960294724])\n",
            "Iter 55; theta =  tensor([4.8600864410, 6.4473047256])\n",
            "Iter 56; theta =  tensor([4.9022393227, 6.4975700378])\n",
            "Iter 57; theta =  tensor([4.9435620308, 6.5468454361])\n",
            "Iter 58; theta =  tensor([4.9840707779, 6.5951504707])\n",
            "Iter 59; theta =  tensor([5.0237812996, 6.6425046921])\n",
            "Iter 60; theta =  tensor([5.0627098083, 6.6889262199])\n",
            "Iter 61; theta =  tensor([5.1008715630, 6.7344336510])\n",
            "Iter 62; theta =  tensor([5.1382813454, 6.7790451050])\n",
            "Iter 63; theta =  tensor([5.1749544144, 6.8227782249])\n",
            "Iter 64; theta =  tensor([5.2109050751, 6.8656501770])\n",
            "Iter 65; theta =  tensor([5.2461476326, 6.9076776505])\n",
            "Iter 66; theta =  tensor([5.2806959152, 6.9488778114])\n",
            "Iter 67; theta =  tensor([5.3145632744, 6.9892668724])\n",
            "Iter 68; theta =  tensor([5.3477635384, 7.0288605690])\n",
            "Iter 69; theta =  tensor([5.3803100586, 7.0676746368])\n",
            "Iter 70; theta =  tensor([5.4122152328, 7.1057243347])\n",
            "Iter 71; theta =  tensor([5.4434919357, 7.1430249214])\n",
            "Iter 72; theta =  tensor([5.4741525650, 7.1795907021])\n",
            "Iter 73; theta =  tensor([5.5042095184, 7.2154364586])\n",
            "Iter 74; theta =  tensor([5.5336742401, 7.2505764961])\n",
            "Iter 75; theta =  tensor([5.5625586510, 7.2850246429])\n",
            "Iter 76; theta =  tensor([5.5908741951, 7.3187942505])\n",
            "Iter 77; theta =  tensor([5.6186318398, 7.3518991470])\n",
            "Iter 78; theta =  tensor([5.6458425522, 7.3843522072])\n",
            "Iter 79; theta =  tensor([5.6725172997, 7.4161663055])\n",
            "Iter 80; theta =  tensor([5.6986665726, 7.4473538399])\n",
            "Iter 81; theta =  tensor([5.7243008614, 7.4779272079])\n",
            "Iter 82; theta =  tensor([5.7494301796, 7.5078983307])\n",
            "Iter 83; theta =  tensor([5.7740645409, 7.5372796059])\n",
            "Iter 84; theta =  tensor([5.7982134819, 7.5660820007])\n",
            "Iter 85; theta =  tensor([5.8218865395, 7.5943174362])\n",
            "Iter 86; theta =  tensor([5.8450932503, 7.6219968796])\n",
            "Iter 87; theta =  tensor([5.8678431511, 7.6491312981])\n",
            "Iter 88; theta =  tensor([5.8901448250, 7.6757316589])\n",
            "Iter 89; theta =  tensor([5.9120073318, 7.7018079758])\n",
            "Iter 90; theta =  tensor([5.9334392548, 7.7273707390])\n",
            "Iter 91; theta =  tensor([5.9544487000, 7.7524304390])\n",
            "Iter 92; theta =  tensor([5.9750442505, 7.7769966125])\n",
            "Iter 93; theta =  tensor([5.9952340126, 7.8010787964])\n",
            "Iter 94; theta =  tensor([6.0150260925, 7.8246870041])\n",
            "Iter 95; theta =  tensor([6.0344285965, 7.8478302956])\n",
            "Iter 96; theta =  tensor([6.0534486771, 7.8705177307])\n",
            "Iter 97; theta =  tensor([6.0720939636, 7.8927583694])\n",
            "Iter 98; theta =  tensor([6.0903720856, 7.9145612717])\n",
            "Iter 99; theta =  tensor([6.1082901955, 7.9359350204])\n",
            "Iter 100; theta =  tensor([6.1258554459, 7.9568877220])\n",
            "Iter 101; theta =  tensor([6.1430745125, 7.9774279594])\n",
            "Iter 102; theta =  tensor([6.1599545479, 7.9975633621])\n",
            "Iter 103; theta =  tensor([6.1765022278, 8.0173025131])\n",
            "Iter 104; theta =  tensor([6.1927237511, 8.0366525650])\n",
            "Iter 105; theta =  tensor([6.2086257935, 8.0556221008])\n",
            "Iter 106; theta =  tensor([6.2242145538, 8.0742177963])\n",
            "Iter 107; theta =  tensor([6.2394962311, 8.0924472809])\n",
            "Iter 108; theta =  tensor([6.2544770241, 8.1103181839])\n",
            "Iter 109; theta =  tensor([6.2691626549, 8.1278371811])\n",
            "Iter 110; theta =  tensor([6.2835588455, 8.1450109482])\n",
            "Iter 111; theta =  tensor([6.2976713181, 8.1618471146])\n",
            "Iter 112; theta =  tensor([6.3115057945, 8.1783514023])\n",
            "Iter 113; theta =  tensor([6.3250679970, 8.1945304871])\n",
            "Iter 114; theta =  tensor([6.3383631706, 8.2103910446])\n",
            "Iter 115; theta =  tensor([6.3513960838, 8.2259397507])\n",
            "Iter 116; theta =  tensor([6.3641724586, 8.2411823273])\n",
            "Iter 117; theta =  tensor([6.3766970634, 8.2561244965])\n",
            "Iter 118; theta =  tensor([6.3889751434, 8.2707719803])\n",
            "Iter 119; theta =  tensor([6.4010114670, 8.2851314545])\n",
            "Iter 120; theta =  tensor([6.4128103256, 8.2992076874])\n",
            "Iter 121; theta =  tensor([6.4243769646, 8.3130073547])\n",
            "Iter 122; theta =  tensor([6.4357156754, 8.3265352249])\n",
            "Iter 123; theta =  tensor([6.4468312263, 8.3397970200])\n",
            "Iter 124; theta =  tensor([6.4577279091, 8.3527975082])\n",
            "Iter 125; theta =  tensor([6.4684095383, 8.3655414581])\n",
            "Iter 126; theta =  tensor([6.4788808823, 8.3780345917])\n",
            "Iter 127; theta =  tensor([6.4891462326, 8.3902816772])\n",
            "Iter 128; theta =  tensor([6.4992094040, 8.4022874832])\n",
            "Iter 129; theta =  tensor([6.5090742111, 8.4140567780])\n",
            "Iter 130; theta =  tensor([6.5187444687, 8.4255943298])\n",
            "Iter 131; theta =  tensor([6.5282244682, 8.4369049072])\n",
            "Iter 132; theta =  tensor([6.5375175476, 8.4479932785])\n",
            "Iter 133; theta =  tensor([6.5466275215, 8.4588632584])\n",
            "Iter 134; theta =  tensor([6.5555582047, 8.4695186615])\n",
            "Iter 135; theta =  tensor([6.5643129349, 8.4799642563])\n",
            "Iter 136; theta =  tensor([6.5728950500, 8.4902048111])\n",
            "Iter 137; theta =  tensor([6.5813083649, 8.5002431870])\n",
            "Iter 138; theta =  tensor([6.5895557404, 8.5100841522])\n",
            "Iter 139; theta =  tensor([6.5976409912, 8.5197315216])\n",
            "Iter 140; theta =  tensor([6.6055669785, 8.5291881561])\n",
            "Iter 141; theta =  tensor([6.6133365631, 8.5384588242])\n",
            "Iter 142; theta =  tensor([6.6209530830, 8.5475473404])\n",
            "Iter 143; theta =  tensor([6.6284198761, 8.5564565659])\n",
            "Iter 144; theta =  tensor([6.6357393265, 8.5651903152])\n",
            "Iter 145; theta =  tensor([6.6429147720, 8.5737524033])\n",
            "Iter 146; theta =  tensor([6.6499485970, 8.5821456909])\n",
            "Iter 147; theta =  tensor([6.6568441391, 8.5903739929])\n",
            "Iter 148; theta =  tensor([6.6636037827, 8.5984401703])\n",
            "Iter 149; theta =  tensor([6.6702303886, 8.6063470840])\n",
            "Iter 150; theta =  tensor([6.6767263412, 8.6140985489])\n",
            "Iter 151; theta =  tensor([6.6830945015, 8.6216974258])\n",
            "Iter 152; theta =  tensor([6.6893367767, 8.6291465759])\n",
            "Iter 153; theta =  tensor([6.6954565048, 8.6364488602])\n",
            "Iter 154; theta =  tensor([6.7014555931, 8.6436080933])\n",
            "Iter 155; theta =  tensor([6.7073364258, 8.6506261826])\n",
            "Iter 156; theta =  tensor([6.7131013870, 8.6575059891])\n",
            "Iter 157; theta =  tensor([6.7187528610, 8.6642503738])\n",
            "Iter 158; theta =  tensor([6.7242927551, 8.6708612442])\n",
            "Iter 159; theta =  tensor([6.7297239304, 8.6773424149])\n",
            "Iter 160; theta =  tensor([6.7350478172, 8.6836957932])\n",
            "Iter 161; theta =  tensor([6.7402667999, 8.6899242401])\n",
            "Iter 162; theta =  tensor([6.7453832626, 8.6960296631])\n",
            "Iter 163; theta =  tensor([6.7503986359, 8.7020149231])\n",
            "Iter 164; theta =  tensor([6.7553153038, 8.7078828812])\n",
            "Iter 165; theta =  tensor([6.7601351738, 8.7136354446])\n",
            "Iter 166; theta =  tensor([6.7648601532, 8.7192745209])\n",
            "Iter 167; theta =  tensor([6.7694921494, 8.7248020172])\n",
            "Iter 168; theta =  tensor([6.7740325928, 8.7302207947])\n",
            "Iter 169; theta =  tensor([6.7784838676, 8.7355327606])\n",
            "Iter 170; theta =  tensor([6.7828474045, 8.7407407761])\n",
            "Iter 171; theta =  tensor([6.7871251106, 8.7458457947])\n",
            "Iter 172; theta =  tensor([6.7913184166, 8.7508506775])\n",
            "Iter 173; theta =  tensor([6.7954292297, 8.7557563782])\n",
            "Iter 174; theta =  tensor([6.7994589806, 8.7605657578])\n",
            "Iter 175; theta =  tensor([6.8034090996, 8.7652807236])\n",
            "Iter 176; theta =  tensor([6.8072814941, 8.7699022293])\n",
            "Iter 177; theta =  tensor([6.8110775948, 8.7744331360])\n",
            "Iter 178; theta =  tensor([6.8147988319, 8.7788743973])\n",
            "Iter 179; theta =  tensor([6.8184471130, 8.7832288742])\n",
            "Iter 180; theta =  tensor([6.8220233917, 8.7874975204])\n",
            "Iter 181; theta =  tensor([6.8255290985, 8.7916822433])\n",
            "Iter 182; theta =  tensor([6.8289656639, 8.7957839966])\n",
            "Iter 183; theta =  tensor([6.8323345184, 8.7998056412])\n",
            "Iter 184; theta =  tensor([6.8356370926, 8.8037481308])\n",
            "Iter 185; theta =  tensor([6.8388748169, 8.8076124191])\n",
            "Iter 186; theta =  tensor([6.8420486450, 8.8114004135])\n",
            "Iter 187; theta =  tensor([6.8451600075, 8.8151140213])\n",
            "Iter 188; theta =  tensor([6.8482098579, 8.8187541962])\n",
            "Iter 189; theta =  tensor([6.8511996269, 8.8223228455])\n",
            "Iter 190; theta =  tensor([6.8541307449, 8.8258218765])\n",
            "Iter 191; theta =  tensor([6.8570041656, 8.8292512894])\n",
            "Iter 192; theta =  tensor([6.8598208427, 8.8326139450])\n",
            "Iter 193; theta =  tensor([6.8625822067, 8.8359098434])\n",
            "Iter 194; theta =  tensor([6.8652892113, 8.8391408920])\n",
            "Iter 195; theta =  tensor([6.8679428101, 8.8423080444])\n",
            "Iter 196; theta =  tensor([6.8705439568, 8.8454132080])\n",
            "Iter 197; theta =  tensor([6.8730940819, 8.8484573364])\n",
            "Iter 198; theta =  tensor([6.8755936623, 8.8514413834])\n",
            "Iter 199; theta =  tensor([6.8780441284, 8.8543663025])\n",
            "Iter 200; theta =  tensor([6.8804464340, 8.8572340012])\n",
            "Iter 201; theta =  tensor([6.8828015327, 8.8600454330])\n",
            "Iter 202; theta =  tensor([6.8851099014, 8.8628015518])\n",
            "Iter 203; theta =  tensor([6.8873729706, 8.8655033112])\n",
            "Iter 204; theta =  tensor([6.8895916939, 8.8681516647])\n",
            "Iter 205; theta =  tensor([6.8917665482, 8.8707475662])\n",
            "Iter 206; theta =  tensor([6.8938984871, 8.8732929230])\n",
            "Iter 207; theta =  tensor([6.8959884644, 8.8757877350])\n",
            "Iter 208; theta =  tensor([6.8980374336, 8.8782339096])\n",
            "Iter 209; theta =  tensor([6.9000458717, 8.8806314468])\n",
            "Iter 210; theta =  tensor([6.9020147324, 8.8829822540])\n",
            "Iter 211; theta =  tensor([6.9039449692, 8.8852863312])\n",
            "Iter 212; theta =  tensor([6.9058370590, 8.8875455856])\n",
            "Iter 213; theta =  tensor([6.9076919556, 8.8897600174])\n",
            "Iter 214; theta =  tensor([6.9095101357, 8.8919305801])\n",
            "Iter 215; theta =  tensor([6.9112925529, 8.8940582275])\n",
            "Iter 216; theta =  tensor([6.9130396843, 8.8961439133])\n",
            "Iter 217; theta =  tensor([6.9147524834, 8.8981885910])\n",
            "Iter 218; theta =  tensor([6.9164319038, 8.9001932144])\n",
            "Iter 219; theta =  tensor([6.9180779457, 8.9021587372])\n",
            "Iter 220; theta =  tensor([6.9196915627, 8.9040851593])\n",
            "Iter 221; theta =  tensor([6.9212737083, 8.9059734344])\n",
            "Iter 222; theta =  tensor([6.9228243828, 8.9078245163])\n",
            "Iter 223; theta =  tensor([6.9243445396, 8.9096393585])\n",
            "Iter 224; theta =  tensor([6.9258346558, 8.9114189148])\n",
            "Iter 225; theta =  tensor([6.9272956848, 8.9131631851])\n",
            "Iter 226; theta =  tensor([6.9287276268, 8.9148731232])\n",
            "Iter 227; theta =  tensor([6.9301314354, 8.9165496826])\n",
            "Iter 228; theta =  tensor([6.9315075874, 8.9181928635])\n",
            "Iter 229; theta =  tensor([6.9328565598, 8.9198036194])\n",
            "Iter 230; theta =  tensor([6.9341793060, 8.9213829041])\n",
            "Iter 231; theta =  tensor([6.9354758263, 8.9229307175])\n",
            "Iter 232; theta =  tensor([6.9367465973, 8.9244480133])\n",
            "Iter 233; theta =  tensor([6.9379925728, 8.9259357452])\n",
            "Iter 234; theta =  tensor([6.9392142296, 8.9273939133])\n",
            "Iter 235; theta =  tensor([6.9404115677, 8.9288234711])\n",
            "Iter 236; theta =  tensor([6.9415855408, 8.9302253723])\n",
            "Iter 237; theta =  tensor([6.9427361488, 8.9315996170])\n",
            "Iter 238; theta =  tensor([6.9438643456, 8.9329462051])\n",
            "Iter 239; theta =  tensor([6.9449701309, 8.9342670441])\n",
            "Iter 240; theta =  tensor([6.9460539818, 8.9355611801])\n",
            "Iter 241; theta =  tensor([6.9471163750, 8.9368305206])\n",
            "Iter 242; theta =  tensor([6.9481582642, 8.9380741119])\n",
            "Iter 243; theta =  tensor([6.9491796494, 8.9392938614])\n",
            "Iter 244; theta =  tensor([6.9501805305, 8.9404888153])\n",
            "Iter 245; theta =  tensor([6.9511618614, 8.9416608810])\n",
            "Iter 246; theta =  tensor([6.9521236420, 8.9428100586])\n",
            "Iter 247; theta =  tensor([6.9530668259, 8.9439363480])\n",
            "Iter 248; theta =  tensor([6.9539914131, 8.9450407028])\n",
            "Iter 249; theta =  tensor([6.9548978806, 8.9461231232])\n",
            "Iter 250; theta =  tensor([6.9557862282, 8.9471836090])\n",
            "Iter 251; theta =  tensor([6.9566569328, 8.9482240677])\n",
            "Iter 252; theta =  tensor([6.9575104713, 8.9492435455])\n",
            "Iter 253; theta =  tensor([6.9583473206, 8.9502429962])\n",
            "Iter 254; theta =  tensor([6.9591679573, 8.9512224197])\n",
            "Iter 255; theta =  tensor([6.9599723816, 8.9521827698])\n",
            "Iter 256; theta =  tensor([6.9607610703, 8.9531240463])\n",
            "Iter 257; theta =  tensor([6.9615340233, 8.9540472031])\n",
            "Iter 258; theta =  tensor([6.9622917175, 8.9549522400])\n",
            "Iter 259; theta =  tensor([6.9630346298, 8.9558391571])\n",
            "Iter 260; theta =  tensor([6.9637627602, 8.9567089081])\n",
            "Iter 261; theta =  tensor([6.9644765854, 8.9575614929])\n",
            "Iter 262; theta =  tensor([6.9651761055, 8.9583969116])\n",
            "Iter 263; theta =  tensor([6.9658622742, 8.9592161179])\n",
            "Iter 264; theta =  tensor([6.9665346146, 8.9600191116])\n",
            "Iter 265; theta =  tensor([6.9671936035, 8.9608068466])\n",
            "Iter 266; theta =  tensor([6.9678397179, 8.9615783691])\n",
            "Iter 267; theta =  tensor([6.9684734344, 8.9623346329])\n",
            "Iter 268; theta =  tensor([6.9690942764, 8.9630765915])\n",
            "Iter 269; theta =  tensor([6.9697031975, 8.9638032913])\n",
            "Iter 270; theta =  tensor([6.9703001976, 8.9645156860])\n",
            "Iter 271; theta =  tensor([6.9708852768, 8.9652147293])\n",
            "Iter 272; theta =  tensor([6.9714589119, 8.9658994675])\n",
            "Iter 273; theta =  tensor([6.9720211029, 8.9665708542])\n",
            "Iter 274; theta =  tensor([6.9725723267, 8.9672288895])\n",
            "Iter 275; theta =  tensor([6.9731125832, 8.9678745270])\n",
            "Iter 276; theta =  tensor([6.9736423492, 8.9685068130])\n",
            "Iter 277; theta =  tensor([6.9741616249, 8.9691267014])\n",
            "Iter 278; theta =  tensor([6.9746704102, 8.9697341919])\n",
            "Iter 279; theta =  tensor([6.9751691818, 8.9703302383])\n",
            "Iter 280; theta =  tensor([6.9756584167, 8.9709148407])\n",
            "Iter 281; theta =  tensor([6.9761381149, 8.9714879990])\n",
            "Iter 282; theta =  tensor([6.9766082764, 8.9720497131])\n",
            "Iter 283; theta =  tensor([6.9770689011, 8.9725999832])\n",
            "Iter 284; theta =  tensor([6.9775204659, 8.9731397629])\n",
            "Iter 285; theta =  tensor([6.9779634476, 8.9736690521])\n",
            "Iter 286; theta =  tensor([6.9783973694, 8.9741878510])\n",
            "Iter 287; theta =  tensor([6.9788227081, 8.9746961594])\n",
            "Iter 288; theta =  tensor([6.9792399406, 8.9751939774])\n",
            "Iter 289; theta =  tensor([6.9796490669, 8.9756822586])\n",
            "Iter 290; theta =  tensor([6.9800500870, 8.9761610031])\n",
            "Iter 291; theta =  tensor([6.9804430008, 8.9766302109])\n",
            "Iter 292; theta =  tensor([6.9808282852, 8.9770908356])\n",
            "Iter 293; theta =  tensor([6.9812059402, 8.9775419235])\n",
            "Iter 294; theta =  tensor([6.9815759659, 8.9779844284])\n",
            "Iter 295; theta =  tensor([6.9819388390, 8.9784183502])\n",
            "Iter 296; theta =  tensor([6.9822945595, 8.9788436890])\n",
            "Iter 297; theta =  tensor([6.9826431274, 8.9792604446])\n",
            "Iter 298; theta =  tensor([6.9829850197, 8.9796686172])\n",
            "Iter 299; theta =  tensor([6.9833202362, 8.9800691605])\n",
            "Iter 300; theta =  tensor([6.9836487770, 8.9804620743])\n",
            "Iter 301; theta =  tensor([6.9839706421, 8.9808464050])\n",
            "Iter 302; theta =  tensor([6.9842863083, 8.9812231064])\n",
            "Iter 303; theta =  tensor([6.9845957756, 8.9815931320])\n",
            "Iter 304; theta =  tensor([6.9848990440, 8.9819555283])\n",
            "Iter 305; theta =  tensor([6.9851965904, 8.9823112488])\n",
            "Iter 306; theta =  tensor([6.9854884148, 8.9826593399])\n",
            "Iter 307; theta =  tensor([6.9857740402, 8.9830007553])\n",
            "Iter 308; theta =  tensor([6.9860544205, 8.9833354950])\n",
            "Iter 309; theta =  tensor([6.9863290787, 8.9836635590])\n",
            "Iter 310; theta =  tensor([6.9865984917, 8.9839849472])\n",
            "Iter 311; theta =  tensor([6.9868626595, 8.9843006134])\n",
            "Iter 312; theta =  tensor([6.9871215820, 8.9846096039])\n",
            "Iter 313; theta =  tensor([6.9873752594, 8.9849128723])\n",
            "Iter 314; theta =  tensor([6.9876241684, 8.9852104187])\n",
            "Iter 315; theta =  tensor([6.9878678322, 8.9855012894])\n",
            "Iter 316; theta =  tensor([6.9881067276, 8.9857864380])\n",
            "Iter 317; theta =  tensor([6.9883408546, 8.9860658646])\n",
            "Iter 318; theta =  tensor([6.9885706902, 8.9863405228])\n",
            "Iter 319; theta =  tensor([6.9887957573, 8.9866094589])\n",
            "Iter 320; theta =  tensor([6.9890165329, 8.9868726730])\n",
            "Iter 321; theta =  tensor([6.9892330170, 8.9871311188])\n",
            "Iter 322; theta =  tensor([6.9894452095, 8.9873847961])\n",
            "Iter 323; theta =  tensor([6.9896531105, 8.9876327515])\n",
            "Iter 324; theta =  tensor([6.9898567200, 8.9878759384])\n"
          ]
        }
      ],
      "source": [
        "# Testando com derivada autograd. Sua função deve retornar algo perto de 7 e 9\n",
        "theta = gd(derivada_torch, media_erros_quadrados, X, y)\n",
        "#cada iteração impressa no terminal é uma \"epoch\" do modelo. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "-YZwD4GZonbo"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([6.9872307777, 8.9908800125], requires_grad=True)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "theta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "p9DuRmmjonbr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter 0; theta =  tensor([0.9532710910, 1.1003383398], requires_grad=True)\n",
            "Iter 1; theta =  tensor([1.0108392239, 1.1823592186])\n",
            "Iter 2; theta =  tensor([1.0678617954, 1.2635266781])\n",
            "Iter 3; theta =  tensor([1.1243438721, 1.3438494205])\n",
            "Iter 4; theta =  tensor([1.1802905798, 1.4233363867])\n",
            "Iter 5; theta =  tensor([1.2357070446, 1.5019962788])\n",
            "Iter 6; theta =  tensor([1.2905981541, 1.5798376799])\n",
            "Iter 7; theta =  tensor([1.3449689150, 1.6568691730])\n",
            "Iter 8; theta =  tensor([1.3988243341, 1.7330991030])\n",
            "Iter 9; theta =  tensor([1.4521691799, 1.8085359335])\n",
            "Iter 10; theta =  tensor([1.5050082207, 1.8831878901])\n",
            "Iter 11; theta =  tensor([1.5573462248, 1.9570631981])\n",
            "Iter 12; theta =  tensor([1.6091879606, 2.0301699638])\n",
            "Iter 13; theta =  tensor([1.6605381966, 2.1025161743])\n",
            "Iter 14; theta =  tensor([1.7114014626, 2.1741096973])\n",
            "Iter 15; theta =  tensor([1.7617822886, 2.2449584007])\n",
            "Iter 16; theta =  tensor([1.8116853237, 2.3150701523])\n",
            "Iter 17; theta =  tensor([1.8611150980, 2.3844525814])\n",
            "Iter 18; theta =  tensor([1.9100760221, 2.4531133175])\n",
            "Iter 19; theta =  tensor([1.9585725069, 2.5210597515])\n",
            "Iter 20; theta =  tensor([2.0066089630, 2.5882995129])\n",
            "Iter 21; theta =  tensor([2.0541896820, 2.6548397541])\n",
            "Iter 22; theta =  tensor([2.1013190746, 2.7206878662])\n",
            "Iter 23; theta =  tensor([2.1480014324, 2.7858510017])\n",
            "Iter 24; theta =  tensor([2.1942408085, 2.8503365517])\n",
            "Iter 25; theta =  tensor([2.2400414944, 2.9141514301])\n",
            "Iter 26; theta =  tensor([2.2854075432, 2.9773025513])\n",
            "Iter 27; theta =  tensor([2.3303432465, 3.0397968292])\n",
            "Iter 28; theta =  tensor([2.3748524189, 3.1016411781])\n",
            "Iter 29; theta =  tensor([2.4189391136, 3.1628425121])\n",
            "Iter 30; theta =  tensor([2.4626073837, 3.2234072685])\n",
            "Iter 31; theta =  tensor([2.5058612823, 3.2833421230])\n",
            "Iter 32; theta =  tensor([2.5487046242, 3.3426537514])\n",
            "Iter 33; theta =  tensor([2.5911412239, 3.4013485909])\n",
            "Iter 34; theta =  tensor([2.6331751347, 3.4594330788])\n",
            "Iter 35; theta =  tensor([2.6748099327, 3.5169136524])\n",
            "Iter 36; theta =  tensor([2.7160494328, 3.5737965107])\n",
            "Iter 37; theta =  tensor([2.7568974495, 3.6300880909])\n",
            "Iter 38; theta =  tensor([2.7973577976, 3.6857943535])\n",
            "Iter 39; theta =  tensor([2.8374338150, 3.7409214973])\n",
            "Iter 40; theta =  tensor([2.8771293163, 3.7954754829])\n",
            "Iter 41; theta =  tensor([2.9164478779, 3.8494622707])\n",
            "Iter 42; theta =  tensor([2.9553930759, 3.9028875828])\n",
            "Iter 43; theta =  tensor([2.9939684868, 3.9557576180])\n",
            "Iter 44; theta =  tensor([3.0321774483, 4.0080780983])\n",
            "Iter 45; theta =  tensor([3.0700235367, 4.0598545074])\n",
            "Iter 46; theta =  tensor([3.1075103283, 4.1110925674])\n",
            "Iter 47; theta =  tensor([3.1446409225, 4.1617980003])\n",
            "Iter 48; theta =  tensor([3.1814188957, 4.2119765282])\n",
            "Iter 49; theta =  tensor([3.2178475857, 4.2616333961])\n",
            "Iter 50; theta =  tensor([3.2539300919, 4.3107743263])\n",
            "Iter 51; theta =  tensor([3.2896697521, 4.3594040871])\n",
            "Iter 52; theta =  tensor([3.3250699043, 4.4075284004])\n",
            "Iter 53; theta =  tensor([3.3601336479, 4.4551525116])\n",
            "Iter 54; theta =  tensor([3.3948643208, 4.5022816658])\n",
            "Iter 55; theta =  tensor([3.4292650223, 4.5489211082])\n",
            "Iter 56; theta =  tensor([3.4633388519, 4.5950760841])\n",
            "Iter 57; theta =  tensor([3.4970889091, 4.6407513618])\n",
            "Iter 58; theta =  tensor([3.5305180550, 4.6859517097])\n",
            "Iter 59; theta =  tensor([3.5636296272, 4.7306823730])\n",
            "Iter 60; theta =  tensor([3.5964264870, 4.7749481201])\n",
            "Iter 61; theta =  tensor([3.6289117336, 4.8187537193])\n",
            "Iter 62; theta =  tensor([3.6610879898, 4.8621044159])\n",
            "Iter 63; theta =  tensor([3.6929585934, 4.9050045013])\n",
            "Iter 64; theta =  tensor([3.7245261669, 4.9474587440])\n",
            "Iter 65; theta =  tensor([3.7557935715, 4.9894719124])\n",
            "Iter 66; theta =  tensor([3.7867636681, 5.0310487747])\n",
            "Iter 67; theta =  tensor([3.8174393177, 5.0721936226])\n",
            "Iter 68; theta =  tensor([3.8478233814, 5.1129107475])\n",
            "Iter 69; theta =  tensor([3.8779184818, 5.1532049179])\n",
            "Iter 70; theta =  tensor([3.9077274799, 5.1930804253])\n",
            "Iter 71; theta =  tensor([3.9372529984, 5.2325415611])\n",
            "Iter 72; theta =  tensor([3.9664978981, 5.2715926170])\n",
            "Iter 73; theta =  tensor([3.9954645634, 5.3102383614])\n",
            "Iter 74; theta =  tensor([4.0241556168, 5.3484826088])\n",
            "Iter 75; theta =  tensor([4.0525741577, 5.3863291740])\n",
            "Iter 76; theta =  tensor([4.0807223320, 5.4237828255])\n",
            "Iter 77; theta =  tensor([4.1086025238, 5.4608473778])\n",
            "Iter 78; theta =  tensor([4.1362175941, 5.4975271225])\n",
            "Iter 79; theta =  tensor([4.1635699272, 5.5338258743])\n",
            "Iter 80; theta =  tensor([4.1906619072, 5.5697474480])\n",
            "Iter 81; theta =  tensor([4.2174963951, 5.6052956581])\n",
            "Iter 82; theta =  tensor([4.2440757751, 5.6404747963])\n",
            "Iter 83; theta =  tensor([4.2704019547, 5.6752886772])\n",
            "Iter 84; theta =  tensor([4.2964777946, 5.7097406387])\n",
            "Iter 85; theta =  tensor([4.3223056793, 5.7438349724])\n",
            "Iter 86; theta =  tensor([4.3478875160, 5.7775750160])\n",
            "Iter 87; theta =  tensor([4.3732261658, 5.8109650612])\n",
            "Iter 88; theta =  tensor([4.3983235359, 5.8440079689])\n",
            "Iter 89; theta =  tensor([4.4231820107, 5.8767080307])\n",
            "Iter 90; theta =  tensor([4.4478039742, 5.9090685844])\n",
            "Iter 91; theta =  tensor([4.4721913338, 5.9410929680])\n",
            "Iter 92; theta =  tensor([4.4963469505, 5.9727845192])\n",
            "Iter 93; theta =  tensor([4.5202727318, 6.0041470528])\n",
            "Iter 94; theta =  tensor([4.5439705849, 6.0351839066])\n",
            "Iter 95; theta =  tensor([4.5674428940, 6.0658984184])\n",
            "Iter 96; theta =  tensor([4.5906915665, 6.0962944031])\n",
            "Iter 97; theta =  tensor([4.6137189865, 6.1263747215])\n",
            "Iter 98; theta =  tensor([4.6365270615, 6.1561427116])\n",
            "Iter 99; theta =  tensor([4.6591181755, 6.1856017113])\n",
            "Iter 100; theta =  tensor([4.6814942360, 6.2147545815])\n",
            "Iter 101; theta =  tensor([4.7036571503, 6.2436046600])\n",
            "Iter 102; theta =  tensor([4.7256088257, 6.2721552849])\n",
            "Iter 103; theta =  tensor([4.7473516464, 6.3004097939])\n",
            "Iter 104; theta =  tensor([4.7688875198, 6.3283710480])\n",
            "Iter 105; theta =  tensor([4.7902183533, 6.3560419083])\n",
            "Iter 106; theta =  tensor([4.8113460541, 6.3834252357])\n",
            "Iter 107; theta =  tensor([4.8322725296, 6.4105243683])\n",
            "Iter 108; theta =  tensor([4.8529996872, 6.4373421669])\n",
            "Iter 109; theta =  tensor([4.8735294342, 6.4638819695])\n",
            "Iter 110; theta =  tensor([4.8938632011, 6.4901461601])\n",
            "Iter 111; theta =  tensor([4.9140033722, 6.5161375999])\n",
            "Iter 112; theta =  tensor([4.9339518547, 6.5418591499])\n",
            "Iter 113; theta =  tensor([4.9537100792, 6.5673141479])\n",
            "Iter 114; theta =  tensor([4.9732799530, 6.5925045013])\n",
            "Iter 115; theta =  tensor([4.9926633835, 6.6174335480])\n",
            "Iter 116; theta =  tensor([5.0118622780, 6.6421041489])\n",
            "Iter 117; theta =  tensor([5.0308785439, 6.6665186882])\n",
            "Iter 118; theta =  tensor([5.0497131348, 6.6906795502])\n",
            "Iter 119; theta =  tensor([5.0683684349, 6.7145895958])\n",
            "Iter 120; theta =  tensor([5.0868458748, 6.7382516861])\n",
            "Iter 121; theta =  tensor([5.1051473618, 6.7616682053])\n",
            "Iter 122; theta =  tensor([5.1232743263, 6.7848420143])\n",
            "Iter 123; theta =  tensor([5.1412286758, 6.8077750206])\n",
            "Iter 124; theta =  tensor([5.1590118408, 6.8304700851])\n",
            "Iter 125; theta =  tensor([5.1766257286, 6.8529295921])\n",
            "Iter 126; theta =  tensor([5.1940712929, 6.8751564026])\n",
            "Iter 127; theta =  tensor([5.2113509178, 6.8971524239])\n",
            "Iter 128; theta =  tensor([5.2284655571, 6.9189200401])\n",
            "Iter 129; theta =  tensor([5.2454171181, 6.9404621124])\n",
            "Iter 130; theta =  tensor([5.2622070312, 6.9617805481])\n",
            "Iter 131; theta =  tensor([5.2788367271, 6.9828777313])\n",
            "Iter 132; theta =  tensor([5.2953081131, 7.0037560463])\n",
            "Iter 133; theta =  tensor([5.3116226196, 7.0244178772])\n",
            "Iter 134; theta =  tensor([5.3277812004, 7.0448656082])\n",
            "Iter 135; theta =  tensor([5.3437857628, 7.0651011467])\n",
            "Iter 136; theta =  tensor([5.3596377373, 7.0851264000])\n",
            "Iter 137; theta =  tensor([5.3753385544, 7.1049442291])\n",
            "Iter 138; theta =  tensor([5.3908896446, 7.1245565414])\n",
            "Iter 139; theta =  tensor([5.4062924385, 7.1439652443])\n",
            "Iter 140; theta =  tensor([5.4215483665, 7.1631727219])\n",
            "Iter 141; theta =  tensor([5.4366588593, 7.1821808815])\n",
            "Iter 142; theta =  tensor([5.4516253471, 7.2009921074])\n",
            "Iter 143; theta =  tensor([5.4664487839, 7.2196078300])\n",
            "Iter 144; theta =  tensor([5.4811310768, 7.2380309105])\n",
            "Iter 145; theta =  tensor([5.4956731796, 7.2562627792])\n",
            "Iter 146; theta =  tensor([5.5100765228, 7.2743053436])\n",
            "Iter 147; theta =  tensor([5.5243425369, 7.2921609879])\n",
            "Iter 148; theta =  tensor([5.5384721756, 7.3098316193])\n",
            "Iter 149; theta =  tensor([5.5524673462, 7.3273186684])\n",
            "Iter 150; theta =  tensor([5.5663290024, 7.3446245193])\n",
            "Iter 151; theta =  tensor([5.5800580978, 7.3617510796])\n",
            "Iter 152; theta =  tensor([5.5936560631, 7.3786997795])\n",
            "Iter 153; theta =  tensor([5.6071243286, 7.3954730034])\n",
            "Iter 154; theta =  tensor([5.6204643250, 7.4120721817])\n",
            "Iter 155; theta =  tensor([5.6336770058, 7.4284992218])\n",
            "Iter 156; theta =  tensor([5.6467633247, 7.4447560310])\n",
            "Iter 157; theta =  tensor([5.6597247124, 7.4608440399])\n",
            "Iter 158; theta =  tensor([5.6725625992, 7.4767651558])\n",
            "Iter 159; theta =  tensor([5.6852779388, 7.4925212860])\n",
            "Iter 160; theta =  tensor([5.6978716850, 7.5081143379])\n",
            "Iter 161; theta =  tensor([5.7103452682, 7.5235457420])\n",
            "Iter 162; theta =  tensor([5.7227001190, 7.5388169289])\n",
            "Iter 163; theta =  tensor([5.7349367142, 7.5539298058])\n",
            "Iter 164; theta =  tensor([5.7470564842, 7.5688862801])\n",
            "Iter 165; theta =  tensor([5.7590608597, 7.5836873055])\n",
            "Iter 166; theta =  tensor([5.7709503174, 7.5983352661])\n",
            "Iter 167; theta =  tensor([5.7827262878, 7.6128311157])\n",
            "Iter 168; theta =  tensor([5.7943897247, 7.6271767616])\n",
            "Iter 169; theta =  tensor([5.8059420586, 7.6413736343])\n",
            "Iter 170; theta =  tensor([5.8173842430, 7.6554236412])\n",
            "Iter 171; theta =  tensor([5.8287167549, 7.6693277359])\n",
            "Iter 172; theta =  tensor([5.8399410248, 7.6830878258])\n",
            "Iter 173; theta =  tensor([5.8510584831, 7.6967053413])\n",
            "Iter 174; theta =  tensor([5.8620696068, 7.7101817131])\n",
            "Iter 175; theta =  tensor([5.8729753494, 7.7235183716])\n",
            "Iter 176; theta =  tensor([5.8837771416, 7.7367167473])\n",
            "Iter 177; theta =  tensor([5.8944759369, 7.7497782707])\n",
            "Iter 178; theta =  tensor([5.9050722122, 7.7627043724])\n",
            "Iter 179; theta =  tensor([5.9155673981, 7.7754969597])\n",
            "Iter 180; theta =  tensor([5.9259624481, 7.7881569862])\n",
            "Iter 181; theta =  tensor([5.9362583160, 7.8006854057])\n",
            "Iter 182; theta =  tensor([5.9464554787, 7.8130841255])\n",
            "Iter 183; theta =  tensor([5.9565553665, 7.8253545761])\n",
            "Iter 184; theta =  tensor([5.9665589333, 7.8374977112])\n",
            "Iter 185; theta =  tensor([5.9764666557, 7.8495149612])\n",
            "Iter 186; theta =  tensor([5.9862799644, 7.8614077568])\n",
            "Iter 187; theta =  tensor([5.9959993362, 7.8731775284])\n",
            "Iter 188; theta =  tensor([6.0056257248, 7.8848252296])\n",
            "Iter 189; theta =  tensor([6.0151600838, 7.8963522911])\n",
            "Iter 190; theta =  tensor([6.0246033669, 7.9077596664])\n",
            "Iter 191; theta =  tensor([6.0339565277, 7.9190492630])\n",
            "Iter 192; theta =  tensor([6.0432200432, 7.9302215576])\n",
            "Iter 193; theta =  tensor([6.0523953438, 7.9412784576])\n",
            "Iter 194; theta =  tensor([6.0614829063, 7.9522204399])\n",
            "Iter 195; theta =  tensor([6.0704836845, 7.9630494118])\n",
            "Iter 196; theta =  tensor([6.0793981552, 7.9737658501])\n",
            "Iter 197; theta =  tensor([6.0882277489, 7.9843716621])\n",
            "Iter 198; theta =  tensor([6.0969729424, 7.9948673248])\n",
            "Iter 199; theta =  tensor([6.1056342125, 8.0052547455])\n",
            "Iter 200; theta =  tensor([6.1142129898, 8.0155344009])\n",
            "Iter 201; theta =  tensor([6.1227097511, 8.0257072449])\n",
            "Iter 202; theta =  tensor([6.1311249733, 8.0357751846])\n",
            "Iter 203; theta =  tensor([6.1394600868, 8.0457382202])\n",
            "Iter 204; theta =  tensor([6.1477150917, 8.0555982590])\n",
            "Iter 205; theta =  tensor([6.1558914185, 8.0653562546])\n",
            "Iter 206; theta =  tensor([6.1639895439, 8.0750131607])\n",
            "Iter 207; theta =  tensor([6.1720099449, 8.0845699310])\n",
            "Iter 208; theta =  tensor([6.1799540520, 8.0940275192])\n",
            "Iter 209; theta =  tensor([6.1878218651, 8.1033878326])\n",
            "Iter 210; theta =  tensor([6.1956148148, 8.1126508713])\n",
            "Iter 211; theta =  tensor([6.2033329010, 8.1218185425])\n",
            "Iter 212; theta =  tensor([6.2109770775, 8.1308908463])\n",
            "Iter 213; theta =  tensor([6.2185482979, 8.1398696899])\n",
            "Iter 214; theta =  tensor([6.2260470390, 8.1487550735])\n",
            "Iter 215; theta =  tensor([6.2334742546, 8.1575489044])\n",
            "Iter 216; theta =  tensor([6.2408304214, 8.1662511826])\n",
            "Iter 217; theta =  tensor([6.2481160164, 8.1748638153])\n",
            "Iter 218; theta =  tensor([6.2553319931, 8.1833868027])\n",
            "Iter 219; theta =  tensor([6.2624788284, 8.1918220520])\n",
            "Iter 220; theta =  tensor([6.2695574760, 8.2001695633])\n",
            "Iter 221; theta =  tensor([6.2765684128, 8.2084302902])\n",
            "Iter 222; theta =  tensor([6.2835121155, 8.2166061401])\n",
            "Iter 223; theta =  tensor([6.2903895378, 8.2246971130])\n",
            "Iter 224; theta =  tensor([6.2972011566, 8.2327041626])\n",
            "Iter 225; theta =  tensor([6.3039474487, 8.2406282425])\n",
            "Iter 226; theta =  tensor([6.3106293678, 8.2484703064])\n",
            "Iter 227; theta =  tensor([6.3172473907, 8.2562313080])\n",
            "Iter 228; theta =  tensor([6.3238019943, 8.2639122009])\n",
            "Iter 229; theta =  tensor([6.3302936554, 8.2715139389])\n",
            "Iter 230; theta =  tensor([6.3367233276, 8.2790365219])\n",
            "Iter 231; theta =  tensor([6.3430914879, 8.2864809036])\n",
            "Iter 232; theta =  tensor([6.3493986130, 8.2938489914])\n",
            "Iter 233; theta =  tensor([6.3556456566, 8.3011407852])\n",
            "Iter 234; theta =  tensor([6.3618326187, 8.3083572388])\n",
            "Iter 235; theta =  tensor([6.3679604530, 8.3154983521])\n",
            "Iter 236; theta =  tensor([6.3740296364, 8.3225660324])\n",
            "Iter 237; theta =  tensor([6.3800406456, 8.3295602798])\n",
            "Iter 238; theta =  tensor([6.3859939575, 8.3364820480])\n",
            "Iter 239; theta =  tensor([6.3918905258, 8.3433322906])\n",
            "Iter 240; theta =  tensor([6.3977308273, 8.3501119614])\n",
            "Iter 241; theta =  tensor([6.4035148621, 8.3568210602])\n",
            "Iter 242; theta =  tensor([6.4092435837, 8.3634605408])\n",
            "Iter 243; theta =  tensor([6.4149174690, 8.3700313568])\n",
            "Iter 244; theta =  tensor([6.4205369949, 8.3765344620])\n",
            "Iter 245; theta =  tensor([6.4261026382, 8.3829698563])\n",
            "Iter 246; theta =  tensor([6.4316153526, 8.3893394470])\n",
            "Iter 247; theta =  tensor([6.4370751381, 8.3956432343])\n",
            "Iter 248; theta =  tensor([6.4424824715, 8.4018812180])\n",
            "Iter 249; theta =  tensor([6.4478383064, 8.4080543518])\n",
            "Iter 250; theta =  tensor([6.4531426430, 8.4141645432])\n",
            "Iter 251; theta =  tensor([6.4583964348, 8.4202108383])\n",
            "Iter 252; theta =  tensor([6.4635996819, 8.4261951447])\n",
            "Iter 253; theta =  tensor([6.4687528610, 8.4321174622])\n",
            "Iter 254; theta =  tensor([6.4738569260, 8.4379777908])\n",
            "Iter 255; theta =  tensor([6.4789118767, 8.4437780380])\n",
            "Iter 256; theta =  tensor([6.4839186668, 8.4495182037])\n",
            "Iter 257; theta =  tensor([6.4888772964, 8.4551992416])\n",
            "Iter 258; theta =  tensor([6.4937887192, 8.4608211517])\n",
            "Iter 259; theta =  tensor([6.4986529350, 8.4663848877])\n",
            "Iter 260; theta =  tensor([6.5034704208, 8.4718914032])\n",
            "Iter 261; theta =  tensor([6.5082421303, 8.4773406982])\n",
            "Iter 262; theta =  tensor([6.5129680634, 8.4827337265])\n",
            "Iter 263; theta =  tensor([6.5176486969, 8.4880714417])\n",
            "Iter 264; theta =  tensor([6.5222845078, 8.4933538437])\n",
            "Iter 265; theta =  tensor([6.5268754959, 8.4985809326])\n",
            "Iter 266; theta =  tensor([6.5314226151, 8.5037546158])\n",
            "Iter 267; theta =  tensor([6.5359263420, 8.5088748932])\n",
            "Iter 268; theta =  tensor([6.5403866768, 8.5139417648])\n",
            "Iter 269; theta =  tensor([6.5448045731, 8.5189561844])\n",
            "Iter 270; theta =  tensor([6.5491800308, 8.5239191055])\n",
            "Iter 271; theta =  tensor([6.5535135269, 8.5288305283])\n",
            "Iter 272; theta =  tensor([6.5578055382, 8.5336914062])\n",
            "Iter 273; theta =  tensor([6.5620565414, 8.5385017395])\n",
            "Iter 274; theta =  tensor([6.5662665367, 8.5432624817])\n",
            "Iter 275; theta =  tensor([6.5704364777, 8.5479736328])\n",
            "Iter 276; theta =  tensor([6.5745663643, 8.5526361465])\n",
            "Iter 277; theta =  tensor([6.5786566734, 8.5572509766])\n",
            "Iter 278; theta =  tensor([6.5827074051, 8.5618181229])\n",
            "Iter 279; theta =  tensor([6.5867195129, 8.5663375854])\n",
            "Iter 280; theta =  tensor([6.5906929970, 8.5708103180])\n",
            "Iter 281; theta =  tensor([6.5946283340, 8.5752372742])\n",
            "Iter 282; theta =  tensor([6.5985260010, 8.5796184540])\n",
            "Iter 283; theta =  tensor([6.6023864746, 8.5839538574])\n",
            "Iter 284; theta =  tensor([6.6062097549, 8.5882444382])\n",
            "Iter 285; theta =  tensor([6.6099963188, 8.5924911499])\n",
            "Iter 286; theta =  tensor([6.6137466431, 8.5966939926])\n",
            "Iter 287; theta =  tensor([6.6174612045, 8.6008529663])\n",
            "Iter 288; theta =  tensor([6.6211400032, 8.6049690247])\n",
            "Iter 289; theta =  tensor([6.6247835159, 8.6090421677])\n",
            "Iter 290; theta =  tensor([6.6283922195, 8.6130733490])\n",
            "Iter 291; theta =  tensor([6.6319661140, 8.6170635223])\n",
            "Iter 292; theta =  tensor([6.6355061531, 8.6210117340])\n",
            "Iter 293; theta =  tensor([6.6390118599, 8.6249189377])\n",
            "Iter 294; theta =  tensor([6.6424841881, 8.6287860870])\n",
            "Iter 295; theta =  tensor([6.6459231377, 8.6326131821])\n",
            "Iter 296; theta =  tensor([6.6493291855, 8.6364011765])\n",
            "Iter 297; theta =  tensor([6.6527023315, 8.6401500702])\n",
            "Iter 298; theta =  tensor([6.6560430527, 8.6438598633])\n",
            "Iter 299; theta =  tensor([6.6593518257, 8.6475315094])\n",
            "Iter 300; theta =  tensor([6.6626291275, 8.6511650085])\n",
            "Iter 301; theta =  tensor([6.6658749580, 8.6547613144])\n",
            "Iter 302; theta =  tensor([6.6690893173, 8.6583204269])\n",
            "Iter 303; theta =  tensor([6.6722731590, 8.6618423462])\n",
            "Iter 304; theta =  tensor([6.6754264832, 8.6653280258])\n",
            "Iter 305; theta =  tensor([6.6785492897, 8.6687774658])\n",
            "Iter 306; theta =  tensor([6.6816420555, 8.6721916199])\n",
            "Iter 307; theta =  tensor([6.6847052574, 8.6755704880])\n",
            "Iter 308; theta =  tensor([6.6877393723, 8.6789140701])\n",
            "Iter 309; theta =  tensor([6.6907439232, 8.6822233200])\n",
            "Iter 310; theta =  tensor([6.6937198639, 8.6854982376])\n",
            "Iter 311; theta =  tensor([6.6966671944, 8.6887397766])\n",
            "Iter 312; theta =  tensor([6.6995863914, 8.6919479370])\n",
            "Iter 313; theta =  tensor([6.7024774551, 8.6951227188])\n",
            "Iter 314; theta =  tensor([6.7053408623, 8.6982650757])\n",
            "Iter 315; theta =  tensor([6.7081766129, 8.7013750076])\n",
            "Iter 316; theta =  tensor([6.7109851837, 8.7044525146])\n",
            "Iter 317; theta =  tensor([6.7137670517, 8.7074985504])\n",
            "Iter 318; theta =  tensor([6.7165222168, 8.7105131149])\n",
            "Iter 319; theta =  tensor([6.7192506790, 8.7134962082])\n",
            "Iter 320; theta =  tensor([6.7219529152, 8.7164487839])\n",
            "Iter 321; theta =  tensor([6.7246294022, 8.7193708420])\n",
            "Iter 322; theta =  tensor([6.7272801399, 8.7222623825])\n",
            "Iter 323; theta =  tensor([6.7299056053, 8.7251243591])\n",
            "Iter 324; theta =  tensor([6.7325057983, 8.7279567719])\n",
            "Iter 325; theta =  tensor([6.7350807190, 8.7307596207])\n",
            "Iter 326; theta =  tensor([6.7376313210, 8.7335338593])\n",
            "Iter 327; theta =  tensor([6.7401571274, 8.7362794876])\n",
            "Iter 328; theta =  tensor([6.7426586151, 8.7389965057])\n",
            "Iter 329; theta =  tensor([6.7451362610, 8.7416849136])\n",
            "Iter 330; theta =  tensor([6.7475900650, 8.7443456650])\n",
            "Iter 331; theta =  tensor([6.7500205040, 8.7469797134])\n",
            "Iter 332; theta =  tensor([6.7524275780, 8.7495861053])\n",
            "Iter 333; theta =  tensor([6.7548112869, 8.7521657944])\n",
            "Iter 334; theta =  tensor([6.7571721077, 8.7547187805])\n",
            "Iter 335; theta =  tensor([6.7595105171, 8.7572450638])\n",
            "Iter 336; theta =  tensor([6.7618265152, 8.7597455978])\n",
            "Iter 337; theta =  tensor([6.7641201019, 8.7622203827])\n",
            "Iter 338; theta =  tensor([6.7663917542, 8.7646694183])\n",
            "Iter 339; theta =  tensor([6.7686414719, 8.7670936584])\n",
            "Iter 340; theta =  tensor([6.7708697319, 8.7694921494])\n",
            "Iter 341; theta =  tensor([6.7730765343, 8.7718658447])\n",
            "Iter 342; theta =  tensor([6.7752618790, 8.7742156982])\n",
            "Iter 343; theta =  tensor([6.7774262428, 8.7765407562])\n",
            "Iter 344; theta =  tensor([6.7795701027, 8.7788419724])\n",
            "Iter 345; theta =  tensor([6.7816934586, 8.7811193466])\n",
            "Iter 346; theta =  tensor([6.7837963104, 8.7833728790])\n",
            "Iter 347; theta =  tensor([6.7858786583, 8.7856035233])\n",
            "Iter 348; theta =  tensor([6.7879409790, 8.7878112793])\n",
            "Iter 349; theta =  tensor([6.7899837494, 8.7899961472])\n",
            "Iter 350; theta =  tensor([6.7920069695, 8.7921581268])\n",
            "Iter 351; theta =  tensor([6.7940106392, 8.7942981720])\n",
            "Iter 352; theta =  tensor([6.7959952354, 8.7964162827])\n",
            "Iter 353; theta =  tensor([6.7979607582, 8.7985124588])\n",
            "Iter 354; theta =  tensor([6.7999072075, 8.8005867004])\n",
            "Iter 355; theta =  tensor([6.8018350601, 8.8026399612])\n",
            "Iter 356; theta =  tensor([6.8037443161, 8.8046722412])\n",
            "Iter 357; theta =  tensor([6.8056349754, 8.8066835403])\n",
            "Iter 358; theta =  tensor([6.8075075150, 8.8086738586])\n",
            "Iter 359; theta =  tensor([6.8093624115, 8.8106431961])\n",
            "Iter 360; theta =  tensor([6.8111991882, 8.8125925064])\n",
            "Iter 361; theta =  tensor([6.8130183220, 8.8145217896])\n",
            "Iter 362; theta =  tensor([6.8148202896, 8.8164310455])\n",
            "Iter 363; theta =  tensor([6.8166046143, 8.8183202744])\n",
            "Iter 364; theta =  tensor([6.8183717728, 8.8201904297])\n",
            "Iter 365; theta =  tensor([6.8201222420, 8.8220415115])\n",
            "Iter 366; theta =  tensor([6.8218555450, 8.8238735199])\n",
            "Iter 367; theta =  tensor([6.8235721588, 8.8256864548])\n",
            "Iter 368; theta =  tensor([6.8252725601, 8.8274803162])\n",
            "Iter 369; theta =  tensor([6.8269567490, 8.8292560577])\n",
            "Iter 370; theta =  tensor([6.8286247253, 8.8310136795])\n",
            "Iter 371; theta =  tensor([6.8302764893, 8.8327531815])\n",
            "Iter 372; theta =  tensor([6.8319125175, 8.8344745636])\n",
            "Iter 373; theta =  tensor([6.8335328102, 8.8361778259])\n",
            "Iter 374; theta =  tensor([6.8351373672, 8.8378639221])\n",
            "Iter 375; theta =  tensor([6.8367266655, 8.8395328522])\n",
            "Iter 376; theta =  tensor([6.8383007050, 8.8411836624])\n",
            "Iter 377; theta =  tensor([6.8398594856, 8.8428182602])\n",
            "Iter 378; theta =  tensor([6.8414030075, 8.8444356918])\n",
            "Iter 379; theta =  tensor([6.8429317474, 8.8460359573])\n",
            "Iter 380; theta =  tensor([6.8444457054, 8.8476200104])\n",
            "Iter 381; theta =  tensor([6.8459453583, 8.8491878510])\n",
            "Iter 382; theta =  tensor([6.8474307060, 8.8507394791])\n",
            "Iter 383; theta =  tensor([6.8489017487, 8.8522748947])\n",
            "Iter 384; theta =  tensor([6.8503584862, 8.8537950516])\n",
            "Iter 385; theta =  tensor([6.8518013954, 8.8552989960])\n",
            "Iter 386; theta =  tensor([6.8532304764, 8.8567876816])\n",
            "Iter 387; theta =  tensor([6.8546457291, 8.8582611084])\n",
            "Iter 388; theta =  tensor([6.8560471535, 8.8597192764])\n",
            "Iter 389; theta =  tensor([6.8574352264, 8.8611621857])\n",
            "Iter 390; theta =  tensor([6.8588099480, 8.8625907898])\n",
            "Iter 391; theta =  tensor([6.8601713181, 8.8640041351])\n",
            "Iter 392; theta =  tensor([6.8615198135, 8.8654031754])\n",
            "Iter 393; theta =  tensor([6.8628554344, 8.8667879105])\n",
            "Iter 394; theta =  tensor([6.8641781807, 8.8681583405])\n",
            "Iter 395; theta =  tensor([6.8654880524, 8.8695144653])\n",
            "Iter 396; theta =  tensor([6.8667850494, 8.8708562851])\n",
            "Iter 397; theta =  tensor([6.8680696487, 8.8721847534])\n",
            "Iter 398; theta =  tensor([6.8693418503, 8.8734989166])\n",
            "Iter 399; theta =  tensor([6.8706021309, 8.8747997284])\n",
            "Iter 400; theta =  tensor([6.8718500137, 8.8760871887])\n",
            "Iter 401; theta =  tensor([6.8730859756, 8.8773612976])\n",
            "Iter 402; theta =  tensor([6.8743100166, 8.8786220551])\n",
            "Iter 403; theta =  tensor([6.8755221367, 8.8798704147])\n",
            "Iter 404; theta =  tensor([6.8767228127, 8.8811054230])\n",
            "Iter 405; theta =  tensor([6.8779120445, 8.8823280334])\n",
            "Iter 406; theta =  tensor([6.8790898323, 8.8835382462])\n",
            "Iter 407; theta =  tensor([6.8802561760, 8.8847360611])\n",
            "Iter 408; theta =  tensor([6.8814110756, 8.8859214783])\n",
            "Iter 409; theta =  tensor([6.8825550079, 8.8870944977])\n",
            "Iter 410; theta =  tensor([6.8836879730, 8.8882551193])\n",
            "Iter 411; theta =  tensor([6.8848099709, 8.8894042969])\n",
            "Iter 412; theta =  tensor([6.8859214783, 8.8905410767])\n",
            "Iter 413; theta =  tensor([6.8870220184, 8.8916664124])\n",
            "Iter 414; theta =  tensor([6.8881120682, 8.8927803040])\n",
            "Iter 415; theta =  tensor([6.8891916275, 8.8938827515])\n",
            "Iter 416; theta =  tensor([6.8902606964, 8.8949737549])\n",
            "Iter 417; theta =  tensor([6.8913197517, 8.8960533142])\n",
            "Iter 418; theta =  tensor([6.8923683167, 8.8971214294])\n",
            "Iter 419; theta =  tensor([6.8934068680, 8.8981790543])\n",
            "Iter 420; theta =  tensor([6.8944354057, 8.8992261887])\n",
            "Iter 421; theta =  tensor([6.8954539299, 8.9002618790])\n",
            "Iter 422; theta =  tensor([6.8964629173, 8.9012870789])\n",
            "Iter 423; theta =  tensor([6.8974618912, 8.9023017883])\n",
            "Iter 424; theta =  tensor([6.8984513283, 8.9033060074])\n",
            "Iter 425; theta =  tensor([6.8994312286, 8.9042997360])\n",
            "Iter 426; theta =  tensor([6.9004015923, 8.9052829742])\n",
            "Iter 427; theta =  tensor([6.9013628960, 8.9062566757])\n",
            "Iter 428; theta =  tensor([6.9023146629, 8.9072198868])\n",
            "Iter 429; theta =  tensor([6.9032573700, 8.9081735611])\n",
            "Iter 430; theta =  tensor([6.9041910172, 8.9091176987])\n",
            "Iter 431; theta =  tensor([6.9051156044, 8.9100513458])\n",
            "Iter 432; theta =  tensor([6.9060316086, 8.9109754562])\n",
            "Iter 433; theta =  tensor([6.9069385529, 8.9118900299])\n",
            "Iter 434; theta =  tensor([6.9078369141, 8.9127950668])\n",
            "Iter 435; theta =  tensor([6.9087266922, 8.9136915207])\n",
            "Iter 436; theta =  tensor([6.9096078873, 8.9145784378])\n",
            "Iter 437; theta =  tensor([6.9104804993, 8.9154558182])\n",
            "Iter 438; theta =  tensor([6.9113445282, 8.9163246155])\n",
            "Iter 439; theta =  tensor([6.9122004509, 8.9171848297])\n",
            "Iter 440; theta =  tensor([6.9130482674, 8.9180355072])\n",
            "Iter 441; theta =  tensor([6.9138875008, 8.9188776016])\n",
            "Iter 442; theta =  tensor([6.9147186279, 8.9197111130])\n",
            "Iter 443; theta =  tensor([6.9155421257, 8.9205360413])\n",
            "Iter 444; theta =  tensor([6.9163575172, 8.9213523865])\n",
            "Iter 445; theta =  tensor([6.9171652794, 8.9221601486])\n",
            "Iter 446; theta =  tensor([6.9179649353, 8.9229602814])\n",
            "Iter 447; theta =  tensor([6.9187569618, 8.9237518311])\n",
            "Iter 448; theta =  tensor([6.9195413589, 8.9245347977])\n",
            "Iter 449; theta =  tensor([6.9203181267, 8.9253101349])\n",
            "Iter 450; theta =  tensor([6.9210877419, 8.9260778427])\n",
            "Iter 451; theta =  tensor([6.9218497276, 8.9268369675])\n",
            "Iter 452; theta =  tensor([6.9226045609, 8.9275884628])\n",
            "Iter 453; theta =  tensor([6.9233517647, 8.9283323288])\n",
            "Iter 454; theta =  tensor([6.9240918159, 8.9290685654])\n",
            "Iter 455; theta =  tensor([6.9248247147, 8.9297971725])\n",
            "Iter 456; theta =  tensor([6.9255509377, 8.9305181503])\n",
            "Iter 457; theta =  tensor([6.9262700081, 8.9312314987])\n",
            "Iter 458; theta =  tensor([6.9269819260, 8.9319381714])\n",
            "Iter 459; theta =  tensor([6.9276871681, 8.9326372147])\n",
            "Iter 460; theta =  tensor([6.9283857346, 8.9333286285])\n",
            "Iter 461; theta =  tensor([6.9290776253, 8.9340133667])\n",
            "Iter 462; theta =  tensor([6.9297628403, 8.9346914291])\n",
            "Iter 463; theta =  tensor([6.9304413795, 8.9353618622])\n",
            "Iter 464; theta =  tensor([6.9311132431, 8.9360256195])\n",
            "Iter 465; theta =  tensor([6.9317784309, 8.9366827011])\n",
            "Iter 466; theta =  tensor([6.9324374199, 8.9373331070])\n",
            "Iter 467; theta =  tensor([6.9330902100, 8.9379768372])\n",
            "Iter 468; theta =  tensor([6.9337363243, 8.9386138916])\n",
            "Iter 469; theta =  tensor([6.9343762398, 8.9392442703])\n",
            "Iter 470; theta =  tensor([6.9350099564, 8.9398679733])\n",
            "Iter 471; theta =  tensor([6.9356379509, 8.9404850006])\n",
            "Iter 472; theta =  tensor([6.9362597466, 8.9410963058])\n",
            "Iter 473; theta =  tensor([6.9368753433, 8.9417009354])\n",
            "Iter 474; theta =  tensor([6.9374852180, 8.9422998428])\n",
            "Iter 475; theta =  tensor([6.9380893707, 8.9428920746])\n",
            "Iter 476; theta =  tensor([6.9386873245, 8.9434785843])\n",
            "Iter 477; theta =  tensor([6.9392795563, 8.9440584183])\n",
            "Iter 478; theta =  tensor([6.9398660660, 8.9446325302])\n",
            "Iter 479; theta =  tensor([6.9404468536, 8.9452009201])\n",
            "Iter 480; theta =  tensor([6.9410223961, 8.9457635880])\n",
            "Iter 481; theta =  tensor([6.9415922165, 8.9463205338])\n",
            "Iter 482; theta =  tensor([6.9421567917, 8.9468717575])\n",
            "Iter 483; theta =  tensor([6.9427156448, 8.9474172592])\n",
            "Iter 484; theta =  tensor([6.9432692528, 8.9479570389])\n",
            "Iter 485; theta =  tensor([6.9438176155, 8.9484910965])\n",
            "Iter 486; theta =  tensor([6.9443607330, 8.9490194321])\n",
            "Iter 487; theta =  tensor([6.9448986053, 8.9495429993])\n",
            "Iter 488; theta =  tensor([6.9454312325, 8.9500608444])\n",
            "Iter 489; theta =  tensor([6.9459586143, 8.9505729675])\n",
            "Iter 490; theta =  tensor([6.9464807510, 8.9510803223])\n",
            "Iter 491; theta =  tensor([6.9469981194, 8.9515819550])\n",
            "Iter 492; theta =  tensor([6.9475102425, 8.9520788193])\n",
            "Iter 493; theta =  tensor([6.9480175972, 8.9525709152])\n",
            "Iter 494; theta =  tensor([6.9485201836, 8.9530572891])\n",
            "Iter 495; theta =  tensor([6.9490175247, 8.9535388947])\n",
            "Iter 496; theta =  tensor([6.9495100975, 8.9540157318])\n",
            "Iter 497; theta =  tensor([6.9499979019, 8.9544878006])\n",
            "Iter 498; theta =  tensor([6.9504814148, 8.9549551010])\n",
            "Iter 499; theta =  tensor([6.9509601593, 8.9554176331])\n",
            "Iter 500; theta =  tensor([6.9514341354, 8.9558753967])\n",
            "Iter 501; theta =  tensor([6.9519038200, 8.9563283920])\n",
            "Iter 502; theta =  tensor([6.9523687363, 8.9567766190])\n",
            "Iter 503; theta =  tensor([6.9528293610, 8.9572200775])\n",
            "Iter 504; theta =  tensor([6.9532852173, 8.9576587677])\n",
            "Iter 505; theta =  tensor([6.9537367821, 8.9580926895])\n",
            "Iter 506; theta =  tensor([6.9541840553, 8.9585227966])\n",
            "Iter 507; theta =  tensor([6.9546270370, 8.9589481354])\n",
            "Iter 508; theta =  tensor([6.9550657272, 8.9593696594])\n",
            "Iter 509; theta =  tensor([6.9555001259, 8.9597864151])\n",
            "Iter 510; theta =  tensor([6.9559302330, 8.9601993561])\n",
            "Iter 511; theta =  tensor([6.9563565254, 8.9606075287])\n",
            "Iter 512; theta =  tensor([6.9567785263, 8.9610118866])\n",
            "Iter 513; theta =  tensor([6.9571962357, 8.9614114761])\n",
            "Iter 514; theta =  tensor([6.9576101303, 8.9618072510])\n",
            "Iter 515; theta =  tensor([6.9580202103, 8.9621992111])\n",
            "Iter 516; theta =  tensor([6.9584259987, 8.9625873566])\n",
            "Iter 517; theta =  tensor([6.9588279724, 8.9629707336])\n",
            "Iter 518; theta =  tensor([6.9592261314, 8.9633502960])\n",
            "Iter 519; theta =  tensor([6.9596204758, 8.9637260437])\n",
            "Iter 520; theta =  tensor([6.9600110054, 8.9640979767])\n",
            "Iter 521; theta =  tensor([6.9603977203, 8.9644660950])\n",
            "Iter 522; theta =  tensor([6.9607806206, 8.9648303986])\n",
            "Iter 523; theta =  tensor([6.9611597061, 8.9651908875])\n",
            "Iter 524; theta =  tensor([6.9615354538, 8.9655475616])\n",
            "Iter 525; theta =  tensor([6.9619073868, 8.9659004211])\n",
            "Iter 526; theta =  tensor([6.9622759819, 8.9662504196])\n",
            "Iter 527; theta =  tensor([6.9626407623, 8.9665966034])\n",
            "Iter 528; theta =  tensor([6.9630022049, 8.9669389725])\n",
            "Iter 529; theta =  tensor([6.9633598328, 8.9672775269])\n",
            "Iter 530; theta =  tensor([6.9637141228, 8.9676132202])\n",
            "Iter 531; theta =  tensor([6.9640650749, 8.9679450989])\n",
            "Iter 532; theta =  tensor([6.9644126892, 8.9682741165])\n",
            "Iter 533; theta =  tensor([6.9647569656, 8.9685993195])\n",
            "Iter 534; theta =  tensor([6.9650979042, 8.9689216614])\n",
            "Iter 535; theta =  tensor([6.9654355049, 8.9692401886])\n",
            "Iter 536; theta =  tensor([6.9657697678, 8.9695558548])\n",
            "Iter 537; theta =  tensor([6.9661006927, 8.9698677063])\n",
            "Iter 538; theta =  tensor([6.9664287567, 8.9701766968])\n",
            "Iter 539; theta =  tensor([6.9667534828, 8.9704828262])\n",
            "Iter 540; theta =  tensor([6.9670753479, 8.9707851410])\n",
            "Iter 541; theta =  tensor([6.9673938751, 8.9710845947])\n",
            "Iter 542; theta =  tensor([6.9677095413, 8.9713811874])\n",
            "Iter 543; theta =  tensor([6.9680218697, 8.9716749191])\n",
            "Iter 544; theta =  tensor([6.9683313370, 8.9719648361])\n",
            "Iter 545; theta =  tensor([6.9686379433, 8.9722518921])\n",
            "Iter 546; theta =  tensor([6.9689412117, 8.9725360870])\n",
            "Iter 547; theta =  tensor([6.9692416191, 8.9728174210])\n",
            "Iter 548; theta =  tensor([6.9695391655, 8.9730958939])\n",
            "Iter 549; theta =  tensor([6.9698338509, 8.9733715057])\n",
            "Iter 550; theta =  tensor([6.9701256752, 8.9736442566])\n",
            "Iter 551; theta =  tensor([6.9704146385, 8.9739141464])\n",
            "Iter 552; theta =  tensor([6.9707007408, 8.9741811752])\n",
            "Iter 553; theta =  tensor([6.9709844589, 8.9744453430])\n",
            "Iter 554; theta =  tensor([6.9712653160, 8.9747076035])\n",
            "Iter 555; theta =  tensor([6.9715433121, 8.9749670029])\n",
            "Iter 556; theta =  tensor([6.9718189240, 8.9752235413])\n",
            "Iter 557; theta =  tensor([6.9720916748, 8.9754772186])\n",
            "Iter 558; theta =  tensor([6.9723615646, 8.9757280350])\n",
            "Iter 559; theta =  tensor([6.9726290703, 8.9759769440])\n",
            "Iter 560; theta =  tensor([6.9728941917, 8.9762229919])\n",
            "Iter 561; theta =  tensor([6.9731564522, 8.9764661789])\n",
            "Iter 562; theta =  tensor([6.9734163284, 8.9767074585])\n",
            "Iter 563; theta =  tensor([6.9736738205, 8.9769458771])\n",
            "Iter 564; theta =  tensor([6.9739284515, 8.9771823883])\n",
            "Iter 565; theta =  tensor([6.9741806984, 8.9774160385])\n",
            "Iter 566; theta =  tensor([6.9744305611, 8.9776477814])\n",
            "Iter 567; theta =  tensor([6.9746780396, 8.9778766632])\n",
            "Iter 568; theta =  tensor([6.9749231339, 8.9781036377])\n",
            "Iter 569; theta =  tensor([6.9751658440, 8.9783277512])\n",
            "Iter 570; theta =  tensor([6.9754061699, 8.9785499573])\n",
            "Iter 571; theta =  tensor([6.9756441116, 8.9787693024])\n",
            "Iter 572; theta =  tensor([6.9758796692, 8.9789867401])\n",
            "Iter 573; theta =  tensor([6.9761133194, 8.9792022705])\n",
            "Iter 574; theta =  tensor([6.9763445854, 8.9794149399])\n",
            "Iter 575; theta =  tensor([6.9765734673, 8.9796257019])\n",
            "Iter 576; theta =  tensor([6.9768004417, 8.9798345566])\n",
            "Iter 577; theta =  tensor([6.9770250320, 8.9800415039])\n",
            "Iter 578; theta =  tensor([6.9772472382, 8.9802455902])\n",
            "Iter 579; theta =  tensor([6.9774675369, 8.9804477692])\n",
            "Iter 580; theta =  tensor([6.9776854515, 8.9806480408])\n",
            "Iter 581; theta =  tensor([6.9779014587, 8.9808464050])\n",
            "Iter 582; theta =  tensor([6.9781155586, 8.9810428619])\n",
            "Iter 583; theta =  tensor([6.9783272743, 8.9812374115])\n",
            "Iter 584; theta =  tensor([6.9785370827, 8.9814291000])\n",
            "Iter 585; theta =  tensor([6.9787449837, 8.9816188812])\n",
            "Iter 586; theta =  tensor([6.9789509773, 8.9818067551])\n",
            "Iter 587; theta =  tensor([6.9791545868, 8.9819927216])\n",
            "Iter 588; theta =  tensor([6.9793562889, 8.9821767807])\n",
            "Iter 589; theta =  tensor([6.9795560837, 8.9823589325])\n",
            "Iter 590; theta =  tensor([6.9797539711, 8.9825391769])\n",
            "Iter 591; theta =  tensor([6.9799499512, 8.9827175140])\n",
            "Iter 592; theta =  tensor([6.9801440239, 8.9828948975])\n",
            "Iter 593; theta =  tensor([6.9803361893, 8.9830703735])\n",
            "Iter 594; theta =  tensor([6.9805264473, 8.9832439423])\n",
            "Iter 595; theta =  tensor([6.9807147980, 8.9834156036])\n",
            "Iter 596; theta =  tensor([6.9809017181, 8.9835853577])\n",
            "Iter 597; theta =  tensor([6.9810867310, 8.9837532043])\n",
            "Iter 598; theta =  tensor([6.9812698364, 8.9839191437])\n",
            "Iter 599; theta =  tensor([6.9814510345, 8.9840841293])\n",
            "Iter 600; theta =  tensor([6.9816308022, 8.9842472076])\n",
            "Iter 601; theta =  tensor([6.9818086624, 8.9844083786])\n",
            "Iter 602; theta =  tensor([6.9819850922, 8.9845676422])\n",
            "Iter 603; theta =  tensor([6.9821596146, 8.9847259521])\n",
            "Iter 604; theta =  tensor([6.9823322296, 8.9848823547])\n",
            "Iter 605; theta =  tensor([6.9825034142, 8.9850368500])\n",
            "Iter 606; theta =  tensor([6.9826726913, 8.9851903915])\n",
            "Iter 607; theta =  tensor([6.9828405380, 8.9853420258])\n",
            "Iter 608; theta =  tensor([6.9830069542, 8.9854917526])\n"
          ]
        }
      ],
      "source": [
        "# Testando com derivada manual. Sua função deve retornar algo perto de 7 e 9\n",
        "theta = gd(derivada_navera, media_erros_quadrados, X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Z6SbuwB7onbt"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([6.9852523804, 8.9826107025], requires_grad=True)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "theta"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BQY5_lJvonbv"
      },
      "source": [
        "12. Altere a função de Gradiente Descendente para funcionar com minibatches. Em outras palavras, não compute o erro usando todos os dados de X. Use um `slice` de tamanho do minibatch. Uma ideia é seguir o pseudocódigo abaixo.\n",
        "\n",
        "```python\n",
        "index = np.arange(len(X))\n",
        "while True:\n",
        "    minib = np.random.choice(index, minibatchsize) # aqui estou usando numpy para selection minibatch elementos\n",
        "    X_batch = X[minib]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "LOyf2F26onbv",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 91 808 428 489 635 941 786 418  88 540 390 336 708 735 179 589 267  43\n",
            " 930 110 887  39 895 229 253 891 763 189 684 461 792 150 152 200 558 504\n",
            " 983 164 140 861 554 195 213 368 461 384 880 564 881 236]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.0000000000,  0.4333291948],\n",
              "        [ 1.0000000000, -0.0738926008],\n",
              "        [ 1.0000000000,  0.2971858084],\n",
              "        [ 1.0000000000,  0.1915854514],\n",
              "        [ 1.0000000000,  0.4669107497],\n",
              "        [ 1.0000000000,  0.2104868442],\n",
              "        [ 1.0000000000,  0.8185428977],\n",
              "        [ 1.0000000000,  0.1994014978],\n",
              "        [ 1.0000000000, -0.7953934073],\n",
              "        [ 1.0000000000,  0.7726532817],\n",
              "        [ 1.0000000000, -1.4111599922],\n",
              "        [ 1.0000000000, -1.0469597578],\n",
              "        [ 1.0000000000, -0.4144256711],\n",
              "        [ 1.0000000000, -0.9461408257],\n",
              "        [ 1.0000000000, -0.4604700804],\n",
              "        [ 1.0000000000,  0.5776293278],\n",
              "        [ 1.0000000000, -1.9389501810],\n",
              "        [ 1.0000000000,  0.8925039172],\n",
              "        [ 1.0000000000,  0.2204968035],\n",
              "        [ 1.0000000000, -1.1230382919],\n",
              "        [ 1.0000000000, -0.0724260211],\n",
              "        [ 1.0000000000,  0.1776871830],\n",
              "        [ 1.0000000000, -1.2966889143],\n",
              "        [ 1.0000000000, -0.8757321835],\n",
              "        [ 1.0000000000,  0.9388884902],\n",
              "        [ 1.0000000000,  0.0676770434],\n",
              "        [ 1.0000000000,  0.0338086188],\n",
              "        [ 1.0000000000,  0.2446376681],\n",
              "        [ 1.0000000000, -0.9436286092],\n",
              "        [ 1.0000000000, -1.7854238749],\n",
              "        [ 1.0000000000,  1.3745963573],\n",
              "        [ 1.0000000000,  1.7461103201],\n",
              "        [ 1.0000000000, -1.0167622566],\n",
              "        [ 1.0000000000, -0.7126050591],\n",
              "        [ 1.0000000000, -0.3410305679],\n",
              "        [ 1.0000000000, -0.2732818425],\n",
              "        [ 1.0000000000,  0.6201128960],\n",
              "        [ 1.0000000000,  2.1669554710],\n",
              "        [ 1.0000000000, -1.5448671579],\n",
              "        [ 1.0000000000,  1.1393982172],\n",
              "        [ 1.0000000000, -1.1358373165],\n",
              "        [ 1.0000000000, -0.6534170508],\n",
              "        [ 1.0000000000,  0.3129270375],\n",
              "        [ 1.0000000000,  0.5017385483],\n",
              "        [ 1.0000000000, -1.7854238749],\n",
              "        [ 1.0000000000, -1.8499407768],\n",
              "        [ 1.0000000000, -0.8948337436],\n",
              "        [ 1.0000000000,  0.8306335211],\n",
              "        [ 1.0000000000,  0.4815075696],\n",
              "        [ 1.0000000000, -0.8421145082]])"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Exemplo abaixo\n",
        "index = np.arange(len(X))\n",
        "mb = np.random.choice(index, 50) # Escolhe 50 índices aleatórios\n",
        "print(mb)\n",
        "X[mb]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "WbssWxyCWBNY"
      },
      "outputs": [],
      "source": [
        "def minibatch_gd(d_fun, loss_fun, X, y, lambda_=0.01, tol=0.00001,\n",
        "                 max_iter=10000, batch_size=10):\n",
        "    '''\n",
        "    Executa Gradiente Descendente. Aqui:\n",
        "    \n",
        "    Parâmetros\n",
        "    ----------\n",
        "    d_fun : é uma função de derivadas\n",
        "    loss_fun : é uma função de perda\n",
        "    X : é um vetor de fatores explanatórios.\n",
        "        Copie seu código de intercepto da primeira aula.\n",
        "        para adicionar o intercepto em X.\n",
        "    y : é a resposta\n",
        "    lambda : é a taxa de aprendizad\n",
        "    tol : é a tolerância, define quando o algoritmo vai parar.\n",
        "    max_ter : é a segunda forma de parada, mesmo sem convergir\n",
        "              paramos depois de max_iter iterações.\n",
        "    batch_size : tamanho do batch\n",
        "    '''\n",
        "    theta = torch.randn(X.shape[1]).double()\n",
        "    theta.requires_grad_(True)\n",
        "    print('Iter {}; theta = '.format(0), theta)\n",
        "    old_err_sq = np.inf\n",
        "    i = 0\n",
        "    \n",
        "    index = np.arange(len(X))\n",
        "    while True:\n",
        "        theta.requires_grad_(True)\n",
        "        # pega o mini batch\n",
        "        mb = np.random.choice(index, batch_size)\n",
        "        Xmb = X[mb]\n",
        "        ymb = y[mb]\n",
        "        \n",
        "        # Computar as derivadas\n",
        "        grad = d_fun(Xmb, theta, ymb)\n",
        "        # Atualizar\n",
        "        with torch.no_grad():\n",
        "            theta_novo = theta - lambda_ * grad\n",
        "        \n",
        "        # Parar quando o erro convergir\n",
        "        err_sq = loss_fun(Xmb, theta, ymb)\n",
        "        if torch.abs(old_err_sq - err_sq) <= tol:\n",
        "            break\n",
        "        \n",
        "        # Atualizar parâmetros e erro\n",
        "        theta = theta_novo\n",
        "        old_err_sq = err_sq\n",
        "        \n",
        "        # Informação de debug\n",
        "        print('Iter {}; theta = '.format(i+1), theta)\n",
        "        i += 1\n",
        "        if i == max_iter:\n",
        "            break\n",
        "    return theta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "Q5gzuUW4onb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter 0; theta =  tensor([-1.3188720942,  2.3184990883], dtype=torch.float64, requires_grad=True)\n",
            "Iter 1; theta =  tensor([-1.1756541491,  2.4030607605], dtype=torch.float64)\n",
            "Iter 2; theta =  tensor([-1.0063174486,  2.4806043005], dtype=torch.float64)\n",
            "Iter 3; theta =  tensor([-0.9129659319,  2.5527530479], dtype=torch.float64)\n",
            "Iter 4; theta =  tensor([-0.7943879175,  2.6801480675], dtype=torch.float64)\n",
            "Iter 5; theta =  tensor([-0.5944870996,  2.9293785286], dtype=torch.float64)\n",
            "Iter 6; theta =  tensor([-0.4278093576,  3.0842931843], dtype=torch.float64)\n",
            "Iter 7; theta =  tensor([-0.2974652243,  3.1809904766], dtype=torch.float64)\n",
            "Iter 8; theta =  tensor([-0.1377519560,  3.2853139877], dtype=torch.float64)\n",
            "Iter 9; theta =  tensor([-0.0054841089,  3.4161867714], dtype=torch.float64)\n",
            "Iter 10; theta =  tensor([0.2224461508, 3.6997494888], dtype=torch.float64)\n",
            "Iter 11; theta =  tensor([0.3237919569, 3.8276137543], dtype=torch.float64)\n",
            "Iter 12; theta =  tensor([0.4538153505, 3.9570262527], dtype=torch.float64)\n",
            "Iter 13; theta =  tensor([0.6170461893, 4.1176368713], dtype=torch.float64)\n",
            "Iter 14; theta =  tensor([0.7339593363, 4.2153925896], dtype=torch.float64)\n",
            "Iter 15; theta =  tensor([0.9026479769, 4.3360717201], dtype=torch.float64)\n",
            "Iter 16; theta =  tensor([1.0631204271, 4.4861308479], dtype=torch.float64)\n",
            "Iter 17; theta =  tensor([1.2039475489, 4.6521649361], dtype=torch.float64)\n",
            "Iter 18; theta =  tensor([1.3206321764, 4.7335720348], dtype=torch.float64)\n",
            "Iter 19; theta =  tensor([1.4558336115, 4.8299270248], dtype=torch.float64)\n",
            "Iter 20; theta =  tensor([1.5609584284, 4.9004331779], dtype=torch.float64)\n",
            "Iter 21; theta =  tensor([1.6788122225, 5.0363649845], dtype=torch.float64)\n",
            "Iter 22; theta =  tensor([1.7605040216, 5.0642940307], dtype=torch.float64)\n",
            "Iter 23; theta =  tensor([1.8593511152, 5.1554556346], dtype=torch.float64)\n",
            "Iter 24; theta =  tensor([2.0056692076, 5.2785921264], dtype=torch.float64)\n",
            "Iter 25; theta =  tensor([2.1038650942, 5.3790086055], dtype=torch.float64)\n",
            "Iter 26; theta =  tensor([2.1678207684, 5.3986445940], dtype=torch.float64)\n",
            "Iter 27; theta =  tensor([2.2576267624, 5.4570090711], dtype=torch.float64)\n",
            "Iter 28; theta =  tensor([2.3696358681, 5.5105867422], dtype=torch.float64)\n",
            "Iter 29; theta =  tensor([2.4503377914, 5.5411023724], dtype=torch.float64)\n",
            "Iter 30; theta =  tensor([2.5583673668, 5.6238437283], dtype=torch.float64)\n",
            "Iter 31; theta =  tensor([2.6431013203, 5.7424414265], dtype=torch.float64)\n",
            "Iter 32; theta =  tensor([2.7562360668, 5.8198289931], dtype=torch.float64)\n",
            "Iter 33; theta =  tensor([2.8562988186, 5.8886739504], dtype=torch.float64)\n",
            "Iter 34; theta =  tensor([2.9675441360, 5.9830787718], dtype=torch.float64)\n",
            "Iter 35; theta =  tensor([3.0529582977, 6.0241563761], dtype=torch.float64)\n",
            "Iter 36; theta =  tensor([3.1432633781, 6.0755125439], dtype=torch.float64)\n",
            "Iter 37; theta =  tensor([3.2459745407, 6.2026449597], dtype=torch.float64)\n",
            "Iter 38; theta =  tensor([3.3454048157, 6.3089251339], dtype=torch.float64)\n",
            "Iter 39; theta =  tensor([3.3905266666, 6.3157944739], dtype=torch.float64)\n",
            "Iter 40; theta =  tensor([3.4587140179, 6.3435849917], dtype=torch.float64)\n",
            "Iter 41; theta =  tensor([3.5304561234, 6.3595848358], dtype=torch.float64)\n",
            "Iter 42; theta =  tensor([3.5752437401, 6.3806512725], dtype=torch.float64)\n",
            "Iter 43; theta =  tensor([3.6472223759, 6.4461433780], dtype=torch.float64)\n",
            "Iter 44; theta =  tensor([3.7030474758, 6.4923228633], dtype=torch.float64)\n",
            "Iter 45; theta =  tensor([3.7834842968, 6.5643108690], dtype=torch.float64)\n",
            "Iter 46; theta =  tensor([3.8147733903, 6.5828979504], dtype=torch.float64)\n",
            "Iter 47; theta =  tensor([3.8885921025, 6.6248574555], dtype=torch.float64)\n",
            "Iter 48; theta =  tensor([3.9484335446, 6.6731450188], dtype=torch.float64)\n",
            "Iter 49; theta =  tensor([3.9837054610, 6.6842388332], dtype=torch.float64)\n",
            "Iter 50; theta =  tensor([4.0764862704, 6.8019269836], dtype=torch.float64)\n",
            "Iter 51; theta =  tensor([4.1281148648, 6.8135049856], dtype=torch.float64)\n",
            "Iter 52; theta =  tensor([4.2106333852, 6.8795473659], dtype=torch.float64)\n",
            "Iter 53; theta =  tensor([4.2614880872, 6.9344572532], dtype=torch.float64)\n",
            "Iter 54; theta =  tensor([4.3073052812, 6.9482630491], dtype=torch.float64)\n",
            "Iter 55; theta =  tensor([4.3787587094, 6.9970063591], dtype=torch.float64)\n",
            "Iter 56; theta =  tensor([4.4187383819, 7.0343667364], dtype=torch.float64)\n",
            "Iter 57; theta =  tensor([4.4495887303, 7.0713593674], dtype=torch.float64)\n",
            "Iter 58; theta =  tensor([4.4851007438, 7.0775415957], dtype=torch.float64)\n",
            "Iter 59; theta =  tensor([4.5381893992, 7.0986897099], dtype=torch.float64)\n",
            "Iter 60; theta =  tensor([4.5941774631, 7.1441381276], dtype=torch.float64)\n",
            "Iter 61; theta =  tensor([4.6253349757, 7.1389393461], dtype=torch.float64)\n",
            "Iter 62; theta =  tensor([4.6851433730, 7.1869691932], dtype=torch.float64)\n",
            "Iter 63; theta =  tensor([4.7233344769, 7.2153163898], dtype=torch.float64)\n",
            "Iter 64; theta =  tensor([4.7683819604, 7.2427768981], dtype=torch.float64)\n",
            "Iter 65; theta =  tensor([4.8012405658, 7.2607467961], dtype=torch.float64)\n",
            "Iter 66; theta =  tensor([4.8477601171, 7.2802005053], dtype=torch.float64)\n",
            "Iter 67; theta =  tensor([4.8814470148, 7.2917709255], dtype=torch.float64)\n",
            "Iter 68; theta =  tensor([4.9166820526, 7.3090363348], dtype=torch.float64)\n",
            "Iter 69; theta =  tensor([4.9416288328, 7.3257061517], dtype=torch.float64)\n",
            "Iter 70; theta =  tensor([4.9969489717, 7.4207202470], dtype=torch.float64)\n",
            "Iter 71; theta =  tensor([5.0180095673, 7.4211380515], dtype=torch.float64)\n",
            "Iter 72; theta =  tensor([5.0700773811, 7.4937108646], dtype=torch.float64)\n",
            "Iter 73; theta =  tensor([5.1080989218, 7.5196976624], dtype=torch.float64)\n",
            "Iter 74; theta =  tensor([5.1530288124, 7.5423360715], dtype=torch.float64)\n",
            "Iter 75; theta =  tensor([5.2068148804, 7.5779663930], dtype=torch.float64)\n",
            "Iter 76; theta =  tensor([5.2341099072, 7.5954769740], dtype=torch.float64)\n",
            "Iter 77; theta =  tensor([5.2626598454, 7.6014477906], dtype=torch.float64)\n",
            "Iter 78; theta =  tensor([5.2867544603, 7.6074979249], dtype=torch.float64)\n",
            "Iter 79; theta =  tensor([5.3284649134, 7.6520599262], dtype=torch.float64)\n",
            "Iter 80; theta =  tensor([5.3637625790, 7.6744923798], dtype=torch.float64)\n",
            "Iter 81; theta =  tensor([5.4026340556, 7.6940369049], dtype=torch.float64)\n",
            "Iter 82; theta =  tensor([5.4314828205, 7.7065622810], dtype=torch.float64)\n",
            "Iter 83; theta =  tensor([5.4772410011, 7.7475829319], dtype=torch.float64)\n",
            "Iter 84; theta =  tensor([5.5075380373, 7.7663790552], dtype=torch.float64)\n",
            "Iter 85; theta =  tensor([5.5343133283, 7.7714973620], dtype=torch.float64)\n",
            "Iter 86; theta =  tensor([5.5708595586, 7.7906173710], dtype=torch.float64)\n",
            "Iter 87; theta =  tensor([5.5990917134, 7.7990449134], dtype=torch.float64)\n",
            "Iter 88; theta =  tensor([5.6297262311, 7.8222105113], dtype=torch.float64)\n",
            "Iter 89; theta =  tensor([5.6454471707, 7.8466115943], dtype=torch.float64)\n",
            "Iter 90; theta =  tensor([5.6676886225, 7.8639817492], dtype=torch.float64)\n",
            "Iter 91; theta =  tensor([5.6748905814, 7.8708409790], dtype=torch.float64)\n",
            "Iter 92; theta =  tensor([5.7045841277, 7.8978084425], dtype=torch.float64)\n",
            "Iter 93; theta =  tensor([5.7288396466, 7.9178167275], dtype=torch.float64)\n",
            "Iter 94; theta =  tensor([5.7517551982, 7.9301657895], dtype=torch.float64)\n",
            "Iter 95; theta =  tensor([5.7703435290, 7.9397683326], dtype=torch.float64)\n",
            "Iter 96; theta =  tensor([5.7870809400, 7.9491510228], dtype=torch.float64)\n",
            "Iter 97; theta =  tensor([5.8089933956, 7.9744062356], dtype=torch.float64)\n",
            "Iter 98; theta =  tensor([5.8303804243, 7.9840240333], dtype=torch.float64)\n",
            "Iter 99; theta =  tensor([5.8589518917, 8.0063313816], dtype=torch.float64)\n",
            "Iter 100; theta =  tensor([5.8795104563, 8.0298003910], dtype=torch.float64)\n",
            "Iter 101; theta =  tensor([5.9144310009, 8.0601762436], dtype=torch.float64)\n",
            "Iter 102; theta =  tensor([5.9448294985, 8.0891603372], dtype=torch.float64)\n",
            "Iter 103; theta =  tensor([5.9677628648, 8.1093832967], dtype=torch.float64)\n",
            "Iter 104; theta =  tensor([5.9788551795, 8.1137912566], dtype=torch.float64)\n",
            "Iter 105; theta =  tensor([6.0044633996, 8.1455819613], dtype=torch.float64)\n",
            "Iter 106; theta =  tensor([6.0304264724, 8.1773629696], dtype=torch.float64)\n",
            "Iter 107; theta =  tensor([6.0506546390, 8.1874961812], dtype=torch.float64)\n",
            "Iter 108; theta =  tensor([6.0711332262, 8.1980211944], dtype=torch.float64)\n",
            "Iter 109; theta =  tensor([6.0868642247, 8.2154139370], dtype=torch.float64)\n",
            "Iter 110; theta =  tensor([6.1037778115, 8.2331350703], dtype=torch.float64)\n",
            "Iter 111; theta =  tensor([6.1273682284, 8.2561067647], dtype=torch.float64)\n",
            "Iter 112; theta =  tensor([6.1508792377, 8.2705906589], dtype=torch.float64)\n",
            "Iter 113; theta =  tensor([6.1683549976, 8.2896226723], dtype=torch.float64)\n",
            "Iter 114; theta =  tensor([6.1817563891, 8.2997679526], dtype=torch.float64)\n",
            "Iter 115; theta =  tensor([6.1934539831, 8.3013315458], dtype=torch.float64)\n",
            "Iter 116; theta =  tensor([6.2147276843, 8.3172857279], dtype=torch.float64)\n",
            "Iter 117; theta =  tensor([6.2316482890, 8.3285768325], dtype=torch.float64)\n",
            "Iter 118; theta =  tensor([6.2431017339, 8.3403483421], dtype=torch.float64)\n",
            "Iter 119; theta =  tensor([6.2539230764, 8.3466087360], dtype=torch.float64)\n",
            "Iter 120; theta =  tensor([6.2696890211, 8.3566685385], dtype=torch.float64)\n",
            "Iter 121; theta =  tensor([6.2828866982, 8.3691249675], dtype=torch.float64)\n",
            "Iter 122; theta =  tensor([6.3005790639, 8.3803488214], dtype=torch.float64)\n",
            "Iter 123; theta =  tensor([6.3108516169, 8.3840880508], dtype=torch.float64)\n",
            "Iter 124; theta =  tensor([6.3264934731, 8.3960913164], dtype=torch.float64)\n",
            "Iter 125; theta =  tensor([6.3443763161, 8.4112481064], dtype=torch.float64)\n",
            "Iter 126; theta =  tensor([6.3544752133, 8.4196480615], dtype=torch.float64)\n",
            "Iter 127; theta =  tensor([6.3666034603, 8.4360757119], dtype=torch.float64)\n",
            "Iter 128; theta =  tensor([6.3764356530, 8.4425377227], dtype=torch.float64)\n",
            "Iter 129; theta =  tensor([6.3900713217, 8.4538499738], dtype=torch.float64)\n",
            "Iter 130; theta =  tensor([6.3967041528, 8.4568121783], dtype=torch.float64)\n",
            "Iter 131; theta =  tensor([6.4008574027, 8.4607383931], dtype=torch.float64)\n",
            "Iter 132; theta =  tensor([6.4136197060, 8.4694250245], dtype=torch.float64)\n",
            "Iter 133; theta =  tensor([6.4210378927, 8.4782909865], dtype=torch.float64)\n",
            "Iter 134; theta =  tensor([6.4325784200, 8.4859522993], dtype=torch.float64)\n",
            "Iter 135; theta =  tensor([6.4437176722, 8.4960036666], dtype=torch.float64)\n",
            "Iter 136; theta =  tensor([6.4572595018, 8.5099921364], dtype=torch.float64)\n",
            "Iter 137; theta =  tensor([6.4796330088, 8.5510942406], dtype=torch.float64)\n",
            "Iter 138; theta =  tensor([6.4887899619, 8.5559031237], dtype=torch.float64)\n",
            "Iter 139; theta =  tensor([6.4985299283, 8.5601685048], dtype=torch.float64)\n",
            "Iter 140; theta =  tensor([6.5090823394, 8.5675231827], dtype=torch.float64)\n",
            "Iter 141; theta =  tensor([6.5214712268, 8.5771293832], dtype=torch.float64)\n",
            "Iter 142; theta =  tensor([6.5338506371, 8.5905308080], dtype=torch.float64)\n",
            "Iter 143; theta =  tensor([6.5413608783, 8.5986718179], dtype=torch.float64)\n",
            "Iter 144; theta =  tensor([6.5485440063, 8.6046129645], dtype=torch.float64)\n",
            "Iter 145; theta =  tensor([6.5607870829, 8.6114412630], dtype=torch.float64)\n",
            "Iter 146; theta =  tensor([6.5684510130, 8.6174261678], dtype=torch.float64)\n",
            "Iter 147; theta =  tensor([6.5793468934, 8.6314466751], dtype=torch.float64)\n",
            "Iter 148; theta =  tensor([6.5864796251, 8.6352906210], dtype=torch.float64)\n",
            "Iter 149; theta =  tensor([6.5969777638, 8.6439541794], dtype=torch.float64)\n",
            "Iter 150; theta =  tensor([6.6058627605, 8.6553548480], dtype=torch.float64)\n",
            "Iter 151; theta =  tensor([6.6155176091, 8.6692133594], dtype=torch.float64)\n",
            "Iter 152; theta =  tensor([6.6239390838, 8.6785207821], dtype=torch.float64)\n",
            "Iter 153; theta =  tensor([6.6321170861, 8.6816659973], dtype=torch.float64)\n",
            "Iter 154; theta =  tensor([6.6376805830, 8.6849929205], dtype=torch.float64)\n",
            "Iter 155; theta =  tensor([6.6461764157, 8.6943885420], dtype=torch.float64)\n",
            "Iter 156; theta =  tensor([6.6530784714, 8.6975868458], dtype=torch.float64)\n",
            "Iter 157; theta =  tensor([6.6571202615, 8.7009534449], dtype=torch.float64)\n",
            "Iter 158; theta =  tensor([6.6654071870, 8.7110613079], dtype=torch.float64)\n",
            "Iter 159; theta =  tensor([6.6745140043, 8.7188058729], dtype=torch.float64)\n",
            "Iter 160; theta =  tensor([6.6825441793, 8.7297118253], dtype=torch.float64)\n",
            "Iter 161; theta =  tensor([6.6891216686, 8.7318855888], dtype=torch.float64)\n",
            "Iter 162; theta =  tensor([6.6960712615, 8.7362594629], dtype=torch.float64)\n",
            "Iter 163; theta =  tensor([6.7052996871, 8.7455846400], dtype=torch.float64)\n",
            "Iter 164; theta =  tensor([6.7076711719, 8.7482841576], dtype=torch.float64)\n",
            "Iter 165; theta =  tensor([6.7141347699, 8.7507832272], dtype=torch.float64)\n",
            "Iter 166; theta =  tensor([6.7215260909, 8.7547369830], dtype=torch.float64)\n",
            "Iter 167; theta =  tensor([6.7256764017, 8.7570951144], dtype=torch.float64)\n",
            "Iter 168; theta =  tensor([6.7296046613, 8.7572952591], dtype=torch.float64)\n",
            "Iter 169; theta =  tensor([6.7366476826, 8.7640629421], dtype=torch.float64)\n",
            "Iter 170; theta =  tensor([6.7437025623, 8.7727169000], dtype=torch.float64)\n",
            "Iter 171; theta =  tensor([6.7473328967, 8.7747808027], dtype=torch.float64)\n",
            "Iter 172; theta =  tensor([6.7540040906, 8.7803526724], dtype=torch.float64)\n",
            "Iter 173; theta =  tensor([6.7583600189, 8.7815582730], dtype=torch.float64)\n",
            "Iter 174; theta =  tensor([6.7658951701, 8.7895008494], dtype=torch.float64)\n",
            "Iter 175; theta =  tensor([6.7705392568, 8.7916689392], dtype=torch.float64)\n",
            "Iter 176; theta =  tensor([6.7747768383, 8.7982201435], dtype=torch.float64)\n",
            "Iter 177; theta =  tensor([6.7804049133, 8.8041809876], dtype=torch.float64)\n",
            "Iter 178; theta =  tensor([6.7851284669, 8.8094929572], dtype=torch.float64)\n",
            "Iter 179; theta =  tensor([6.7879236402, 8.8122676490], dtype=torch.float64)\n",
            "Iter 180; theta =  tensor([6.7921521224, 8.8164876817], dtype=torch.float64)\n",
            "Iter 181; theta =  tensor([6.7957060291, 8.8182007738], dtype=torch.float64)\n",
            "Iter 182; theta =  tensor([6.8004705305, 8.8227782451], dtype=torch.float64)\n",
            "Iter 183; theta =  tensor([6.8034034415, 8.8265462928], dtype=torch.float64)\n",
            "Iter 184; theta =  tensor([6.8076046278, 8.8294922100], dtype=torch.float64)\n",
            "Iter 185; theta =  tensor([6.8123778494, 8.8324089651], dtype=torch.float64)\n",
            "Iter 186; theta =  tensor([6.8157524116, 8.8336815271], dtype=torch.float64)\n",
            "Iter 187; theta =  tensor([6.8211130418, 8.8388206628], dtype=torch.float64)\n",
            "Iter 188; theta =  tensor([6.8246684177, 8.8415600357], dtype=torch.float64)\n",
            "Iter 189; theta =  tensor([6.8275519954, 8.8424517178], dtype=torch.float64)\n",
            "Iter 190; theta =  tensor([6.8326364355, 8.8469365483], dtype=torch.float64)\n",
            "Iter 191; theta =  tensor([6.8370475434, 8.8514592111], dtype=torch.float64)\n",
            "Iter 192; theta =  tensor([6.8431328319, 8.8584407919], dtype=torch.float64)\n",
            "Iter 193; theta =  tensor([6.8451400678, 8.8591826412], dtype=torch.float64)\n",
            "Iter 194; theta =  tensor([6.8476976167, 8.8595138294], dtype=torch.float64)\n",
            "Iter 195; theta =  tensor([6.8510265847, 8.8624754426], dtype=torch.float64)\n",
            "Iter 196; theta =  tensor([6.8550365122, 8.8655413181], dtype=torch.float64)\n",
            "Iter 197; theta =  tensor([6.8573756684, 8.8661967624], dtype=torch.float64)\n",
            "Iter 198; theta =  tensor([6.8599612881, 8.8676017768], dtype=torch.float64)\n",
            "Iter 199; theta =  tensor([6.8632623650, 8.8707312984], dtype=torch.float64)\n",
            "Iter 200; theta =  tensor([6.8666794439, 8.8744451726], dtype=torch.float64)\n",
            "Iter 201; theta =  tensor([6.8700324918, 8.8771088368], dtype=torch.float64)\n",
            "Iter 202; theta =  tensor([6.8734396411, 8.8804980994], dtype=torch.float64)\n",
            "Iter 203; theta =  tensor([6.8767528756, 8.8863855029], dtype=torch.float64)\n",
            "Iter 204; theta =  tensor([6.8800978558, 8.8900637758], dtype=torch.float64)\n",
            "Iter 205; theta =  tensor([6.8822589496, 8.8910846341], dtype=torch.float64)\n",
            "Iter 206; theta =  tensor([6.8842500079, 8.8926043518], dtype=torch.float64)\n",
            "Iter 207; theta =  tensor([6.8871550620, 8.8952800499], dtype=torch.float64)\n",
            "Iter 208; theta =  tensor([6.8883223465, 8.8975198381], dtype=torch.float64)\n",
            "Iter 209; theta =  tensor([6.8910191101, 8.8990200100], dtype=torch.float64)\n",
            "Iter 210; theta =  tensor([6.8931101277, 8.9005084788], dtype=torch.float64)\n",
            "Iter 211; theta =  tensor([6.8952857727, 8.9023550472], dtype=torch.float64)\n",
            "Iter 212; theta =  tensor([6.8966941693, 8.9038961119], dtype=torch.float64)\n",
            "Iter 213; theta =  tensor([6.8990022883, 8.9055186402], dtype=torch.float64)\n",
            "Iter 214; theta =  tensor([6.9011086512, 8.9065145957], dtype=torch.float64)\n",
            "Iter 215; theta =  tensor([6.9036009626, 8.9077271074], dtype=torch.float64)\n",
            "Iter 216; theta =  tensor([6.9057826091, 8.9106679690], dtype=torch.float64)\n",
            "Iter 217; theta =  tensor([6.9087329946, 8.9141631657], dtype=torch.float64)\n",
            "Iter 218; theta =  tensor([6.9114024864, 8.9165113881], dtype=torch.float64)\n",
            "Iter 219; theta =  tensor([6.9137537123, 8.9179821351], dtype=torch.float64)\n",
            "Iter 220; theta =  tensor([6.9149634846, 8.9193124448], dtype=torch.float64)\n",
            "Iter 221; theta =  tensor([6.9164948542, 8.9196023191], dtype=torch.float64)\n",
            "Iter 222; theta =  tensor([6.9181617258, 8.9204841851], dtype=torch.float64)\n",
            "Iter 223; theta =  tensor([6.9190287789, 8.9207468786], dtype=torch.float64)\n",
            "Iter 224; theta =  tensor([6.9205755032, 8.9227467145], dtype=torch.float64)\n",
            "Iter 225; theta =  tensor([6.9221305235, 8.9244983402], dtype=torch.float64)\n",
            "Iter 226; theta =  tensor([6.9242347888, 8.9257519090], dtype=torch.float64)\n",
            "Iter 227; theta =  tensor([6.9251103858, 8.9279660461], dtype=torch.float64)\n",
            "Iter 228; theta =  tensor([6.9273185339, 8.9296431518], dtype=torch.float64)\n",
            "Iter 229; theta =  tensor([6.9287911806, 8.9302277027], dtype=torch.float64)\n",
            "Iter 230; theta =  tensor([6.9305906133, 8.9324546591], dtype=torch.float64)\n",
            "Iter 231; theta =  tensor([6.9317492055, 8.9325935833], dtype=torch.float64)\n",
            "Iter 232; theta =  tensor([6.9332001876, 8.9344847225], dtype=torch.float64)\n",
            "Iter 233; theta =  tensor([6.9350476017, 8.9357763319], dtype=torch.float64)\n",
            "Iter 234; theta =  tensor([6.9361934910, 8.9366110385], dtype=torch.float64)\n",
            "Iter 235; theta =  tensor([6.9378758975, 8.9386525163], dtype=torch.float64)\n",
            "Iter 236; theta =  tensor([6.9386275169, 8.9402862688], dtype=torch.float64)\n",
            "Iter 237; theta =  tensor([6.9396945035, 8.9410732682], dtype=torch.float64)\n",
            "Iter 238; theta =  tensor([6.9407602812, 8.9423195923], dtype=torch.float64)\n",
            "Iter 239; theta =  tensor([6.9413232047, 8.9426373619], dtype=torch.float64)\n",
            "Iter 240; theta =  tensor([6.9426298052, 8.9437975398], dtype=torch.float64)\n",
            "Iter 241; theta =  tensor([6.9442491663, 8.9455181841], dtype=torch.float64)\n",
            "Iter 242; theta =  tensor([6.9450469254, 8.9467796556], dtype=torch.float64)\n",
            "Iter 243; theta =  tensor([6.9456807402, 8.9471318105], dtype=torch.float64)\n",
            "Iter 244; theta =  tensor([6.9470875386, 8.9484002963], dtype=torch.float64)\n",
            "Iter 245; theta =  tensor([6.9489168938, 8.9507197000], dtype=torch.float64)\n",
            "Iter 246; theta =  tensor([6.9495638764, 8.9512249533], dtype=torch.float64)\n",
            "Iter 247; theta =  tensor([6.9507820838, 8.9519289858], dtype=torch.float64)\n",
            "Iter 248; theta =  tensor([6.9524212087, 8.9538103967], dtype=torch.float64)\n",
            "Iter 249; theta =  tensor([6.9534054607, 8.9543697279], dtype=torch.float64)\n",
            "Iter 250; theta =  tensor([6.9549087293, 8.9561768382], dtype=torch.float64)\n",
            "Iter 251; theta =  tensor([6.9556485298, 8.9566385267], dtype=torch.float64)\n",
            "Iter 252; theta =  tensor([6.9570556420, 8.9580399073], dtype=torch.float64)\n",
            "Iter 253; theta =  tensor([6.9583993214, 8.9598517635], dtype=torch.float64)\n",
            "Iter 254; theta =  tensor([6.9590481928, 8.9605681483], dtype=torch.float64)\n",
            "Iter 255; theta =  tensor([6.9598823012, 8.9608809489], dtype=torch.float64)\n",
            "Iter 256; theta =  tensor([6.9605940360, 8.9617723234], dtype=torch.float64)\n",
            "Iter 257; theta =  tensor([6.9613247203, 8.9623024046], dtype=torch.float64)\n",
            "Iter 258; theta =  tensor([6.9619767579, 8.9629200102], dtype=torch.float64)\n",
            "Iter 259; theta =  tensor([6.9627550072, 8.9633429949], dtype=torch.float64)\n",
            "Iter 260; theta =  tensor([6.9637095437, 8.9640644324], dtype=torch.float64)\n",
            "Iter 261; theta =  tensor([6.9642637434, 8.9643475222], dtype=torch.float64)\n",
            "Iter 262; theta =  tensor([6.9651365147, 8.9648994443], dtype=torch.float64)\n",
            "Iter 263; theta =  tensor([6.9656674824, 8.9652077204], dtype=torch.float64)\n",
            "Iter 264; theta =  tensor([6.9663434487, 8.9659459457], dtype=torch.float64)\n",
            "Iter 265; theta =  tensor([6.9672696191, 8.9668053708], dtype=torch.float64)\n",
            "Iter 266; theta =  tensor([6.9675894218, 8.9669704953], dtype=torch.float64)\n",
            "Iter 267; theta =  tensor([6.9683901292, 8.9675579653], dtype=torch.float64)\n",
            "Iter 268; theta =  tensor([6.9692186204, 8.9684811520], dtype=torch.float64)\n",
            "Iter 269; theta =  tensor([6.9698483067, 8.9689708663], dtype=torch.float64)\n",
            "Iter 270; theta =  tensor([6.9701610066, 8.9695083838], dtype=torch.float64)\n",
            "Iter 271; theta =  tensor([6.9706245057, 8.9697928157], dtype=torch.float64)\n",
            "Iter 272; theta =  tensor([6.9711705052, 8.9701216846], dtype=torch.float64)\n",
            "Iter 273; theta =  tensor([6.9716884772, 8.9706117643], dtype=torch.float64)\n",
            "Iter 274; theta =  tensor([6.9724093501, 8.9710255743], dtype=torch.float64)\n",
            "Iter 275; theta =  tensor([6.9731597964, 8.9717254709], dtype=torch.float64)\n",
            "Iter 276; theta =  tensor([6.9736690070, 8.9723978472], dtype=torch.float64)\n",
            "Iter 277; theta =  tensor([6.9738971164, 8.9726476212], dtype=torch.float64)\n",
            "Iter 278; theta =  tensor([6.9746879661, 8.9738188187], dtype=torch.float64)\n",
            "Iter 279; theta =  tensor([6.9751860072, 8.9746434723], dtype=torch.float64)\n",
            "Iter 280; theta =  tensor([6.9760687625, 8.9758772592], dtype=torch.float64)\n",
            "Iter 281; theta =  tensor([6.9766850936, 8.9764373554], dtype=torch.float64)\n",
            "Iter 282; theta =  tensor([6.9774207093, 8.9773680632], dtype=torch.float64)\n",
            "Iter 283; theta =  tensor([6.9778697888, 8.9779037787], dtype=torch.float64)\n",
            "Iter 284; theta =  tensor([6.9780596520, 8.9782786549], dtype=torch.float64)\n",
            "Iter 285; theta =  tensor([6.9783250205, 8.9788005478], dtype=torch.float64)\n",
            "Iter 286; theta =  tensor([6.9786681392, 8.9791832687], dtype=torch.float64)\n",
            "Iter 287; theta =  tensor([6.9790466621, 8.9794137543], dtype=torch.float64)\n",
            "Iter 288; theta =  tensor([6.9794438808, 8.9795761758], dtype=torch.float64)\n",
            "Iter 289; theta =  tensor([6.9799387343, 8.9801238997], dtype=torch.float64)\n",
            "Iter 290; theta =  tensor([6.9804914687, 8.9804255102], dtype=torch.float64)\n",
            "Iter 291; theta =  tensor([6.9807908032, 8.9807261634], dtype=torch.float64)\n",
            "Iter 292; theta =  tensor([6.9809938948, 8.9810388245], dtype=torch.float64)\n",
            "Iter 293; theta =  tensor([6.9812578356, 8.9814361383], dtype=torch.float64)\n",
            "Iter 294; theta =  tensor([6.9815776751, 8.9816489137], dtype=torch.float64)\n",
            "Iter 295; theta =  tensor([6.9820838358, 8.9819901831], dtype=torch.float64)\n",
            "Iter 296; theta =  tensor([6.9824266179, 8.9821298573], dtype=torch.float64)\n",
            "Iter 297; theta =  tensor([6.9827566750, 8.9825530892], dtype=torch.float64)\n",
            "Iter 298; theta =  tensor([6.9832307809, 8.9829970015], dtype=torch.float64)\n",
            "Iter 299; theta =  tensor([6.9835863107, 8.9837133278], dtype=torch.float64)\n",
            "Iter 300; theta =  tensor([6.9839672082, 8.9840799169], dtype=torch.float64)\n",
            "Iter 301; theta =  tensor([6.9843228410, 8.9842544222], dtype=torch.float64)\n",
            "Iter 302; theta =  tensor([6.9845693010, 8.9843906876], dtype=torch.float64)\n",
            "Iter 303; theta =  tensor([6.9848499230, 8.9845391290], dtype=torch.float64)\n",
            "Iter 304; theta =  tensor([6.9852395666, 8.9850453941], dtype=torch.float64)\n",
            "Iter 305; theta =  tensor([6.9855497153, 8.9852343459], dtype=torch.float64)\n",
            "Iter 306; theta =  tensor([6.9858848546, 8.9854508273], dtype=torch.float64)\n",
            "Iter 307; theta =  tensor([6.9861651023, 8.9855766084], dtype=torch.float64)\n",
            "Iter 308; theta =  tensor([6.9864566167, 8.9858158846], dtype=torch.float64)\n",
            "Iter 309; theta =  tensor([6.9866684936, 8.9858513771], dtype=torch.float64)\n",
            "Iter 310; theta =  tensor([6.9870917543, 8.9862316310], dtype=torch.float64)\n",
            "Iter 311; theta =  tensor([6.9874879078, 8.9867014299], dtype=torch.float64)\n",
            "Iter 312; theta =  tensor([6.9876891145, 8.9868304842], dtype=torch.float64)\n",
            "Iter 313; theta =  tensor([6.9879376315, 8.9870565757], dtype=torch.float64)\n",
            "Iter 314; theta =  tensor([6.9881658052, 8.9871142279], dtype=torch.float64)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([6.9881658052, 8.9871142279], dtype=torch.float64, requires_grad=True)"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sua função deve retornar algo perto de 7 e 9\n",
        "minibatch_gd(derivada_torch, media_erros_quadrados, X, y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ao mudar o erro tolerado passado como parâmentro da função acima, o algoritmo de gradient descent deve passar por mais epochs até chegar numa estimativa razoável. Isto é: quanto mais exigente for o algoritmo, maior o número de iter na execução da função."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "khoTY_BZonb7"
      },
      "source": [
        "## Conjunto de Problemas 3: Logistic from Scratch"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "puVaL8Kuonb8"
      },
      "source": [
        "12. Repita o mesmo processo para a Logística. Lembrando que a mesma tem a seguinte forma:\n",
        "\n",
        "$$f(x_i) = \\frac{1}{1 + e^{-(1 + \\theta_1 x_{i1} + \\theta_2 x_{i2} + \\cdots \\theta_k x_{ik})}}$$\n",
        "\n",
        "Implemente a função logística."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "9gMYzjfDWBNh"
      },
      "outputs": [],
      "source": [
        "def logistic(X, theta):\n",
        "    return 1 / (1 + torch.exp(-torch.matmul(X, theta))).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "t-AsqWqHWBNk"
      },
      "outputs": [],
      "source": [
        "# testes, não apague!\n",
        "X_teste = torch.randn(1000, 20000)\n",
        "theta = torch.randn(20000)\n",
        "y_hat_teste = logistic(X_teste, theta)\n",
        "assert_equal(True, (y_hat_teste >= 0).numpy().all())\n",
        "assert_equal(True, (y_hat_teste <= 1).numpy().all())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xcOzTSYqoncA"
      },
      "source": [
        "Usando a logística acima implemente uma função logistica_prever que retorna 0 ou 1. Use o limiar dado na função. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "7IzJAoDYoncB"
      },
      "outputs": [],
      "source": [
        "def logistica_prever(X, theta, limiar=0.5):\n",
        "    return (logistic(X, theta) >= limiar).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "WeNGI7IFWBNs"
      },
      "outputs": [],
      "source": [
        "# testes, não apague!\n",
        "X_teste = torch.randn(1000, 20000)\n",
        "theta = torch.randn(20000)\n",
        "y_hat_teste = logistica_prever(X_teste, theta)\n",
        "for yi in y_hat_teste.numpy():\n",
        "    assert(yi in {0, 1})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "34WQX2AloncI"
      },
      "source": [
        "Agora, implemente uma função de entropia cruzada da logística. A mesma, é proporcional ao inverso da verossimilhança. Para entender a derivação entre as duas faça uso dos [Slides](https://docs.google.com/presentation/d/1yGPETPe8o7PPOP6_CF38LHr3vpxgTEnF5LjP-1pkGIc/edit?usp=sharing). \n",
        "\n",
        "Sendo:\n",
        "\n",
        "$$ll(x_i,y_i~|~\\theta) = y_i \\log f(x_i\\theta) + (1-y_i) \\log (1-f(x_i\\theta))$$\n",
        "\n",
        "A verossimilhança para uma observação. A entropia cruzada é a media da negação do termo para todos os exemplos:\n",
        "\n",
        "$$L(\\theta) = -n^{-1}\\sum_i \\big((1-y_i)\\log (1-f_{\\theta}(x_i)) + y_i\\log (f_{\\theta}(x_i))\\big)$$\n",
        "\n",
        "`dica: use torch.clamp(logistic(X, theta), min = 0.001, max = 0.999)`. A função remove os 0 e 1s da logistic, evitando assim o valor log(0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "z5XRS87bWBNw"
      },
      "outputs": [],
      "source": [
        "def cross_entropy_mean(X, theta, y):\n",
        "    logit = logistic(X, theta)\n",
        "    logit = torch.clamp(logit, min=0.00001, max = 0.99999)\n",
        "    return -(y * torch.log(logit) + (1 - y) * torch.log(1 - logit)).mean()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A entropia cruzada significa a distância entre o dado real e o dado previsto pelo modelo. Serve como a função de erro do modelo, substituindo a função de erro quadrático utilizada previamente. Quanto maior a entropia, maior a distância entre a solução real e a sugerida pelo modelo. A partir daqui, implementamos um modelo que aprende baseado na aproximação função logística utilizando do erro calculado pela entropia cruzada entre previsão e real."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "MC_fPXj0oncM"
      },
      "outputs": [],
      "source": [
        "# testes, não apague!\n",
        "from sklearn import datasets\n",
        "state = np.random.seed(20190187)\n",
        "\n",
        "X, y = datasets.make_blobs(n_samples=200, n_features=2, centers=2)\n",
        "X = torch.tensor(X).double()\n",
        "y = torch.tensor(y).double()\n",
        "\n",
        "for _ in range(100):\n",
        "    theta = torch.randn(2,1).double()\n",
        "    assert(cross_entropy_mean(X, theta, y) >= 0)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_1E_BSkhoncO"
      },
      "source": [
        "Agora implemente a derivada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "iJqaZncSWBN2"
      },
      "outputs": [],
      "source": [
        "def derivada_torch_logit(X, theta, y):\n",
        "    e = cross_entropy_mean(X, theta, y)\n",
        "    e.backward()\n",
        "    return theta.grad"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "D4kELMG4oncS"
      },
      "source": [
        "A partir daqui basta executar código."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "QZP6mlFIoncT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x289dded00>"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.scatter(X.numpy()[:, 0], X.numpy()[:, 1], s=80, edgecolors='k')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XlRLH5sMoncW"
      },
      "source": [
        "13. Assim como foi feito na primeira aula, abaixo testamos o seu código com um toy dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "_mY_Dfj8oncW"
      },
      "outputs": [],
      "source": [
        "# Use essa função antes de executar o GD\n",
        "def add_intercept(X):\n",
        "    Xn = torch.zeros(X.shape[0], X.shape[1] + 1).double()\n",
        "    Xn[:, 0]  = 1.0\n",
        "    Xn[:, 1:] = X\n",
        "    return Xn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "jT4OCJwYoncb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter 0; theta =  tensor([ 1.4894741774, -1.8465216160,  2.7510371208], dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "Iter 1; theta =  tensor([ 1.4894735961, -1.8465239187,  2.7510375798], dtype=torch.float64)\n",
            "Iter 2; theta =  tensor([ 1.4894732676, -1.8465253210,  2.7510378806], dtype=torch.float64)\n",
            "Iter 3; theta =  tensor([ 1.4893981197, -1.8468233589,  2.7509643857], dtype=torch.float64)\n",
            "Iter 4; theta =  tensor([ 1.4893974630, -1.8468266196,  2.7509644141], dtype=torch.float64)\n",
            "Iter 5; theta =  tensor([ 1.4893963576, -1.8468314248,  2.7509647925], dtype=torch.float64)\n",
            "Iter 6; theta =  tensor([ 1.4893962389, -1.8468319913,  2.7509648665], dtype=torch.float64)\n",
            "Iter 7; theta =  tensor([ 1.4893743295, -1.8469094548,  2.7509563158], dtype=torch.float64)\n",
            "Iter 8; theta =  tensor([ 1.4893743046, -1.8469095503,  2.7509563611], dtype=torch.float64)\n",
            "Iter 9; theta =  tensor([ 1.4893726160, -1.8469154747,  2.7509574491], dtype=torch.float64)\n",
            "Iter 10; theta =  tensor([ 1.4893722245, -1.8469171058,  2.7509578664], dtype=torch.float64)\n",
            "Iter 11; theta =  tensor([ 1.4893716496, -1.8469199394,  2.7509578933], dtype=torch.float64)\n",
            "tensor([ 1.4893716496, -1.8469199394,  2.7509578933], dtype=torch.float64,\n",
            "       requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "Xn = add_intercept(X)\n",
        "theta = minibatch_gd(derivada_torch_logit, cross_entropy_mean, Xn, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "47Iaopm_onch"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True])\n",
            "tensor(1., dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "y_p = logistica_prever(Xn, theta)\n",
        "print(y == y_p.int().double())\n",
        "print((y == y_p.int().double()).double().mean())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "02-Linear e Logistica.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
